{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Getting familiar with TensorFlow\n",
    "\n",
    "*TensorFlow* is one of the most popular deep learning framework developed by Google. If you are new to TensorFlow, please read and play with the sample in [Getting started with TensorFlow](https://www.tensorflow.org/get_started/get_started) to get started.\n",
    "\n",
    "* <b>Learning Objective:</b> In Problem 1, you implemented a fully connected network from scratch on your own. Very tedious to do it all by yourself, right? Well, we actually feel the same thing, that's why we are using tools instead of doing everything from scratch, lonely and depressed. For this part of the assignment, we will familiarize you with a widely-used deep learning framework developed by Google, TensorFlow and walk you through convolutional neural networks and show how to train them.\n",
    "* <b>Provided Codes:</b> We provide the Template class for a simple CNN model as BaseModel, predefined skeletons for conv2d() and max_pool(), as well as the dataset preprocessing parts.\n",
    "* <b>TODOs:</b> You are asked to implement the BaseModel following the detailed instrunctions and design your own model in YourModel to achieve a reasonably good performance for classification task on CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import libraries\n",
    "Install tensorflow and matplotlib.\n",
    "\n",
    "```\n",
    "pip install -U tensorflow matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "TensorFlow Version 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "# Add whatever you want\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print \"TensorFlow Version {}\".format(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f4c6bf4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test matplotlib\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "plt.plot(x, np.maximum(0, x), label='relu')\n",
    "plt.plot(x, 1/(1 + np.exp(-x)), label='sigmoid')\n",
    "plt.plot(x, (1 - np.exp(-2 * x))/(1 + np.exp(-2 * x)), label='tanh')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.title(\"Activation functions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.3.0\n",
      "2.000000 * 3.000000 = 6.000000\n"
     ]
    }
   ],
   "source": [
    "# Test tensorflow\n",
    "print('TensorFlow version: ' + tf.__version__)\n",
    "a = tf.constant(2.0)\n",
    "b = tf.constant(3.0)\n",
    "c = a * b\n",
    "\n",
    "sess = tf.Session()\n",
    "result = sess.run([a, b, c])\n",
    "print('%f * %f = %f' % (result[0], result[1], result[2]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "Download [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz) and load the dataset. In this assignment, we will use all 50,000 images for training and 10,000 images for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "num_training = 49000\n",
    "num_validation = 50000 - num_training\n",
    "num_test = 10000\n",
    "\n",
    "def unpickle(file):\n",
    "    import sys\n",
    "    if sys.version_info.major == 2:\n",
    "        import cPickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = cPickle.load(fo)\n",
    "        return dict['data'], dict['labels']\n",
    "    else:\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict[b'data'], dict[b'labels']\n",
    "\n",
    "def load_train_data():\n",
    "    #############################################################################\n",
    "    # TODO: Load training data from cifar-10 dataset                            #\n",
    "    # Load five files from 'data_batch_1' to 'data_batch_5'                     #\n",
    "    # Reshape images and labels to the shape of [50000, 32, 32, 3]              # \n",
    "    # and [50000], respectively                                                 #\n",
    "    #############################################################################\n",
    "    import os\n",
    "    data_path = \"data/cifar-10-batches-py\"\n",
    "    all_batches = []\n",
    "    all_labels = []\n",
    "    for b in range(1,6):\n",
    "        f_train_curr = os.path.join(data_path, 'data_batch_%d' % (b, ))\n",
    "        batch, labels = unpickle(f_train_curr)\n",
    "        batch = batch.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "        all_batches.append(batch)\n",
    "        all_labels.append(labels)\n",
    "    data_train = np.concatenate(all_batches)\n",
    "    labels_train = np.concatenate(all_labels)\n",
    "    del batch, labels\n",
    "    data_val = data_train[range(num_training, num_training+num_validation)]\n",
    "    labels_val = labels_train[range(num_training, num_training+num_validation)]\n",
    "    data_train = data_train[range(num_training)]\n",
    "    labels_train = labels_train[range(num_training)]\n",
    "\n",
    "    seq = range(num_training)\n",
    "    np.random.shuffle(seq)\n",
    "    data_train = data_train[seq]\n",
    "    labels_train = labels_train[seq]\n",
    "    return data_train, labels_train, data_val, labels_val \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "def load_test_data():\n",
    "    #############################################################################\n",
    "    # TODO: Load testing data from cifar-10 dataset                             #\n",
    "    # Load 'test_batch' file                                                    #\n",
    "    # Reshape images and labels to the shape of [10000, 32, 32, 3]              #\n",
    "    # and [10000], respectively                                                 #\n",
    "    #############################################################################\n",
    "    import os\n",
    "    data_path = \"data/cifar-10-batches-py\"\n",
    "    f_test = os.path.join(data_path, 'test_batch')\n",
    "    data_test, labels_test = unpickle(f_test)\n",
    "    data_test = data_test.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    return data_test, np.array(labels_test)\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "# Load cifar-10 data\n",
    "X_train, Y_train, X_val, Y_val = load_train_data()\n",
    "X_test, Y_test = load_test_data()\n",
    "\n",
    "# Check the shape of the dataset\n",
    "assert X_train.shape == (num_training, 32, 32, 3)\n",
    "assert Y_train.shape == (num_training, )\n",
    "assert X_val.shape == (num_validation, 32, 32, 3)\n",
    "assert Y_val.shape == (num_validation, )\n",
    "assert X_test.shape == (num_test, 32, 32, 3)\n",
    "assert Y_test.shape == (10000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2-1\n",
    "\n",
    "Using the code provided, implement a neural network architecture with an optimization routine according to the specification provided below.\n",
    "\n",
    "**Model:**\n",
    "- Input image with the size 32x32x3\n",
    "- 7x7 convolutional layer with 32 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- 5x5 convolutional layer with 64 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- Flatten layer (8x8x64 -> 4096)\n",
    "- Fully-connected layer with 384 output units (4096 -> 384)\n",
    "- ReLU activation layer\n",
    "- Fully-connected layer with 10 output units (384 -> 10)\n",
    "- Output logits (10)\n",
    "\n",
    "**Optimizer:**\n",
    "- Adam optimizer\n",
    "\n",
    "**Learning rate:**\n",
    "- Set start learning rate as 5e-4 and apply exponential decay every 500 steps with a base of 0.96\n",
    "- Use 'tf.train.exponential_decay' and 'tf.train.AdamOptimizer'\n",
    "\n",
    "**Loss:**\n",
    "- Softmax cross entropy loss\n",
    "- Use 'tf.nn.softmax_cross_entropy_with_logits'\n",
    "\n",
    "\n",
    "Your model **should** achieve about 60% accuracy on validation set in 5 epochs using provided evaluation code.\n",
    "\n",
    "You can modify the template code as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max pooling and conv layers\n",
    "def conv2d(input, kernel_size, stride, num_filter):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "#############################################################################\n",
    "# TODO: You can add any layers (fully-connected, normalization)             #\n",
    "#############################################################################\n",
    "def conv2d_wd(input, kernel_size, stride, num_filter, weight_decay):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "    \n",
    "    init_val = np.sqrt(2.0/(kernel_size*kernel_size*input.get_shape().as_list()[3]))\n",
    "    W = tf.get_variable('W', filter_shape, tf.float32, tf.random_normal_initializer(0.0, init_val))\n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "    weight_loss = tf.multiply(tf.nn.l2_loss(W), weight_decay, name='weight_loss')\n",
    "    tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, weight_loss)\n",
    "    return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "\n",
    "def weight_variable(shape, weight_decay):\n",
    "    \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "    init_val = np.sqrt(2.0/shape[0])\n",
    "    W = tf.get_variable(\"W\", shape, tf.float32, tf.random_normal_initializer(0.0, init_val))\n",
    "    weight_loss = tf.multiply(tf.nn.l2_loss(W), weight_decay, name='weight_loss')\n",
    "    tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, weight_loss)\n",
    "    return W\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "    b = tf.get_variable(name=\"b\", shape=shape, initializer=tf.zeros_initializer())\n",
    "    return b\n",
    "\n",
    "def convBnRelu(input, kernel_size, stride, num_filter, weight_decay, is_train):\n",
    "    conv = conv2d_wd(input, kernel_size, stride, num_filter, weight_decay)\n",
    "    bn = tf.contrib.layers.batch_norm(conv, center=True, scale=True, is_training=is_train)\n",
    "    relu = tf.nn.relu(bn)\n",
    "    return relu\n",
    "\n",
    "def avg_pool(input, kernel_size, stride, padding = 'SAME'):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.avg_pool(input, ksize=ksize, strides=strides, padding=padding)\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample convolutional nueral network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 5\n",
    "        self.batch_size = 128\n",
    "        self.log_step = 50\n",
    "        self._build_model()\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Sample model  ' + '-' * 5)\n",
    "\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv1'):\n",
    "            self.conv1 = conv2d(self.X, 7, 1, 32)\n",
    "            self.relu1 = tf.nn.relu(self.conv1)\n",
    "            self.pool1 = max_pool(self.relu1, 3, 2)            \n",
    "            print('conv1 layer: ' + str(self.pool1.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv2'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.conv2 = conv2d(self.pool1, kernel_size = 5, stride = 1, num_filter = 64)\n",
    "            self.relu2 = tf.nn.relu(self.conv2)\n",
    "            self.pool2 = max_pool(self.relu2, kernel_size = 3, stride = 2)           \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('conv2 layer: ' + str(self.pool2.get_shape()))\n",
    "\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Flatten the output tensor from conv2 layer                          #\n",
    "        #############################################################################\n",
    "        self.flat = tf.reshape(self.pool2, [-1, 8*8*64])\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################      \n",
    "        print('flat layer: ' + str(self.flat.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('fc3'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc3 = tf.contrib.layers.fully_connected(self.flat, 384)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc3 layer: ' + str(self.fc3.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('fc4'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc4 = tf.contrib.layers.fully_connected(self.fc3, 10, activation_fn = None)          \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc4 layer: ' + str(self.fc4.get_shape()))\n",
    "        # Return the last layer\n",
    "        return self.fc4\n",
    "\n",
    "    def _input_ops(self):\n",
    "        # Placeholders\n",
    "        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "        \n",
    "        #############################################################################\n",
    "        # TODO: You can add any placeholders                                        #\n",
    "        #############################################################################\n",
    "        self.is_train = tf.placeholder(tf.bool)\n",
    "        self.keep_prob = 0.2\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        # Adam optimizer 'self.train_op' that minimizes 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        #Set start learning rate as 5e-4 and apply exponential decay every 500 steps with a base of 0.96\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate =  tf.train.exponential_decay(5e-4, global_step, 500, 0.96, staircase=True)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss_op)        \n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "        \n",
    "    def _loss(self, labels, logits):\n",
    "        # Softmax cross entropy loss 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        self.loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits = logits))\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Define input variables\n",
    "        self._input_ops()\n",
    "\n",
    "        # Convert Y to one-hot vector\n",
    "        labels = tf.one_hot(self.Y, 10)\n",
    "\n",
    "        # Build a model and get logits\n",
    "        logits = self._model()\n",
    "\n",
    "        # Compute loss\n",
    "        self._loss(labels, logits)\n",
    "        \n",
    "        # Build optimizer\n",
    "        self._build_optimizer()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predict = tf.argmax(logits, 1)\n",
    "        correct = tf.equal(predict, self.Y)\n",
    "        self.accuracy_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "    def train(self, sess, X_train, Y_train, X_val, Y_val):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\n",
    "                #############################################################################\n",
    "                # TODO: You can change feed data as you want                                #\n",
    "                #############################################################################\n",
    "                feed_dict = {self.X: X_, self.Y: Y_, self.is_train: 1}                \n",
    "                #############################################################################\n",
    "                #                             END OF YOUR CODE                              #\n",
    "                #############################################################################\n",
    "                fetches = [self.train_op, self.loss_op, self.accuracy_op]\n",
    "\n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "\n",
    "            #############################################################################\n",
    "            # TODO: Plot training curves                                                #\n",
    "            #############################################################################\n",
    "            #def average(arr, n):\n",
    "            #    start = len(arr) % n\n",
    "            #    part = np.mean(np.array(arr[start:]).reshape(-1, n), 1)\n",
    "            #    if start != 0:\n",
    "            #        part = np.append(np.array(sum(arr[:start])) / start, part)\n",
    "            #    return part\n",
    "            #average_len = 100\n",
    "            # Graph 1. X: epoch, Y: training loss\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.title('Training loss')\n",
    "            #loss_hist_ = average(losses, average_len) # sparse the curve a bit\n",
    "            plt.plot(losses)\n",
    "            plt.xlabel('Iteration')\n",
    "            # Graph 2. X: epoch, Y: training accuracy\n",
    "            plt.subplot(2, 1, 2)\n",
    "            #accuracy_hist_ = average(accuracies, average_len)\n",
    "            plt.title('Training Accuracy')\n",
    "            plt.plot(accuracies)\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.gcf().set_size_inches(15, 12)\n",
    "            plt.show()\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "\n",
    "            # Print validation results\n",
    "            print('validation for epoch %d' % epoch)\n",
    "            val_accuracy = self.evaluate(sess, X_val, Y_val)\n",
    "            print('-  epoch %d: validation accuracy = %.3f' % (epoch, val_accuracy))\n",
    "\n",
    "    def evaluate(self, sess, X_eval, Y_eval):\n",
    "        eval_accuracy = 0.0\n",
    "        eval_iter = 0\n",
    "        for i in range(X_eval.shape[0] // self.batch_size):\n",
    "            X_ = X_eval[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "            Y_ = Y_eval[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                        \n",
    "            #############################################################################\n",
    "            # TODO: You can change feed data as you want                                #\n",
    "            #############################################################################\n",
    "            feed_dict = {self.X: X_, self.Y: Y_, self.is_train: 0}\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            accuracy = sess.run(self.accuracy_op, feed_dict=feed_dict)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_iter += 1\n",
    "        return eval_accuracy / eval_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Sample model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "flat layer: (?, 4096)\n",
      "fc3 layer: (?, 384)\n",
      "fc4 layer: (?, 10)\n",
      "-----  Start training  -----\n",
      "train for epoch 0\n",
      "iteration (0): loss = 31.209, accuracy = 0.117\n",
      "iteration (50): loss = 2.050, accuracy = 0.250\n",
      "iteration (100): loss = 1.751, accuracy = 0.398\n",
      "iteration (150): loss = 1.637, accuracy = 0.445\n",
      "iteration (200): loss = 1.611, accuracy = 0.453\n",
      "iteration (250): loss = 1.685, accuracy = 0.383\n",
      "iteration (300): loss = 1.455, accuracy = 0.414\n",
      "iteration (350): loss = 1.544, accuracy = 0.398\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAALJCAYAAAAeb3rdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22bcbc4290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation for epoch 0\n",
      "-  epoch 0: validation accuracy = 0.499\n",
      "train for epoch 1\n",
      "iteration (400): loss = 1.493, accuracy = 0.469\n",
      "iteration (450): loss = 1.326, accuracy = 0.508\n",
      "iteration (500): loss = 1.443, accuracy = 0.484\n",
      "iteration (550): loss = 1.418, accuracy = 0.539\n",
      "iteration (600): loss = 1.444, accuracy = 0.555\n",
      "iteration (650): loss = 1.382, accuracy = 0.508\n",
      "iteration (700): loss = 1.231, accuracy = 0.602\n",
      "iteration (750): loss = 1.155, accuracy = 0.586\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAALJCAYAAADxrRHjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERERHRMvP/ARxNHiUpY/MRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22549b3390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation for epoch 1\n",
      "-  epoch 1: validation accuracy = 0.574\n",
      "train for epoch 2\n",
      "iteration (800): loss = 1.309, accuracy = 0.562\n",
      "iteration (850): loss = 1.259, accuracy = 0.555\n",
      "iteration (900): loss = 1.245, accuracy = 0.516\n",
      "iteration (950): loss = 1.359, accuracy = 0.484\n",
      "iteration (1000): loss = 1.211, accuracy = 0.523\n",
      "iteration (1050): loss = 1.036, accuracy = 0.695\n",
      "iteration (1100): loss = 1.307, accuracy = 0.531\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAALJCAYAAAATcQqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns9lamgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2254a094d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation for epoch 2\n",
      "-  epoch 2: validation accuracy = 0.604\n",
      "train for epoch 3\n",
      "iteration (1150): loss = 0.971, accuracy = 0.625\n",
      "iteration (1200): loss = 1.050, accuracy = 0.602\n",
      "iteration (1250): loss = 1.156, accuracy = 0.609\n",
      "iteration (1300): loss = 1.060, accuracy = 0.672\n",
      "iteration (1350): loss = 1.099, accuracy = 0.633\n",
      "iteration (1400): loss = 0.955, accuracy = 0.656\n",
      "iteration (1450): loss = 1.096, accuracy = 0.633\n",
      "iteration (1500): loss = 1.123, accuracy = 0.609\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAALJCAYAAAATcQqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xmc3Hd95/nXp6rvQ+pWq9W6D0uyZRnwgWwMJoAxhzmC\nIWE4JskYwi7ZWWaS2WWZkGQzx+7shBxDhkxm2DCQwTshHEMgdjhjG4hNMDbybVnWad1Ht1qtvs+q\n7/5R1e1qu1tSyy11lfN6Ph56dP1+9auqb9Wvf616/76f3/cbKSUkSZIkSZUps9ANkCRJkiRdOEOd\nJEmSJFUwQ50kSZIkVTBDnSRJkiRVMEOdJEmSJFUwQ50kSZIkVTBDnSSpokRENiIGImLtfG57Ae34\ndxHxxfl+XkmS5qpqoRsgSXppi4iBksUGYBTIFZd/LaX0pbk8X0opBzTN97aSJFUqQ50k6aJKKU2F\nqog4APxPKaV7Zts+IqpSShOXom2SJL0UWH4pSVpQxTLGr0bElyOiH/jliHh1RPw0Is5ExPGI+JOI\nqC5uXxURKSLWF5f/onj/dyOiPyIeiIgNc922eP/bImJ3RPRGxH+KiL+PiA+d5/t4T0TsKLb5BxFx\nRcl9vx0RxyKiLyKeiYg3FNffGBGPFNefjIg/nIePVJL0D4yhTpJUDt4D/CWwGPgqMAH8BrAUuAm4\nFfi1szz+HwO/CywBDgH/91y3jYhlwNeATxRf91nghvNpfERcCfx34J8D7cA9wF0RUR0RVxXbfl1K\naRHwtuLrAvwn4A+L6zcBXz+f15MkqZShTpJUDn6cUvqblFI+pTScUvpZSunBlNJESmk/8Dng9Wd5\n/NdTSttTSuPAl4BrLmDbdwKPpZTuLN73x8Cp82z/B4C7Uko/KD72UxQC6qsoBNQ64KpiaemzxfcE\nMA5sjoi2lFJ/SunB83w9SZKmGOokSeXgcOlCRGyJiG9HxImI6AP+Lwq9Z7M5UXJ7iLMPjjLbtitL\n25FSSsCR82j75GMPljw2X3zsqpTSLuDjFN5DZ7HMdHlx0w8DW4FdEfFQRLz9PF9PkqQphjpJUjlI\nz1v+M+ApYFOxNPFfAXGR23AcWD25EBEBrDrPxx4D1pU8NlN8rqMAKaW/SCndBGwAssDvFdfvSil9\nAFgG/AfgryKi7sW/FUnSPySGOklSOWoGeoHB4vVqZ7uebr58C7guIn4+IqooXNPXfp6P/Rrwroh4\nQ3FAl08A/cCDEXFlRNwcEbXAcPFfHiAifiUilhZ79nophNv8/L4tSdJLnaFOklSOPg7cTiEY/RmF\nwVMuqpTSSeD9wKeBbmAj8CiFefXO9dgdFNr7WaCLwsAu7ypeX1cL/AGF6/NOAK3A7xQf+nZgZ3HU\nzz8C3p9SGpvHtyVJ+gcgCpcMSJKkUhGRpVBW+d6U0v0L3R5JkmZjT50kSUURcWtEtBRLJX+XwuiU\nDy1wsyRJOqs5hbqIuCIiHiv51xcR/yIilkTE3RGxp/iz9WI1WJKki+i1wH4KJZRvBd6TUjpn+aUk\nSQvpgssvi2UpRynMwfMx4HRK6VMR8UmgNaX0m/PXTEmSJEnSTF5M+eUtwL6U0kHgNuCO4vo7gHe/\n2IZJkiRJks6t6kU89gPAl4u3O1JKx4u3TwAdMz0gIj4KfBSgsbHxlVu2bHkRLy9JkiRJlevhhx8+\nlVI63+lzZnVB5ZcRUUNhRLCrUkonI+JMSqml5P6elNJZr6vbtm1b2r59+5xfW5IkSZJeCiLi4ZTS\nthf7PBdafvk24JHinD4AJyNiRbFhK4DOF9swSZIkSdK5XWio+yDPlV4C3EVh0lWKP+98MY2SJEmS\nJJ2fOYe6iGgE3gx8o2T1p4A3R8Qe4E3FZUmSJEnSRTbngVJSSoNA2/PWdVMYDVOSJEmSdAm9mCkN\nJEmSJEkLzFAnSZIkSRXMUCdJkiRJFcxQJ0mSJEkVzFAnSZIkSRXMUCdJkiRJFcxQJ0mSJEkVzFD3\nPHc9fow/+v6uhW6GJEmSJJ0XQ93z/PqXH+VPf7h3oZshSZIkSefFUCdJkiRJFcxQJ0mSJEkVzFAn\nSZIkSRXMUCdJkiRJFcxQJ0mSJEkVzFAnSZIkSRXMUCdJkiRJFcxQJ0mSJEkVzFAnSZIkSRXMUCdJ\nkiRJFcxQJ0mSJEkVzFAnSZIkSRXMUCdJkiRJFcxQJ0mSJEkVzFAnSZIkSRXMUCdJkiRJFcxQJ0mS\nJEkVzFAnSZIkSRXMUCdJkiRJFcxQJ0mSJEkVzFAnSZIkSRXMUCdJkiRJFcxQJ0mSJEkVbM6hLiJa\nIuLrEfFMROyMiFdHxJKIuDsi9hR/tl6MxkqSJEmSpruQnrrPAN9LKW0BrgZ2Ap8E7k0pbQbuLS5L\nkiRJki6yOYW6iFgMvA74AkBKaSyldAa4DbijuNkdwLvns5GSJEmSpJnNtaduA9AF/LeIeDQiPh8R\njUBHSul4cZsTQMdMD46Ij0bE9ojY3tXVdeGtvgRSSgvdBEmSJEk6p7mGuirgOuCzKaVrgUGeV2qZ\nCmloxkSUUvpcSmlbSmlbe3v7hbT3kjHTSZIkSaoEcw11R4AjKaUHi8tfpxDyTkbECoDiz875a+LC\nMNNJkiRJqgRzCnUppRPA4Yi4orjqFuBp4C7g9uK624E7562FC8TyS0mSJEmVoOoCHvPPgS9FRA2w\nH/gwhXD4tYj4CHAQeN/8NXFh5M10kiRJkirAnENdSukxYNsMd93y4ptTPpIFmJIkSZIqwIXMU/cP\ngtWXkiRJkiqBoU6SJEmSKpihbhZ5u+okSZIkVQBDXYnSES/NdJIkSZIqgaGuROmIl2Y6SZIkSZXA\nUFcily/tqTPWSZIkSSp/hroSpdfROU+dJEmSpEpgqCsxbXAUQ50kSZKkCmCoKzH9mjpTnSRJkqTy\nZ6grMf2augVsiCRJkiSdJ0NdiTTtmjpTnSRJkqTyZ6grMa2nbgHbIUmSJEnny1BXIufk45IkSZIq\njKGuxLTBL011kiRJkiqAoa6E5ZeSJEmSKo2hrkTe8ktJkiRJFcZQVyKff+6289RJkiRJqgSGuhL5\naVMaLGBDJEmSJOk8GepKlOY4B0qRJEmSVAkMdSWS19RJkiRJqjCGuhKWXEqSJEmqNIa6aUqvqTPh\nSZIkSSp/hroS0ycfX7h2SJIkSdL5MtSVKC2/NNNJkiRJqgSGuhKlc9M5+qUkSZKkSmCoK1Ga4xw0\nRZIkSVIlMNSVmD44iqlOkiRJUvkz1JVwoBRJkiRJlcZQNwsznSRJkqRKYKgrUVp+6Tx1kiRJkiqB\noa6E5ZeSJEmSKo2hrsS0YVIMdZIkSZIqQNVcHxARB4B+IAdMpJS2RcQS4KvAeuAA8L6UUs/8NfPS\nKC25TF5VJ0mSJKkCXGhP3c0ppWtSStuKy58E7k0pbQbuLS5XHMsvJUmSJFWa+Sq/vA24o3j7DuDd\n8/S8l1hJT52hTpIkSVIFuJBQl4C/jYiHI+KjxXUdKaXjxdsngI6ZHhgRH42I7RGxvaur6wJe+uLK\nl/bUWX4pSZIkqQLM+Zo64LUppaMRsQy4OyKeKb0zpZQiYsZElFL6HPA5gG3btpVdairtncuXXesk\nSZIk6YXm3FOXUjpa/NkJfBO4ATgZESsAij8757ORl0oqHSjF+ktJkiRJFWBOoS4iGiOiefI28Bbg\nKeAu4PbiZrcDd85nIy+V6eWXkiRJklT+5lp+2QF8MyImH/uXKaXvRcTPgK9FxEeAg8D75reZl0Zy\noBRJkiRJFWZOoS6ltB+4eob13cAt89WoBTNtSgNTnSRJkqTyN19TGrwkWH4pSZIkqdIY6kpYfilJ\nkiSp0hjqSiTLLyVJkiRVGENdiXxJkHOeOkmSJEmVwFBXIk27baqTJEmSVP4MdaXSLLclSZIkqUwZ\n6kqUll+a6SRJkiRVAkNdidKxUfIOlCJJkiSpAhjqSkyrvjTTSZIkSaoAhroSll9KkiRJqjSGuhLO\nUydJkiSp0hjqpinpqTPTSZIkSaoAhroSpROOO0+dJEmSpEpgqCsxvfxy4dohSZIkSefLUFciWX4p\nSZIkqcIY6krknadOkiRJUoUx1JVITmkgSZIkqcIY6mZhR50kSZKkSmCoKzFt8nFTnSRJkqQKYKgr\nMW30y4VrhiRJkiSdN0NdCac0kCRJklRpDHUlppVf2lcnSZIkqQIY6kqUxri8mU6SJElSBTDUlZpW\nfmmqkyRJklT+DHUlnHBckiRJUqUx1JUojXTmO0mSJEmVwFBXojTI2WsnSZIkqRIY6kpMn3x8ARsi\nSZIkSefJUFeiNMflTHWSJEmSKoChrlRJkMs7p4EkSZKkCmCoK1Ga4+ypkyRJklQJDHUlkj11kiRJ\nkirMBYW6iMhGxKMR8a3i8oaIeDAi9kbEVyOiZn6beWlMu6bOUCdJkiSpAlxoT91vADtLln8f+OOU\n0iagB/jIi23YQphefrlw7ZAkSZKk8zXnUBcRq4F3AJ8vLgfwRuDrxU3uAN49Xw28lCy/lCRJklRp\nLqSn7j8C/xLIF5fbgDMppYni8hFg1UwPjIiPRsT2iNje1dV1AS996ThQiiRJkqRKMKdQFxHvBDpT\nSg9fyIullD6XUtqWUtrW3t5+IU9xUZVOPu41dZIkSZIqQdUct78JeFdEvB2oAxYBnwFaIqKq2Fu3\nGjg6v828NEo75wx1kiRJkirBnHrqUkq/lVJanVJaD3wA+EFK6ZeAHwLvLW52O3DnvLbyEnH0S0mS\nJEmVZr7mqftN4H+PiL0UrrH7wjw97yVVWn6Z95o6SZIkSRVgruWXU1JKPwJ+VLy9H7hhfpq0cCy/\nlCRJklRp5qun7iUlwtEvJUmSJFUGQ12JybnpqjMZ56mTJEmSVBEMdSUmY1w2E+TyZ91UkiRJksqC\noa7EZMVlVSYcKEWSJElSRTDUlZgMclXZcKAUSZIkSRXBUFdiWvmlPXWSJEmSKoChrlRKREAmwoFS\nJEmSJFUEQ12JfIJgcqAUQ50kSZKk8meoK5FIRASZsPxSkiRJUmUw1JVICTJR6Kmz/FKSJElSJTDU\nlSiUX0ZxoJSFbo0kSZIknZuhrkSicFFd4Zo6Zx+XJEmSVP4MdaUmyy/DgVIkSZIkVQZDXYl8SgRB\nJhPk7KiTJEmSVAEMdSVSggjIZgoBT5IkSZLKnaGuRKIw8bjll5IkSZIqhaGuRKH8EjKZsKdOkiRJ\nUkUw1JVIicLol/bUSZIkSaoQhrrnycTkQCmGOkmSJEnlz1BXIp9SYaCUsPxSkiRJUmUw1JVIhbnH\ni5OPG+okSZIklT9DXYlEeq780kwnSZIkqQIY6krkJ+epC8jbUydJkiSpAhjqShQuowvLLyVJkiRV\nDEPdNIlMFEbAdKAUSZIkSZXAUFciny+WX9pTJ0mSJKlCGOpKJBLB5EAphjpJkiRJ5c9QVyIlyARU\n2VMnSZIkqUIY6koURr8MsmGokyRJklQZDHUlEoUgl8mEUxpIkiRJqghVC92AcrKxvYnxXCr01HlN\nnSRJkqQKYKgr8bGbNwHwW994klx+gRsjSZIkSedhTuWXEVEXEQ9FxOMRsSMi/m1x/YaIeDAi9kbE\nVyOi5uI099LIZnCeOkmSJEkVYa7X1I0Cb0wpXQ1cA9waETcCvw/8cUppE9ADfGR+m3lpOVCKJEmS\npEoxp1CXCgaKi9XFfwl4I/D14vo7gHfPWwsXgAOlSJIkSaoUcx79MiKyEfEY0AncDewDzqSUJoqb\nHAFWzfLYj0bE9ojY3tXVdaFtvugcKEWSJElSpZhzqEsp5VJK1wCrgRuALXN47OdSSttSStva29vn\n+tKXTNbJxyVJkiRViAuepy6ldAb4IfBqoCUiJkfSXA0cnYe2LZhMJhwoRZIkSVJFmOvol+0R0VK8\nXQ+8GdhJIdy9t7jZ7cCd89nIS82BUiRJkiRVirnOU7cCuCMishQC4ddSSt+KiKeBr0TEvwMeBb4w\nz+28pAo9dZBSIiIWujmSJEmSNKs5hbqU0hPAtTOs30/h+rqXhGwxyOUTZM10kiRJksrYBV9T91KW\nLX4qlmBKkiRJKneGuhlkMpM9dYY6SZIkSeXNUDeDqmKom7CnTpIkSVKZM9TNIFO8ps7yS0mSJEnl\nzlA3g+xk+aWhTpIkSVKZM9TNYDLU5bymTpIkSVKZM9TNYLL80p46SZIkSeXOUDcDe+okSZIkVQpD\n3QyyDpQiSZIkqUIY6mYwNU9dfoEbIkmSJEnnYKibQbb4qVh+KUmSJKncGepm4Dx1kiRJkiqFoW4G\nU/PU2VMnSZIkqcwZ6mbgQCmSJEmSKoWhbgaTA6UY6iRJkiSVO0PdDCZ76iy/lCRJklTuDHUzyNpT\nJ0mSJKlCGOpmkHGgFEmSJEkVwlA3g8nyy4mcoU6SJElSeTPUzWCq/NKeOkmSJEllzlA3g6l56vIL\n3BBJkiRJOgdD3QyyxU/FnjpJkiRJ5c5QN4PM5JQGjn4pSZIkqcwZ6mbglAaSJEmSKoWhbgaTPXWW\nX0qSJEkqd4a6GTw3UIqhTpIkSVJ5M9TNwCkNJEmSJFUKQ90Mpsov7amTJEmSVOYMdTOYKr+0p06S\nJElSmTPUzSA71VO3wA2RJEmSpHMw1M0gU/xUHChFkiRJUrkz1M3AgVIkSZIkVYo5hbqIWBMRP4yI\npyNiR0T8RnH9koi4OyL2FH+2XpzmXhpZB0qRJEmSVCHm2lM3AXw8pbQVuBH4WERsBT4J3JtS2gzc\nW1yuWBkHSpEkSZJUIeYU6lJKx1NKjxRv9wM7gVXAbcAdxc3uAN49n4281CZ76iZyhjpJkiRJ5e2C\nr6mLiPXAtcCDQEdK6XjxrhNAxyyP+WhEbI+I7V1dXRf60hddNmtPnSRJkqTKcEGhLiKagL8C/kVK\nqa/0vpRSAmZMQymlz6WUtqWUtrW3t1/IS18SXlMnSZIkqVLMOdRFRDWFQPellNI3iqtPRsSK4v0r\ngM75a+Kl5+iXkiRJkirFXEe/DOALwM6U0qdL7roLuL14+3bgzvlp3sLIFHvqnKdOkiRJUrmrmuP2\nNwG/AjwZEY8V1/028CngaxHxEeAg8L75a+KlN9VTl1/ghkiSJEnSOcwp1KWUfgzELHff8uKbUx6K\nmc7yS0mSJEll74JHv3wpiwgyYfmlJEmSpPJnqJtFNhP21EmSJEkqe4a6WWQi7KmTJEmSVPYMdbPI\nZsJ56iRJkiSVPUPdLLJh+aUkSZKk8meom0UmY/mlJEmSpPJnqJuFA6VIkiRJqgSGullkIpx8XJIk\nSVLZM9TNIptxnjpJkiRJ5c9QN4tsBBOGOkmSJEllzlA3i2w2yHtNnSRJkqQyZ6ibRTacp06SJElS\n+TPUzSLj6JeSJEmSKoChbhbZcJ46SZIkSeXPUDeLbMbyS0mSJEnlz1A3i0w4UIokSZKk8meom4U9\ndZIkSZIqgaFuFoWBUha6FZIkSZJ0doa6WWQDB0qRJEmSVPYMdbOw/FKSJElSJTDUzSITzlMnSZIk\nqfwZ6maRzThPnSRJkqTyZ6ibRTZjT50kSZKk8meom0Um7KmTJEmSVP4MdbOwp06SJElSJTDUzSIT\nwYQT1UmSJEkqc4a6WVRlgrw9dZIkSZLKnKFuFs5TJ0mSJKkSGOpmkckEZjpJkiRJ5c5QN4vqTDCe\nyy90MyRJkiTprAx1s6itzjAybqiTJEmSVN4MdbOoq84yOp5b6GZIkiRJ0lnNOdRFxJ9HRGdEPFWy\nbklE3B0Re4o/W+e3mZdeXXWWkQlDnSRJkqTydiE9dV8Ebn3euk8C96aUNgP3FpcrWl1VlvFccgRM\nSZIkSWVtzqEupXQfcPp5q28D7ijevgN494ts14Krqy58NCOWYEqSJEkqY/N1TV1HSul48fYJoGOm\njSLioxGxPSK2d3V1zdNLXxx11VkAhg11kiRJksrYvA+UklJKwIw1iymlz6WUtqWUtrW3t8/3S8+r\n+mKos6dOkiRJUjmbr1B3MiJWABR/ds7T8y6Y2qnyS6c1kCRJklS+5ivU3QXcXrx9O3DnPD3vgqmz\np06SJElSBbiQKQ2+DDwAXBERRyLiI8CngDdHxB7gTcXlimaokyRJklQJqub6gJTSB2e565YX2Zay\nUldl+aUkSZKk8jfvA6W8VNTX2FMnSZIkqfwZ6mYxVX45YaiTJEmSVL4MdbOoq5rsqbP8UpIkSVL5\nMtTNoq44pYGTj0uSJEkqZ4a6WdQVr6kbNdRJkiRJKmOGulk8V35pqJMkSZJUvgx1s6jOBpnwmjpJ\nkiRJ5c1QN4uIoK466zV1kiRJksqaoe4s6qqzll9KkiRJKmuGurOor85afilJkiSprBnqzqK2OuPk\n45IkSZLKmqHuLOqqsoyMGeokSZIklS9D3VnU2VMnSZIkqcwZ6s6izmvqJEmSJJU5Q91Z1Dv6pSRJ\nkqQyZ6g7C+epkyRJklTuDHVn0dZUw6n+0YVuhiRJkiTNylB3Fqtb6+kbmaB3eHyhmyJJkiRJMzLU\nncXq1gYAjvQMLXBLJEmSJGlmhrqzWN1aD8ChbkOdJEmSpPJkqDuLyzuaqa/O8tP93QvdFEmSJEma\nkaHuLOqqs9y0aSn37OwkpbTQzZEkSZKkFzDUncMtVy7j6Jlhdp3sX+imSJIkSdILGOrO4ZYty4iA\n7z55YqGbIkmSJEkvULXQDSh3yxbVceOGNv70h3u5csUiljbVkM0EYxN5OhbVUVOVYXg8x4a2RiJg\nx7E+tixvpipbyMspJf5udxc3bVpKddYMLUmSJGl+GerOw/9680Ye+EI3/8tfPDzrNisW1zGeS5wa\nGKW1oZqxiTyvuqyNg92D7OsapK46w/u3rWHZojrGJvK0NdXQWFPFO16xgrrqLPl8Yv+pAfKpMEAL\nFAJhRFyqtzlN/8g41dkMddXZBXl9SZIkSecnFmoAkG3btqXt27cvyGtfiKeO9rKva4BFddUAJBLd\nA2MMjk7QPzLB40d6OdE3zDPH++lYVMfRM8OsXFzHsd4RAKoywUT+hZ91VSZYXF/N8HiOobEcAJct\nbWT/qcGpbV62ahHjE4n+kXHWtTXypq0dbGxvJAH/8Z49rG6t59dedxmfv/9ZhsdzvHlrB9945Aj/\n+FXr+LlNS/nR7k5euXYJq1rruW9PF08d6eUXX7maH+85xRuuaCefYPvB09x4WRs/3d/Nv/vWTk70\njfDmrR3813+yDSiEvN7hcRbXV9Nc/AwA8vlEArKZYDyX58mjvWxdsYhdJ/p52arFpJSm9VqO5xLH\ne4epymZYubgOgL2dA6xtayCXT3zjkaM8sL+bz7z/GiKCk30jrGypZyKXJ8FUb2dKiZHxPNXZIJcS\ntVXnFz4HRydoqMnOOSwPjBYmoV/VUj+1LpdPZDNzD93DYznqqjPnbMP+rgGGxnK8bNXiOb+GJEmS\nyl9EPJxS2vain8dQd3H0j4zTXFfN08f6aKqtYs2SekYn8gyOTpDNBEd6hrln50lO9o0ynstzoneE\nH+89RSbg+vVLONY7zOHTw7z+8nYOnR6ivjrL+qUNPPTsaU4NjJ13O0rDZHNdFf0jE3N6H69c18qp\ngVEOFufqW9pUy89tXkr/yAQtDdXcv6eLodEcr7qsjXt2npzxOToW1XL16hZ+sq+bgdGZX//atS08\neujM1PLG9kYm8omD3UP8wrWruPeZTnqHx3nfttX0DI2z/cBpeobGAaivzvLua1dy99MneecrVjKe\ny/PIoTPsPN7Hh16znr6RcY6dGSafh58dPM3KxfVct66VAHaf7OemTUt519UraazNcsdPDvLY4TM8\nebSXyzuaeNOVHUzkE9958jhHeoZZ0ljDhqWNPHHkDOO5xE2b2vjMB66lZ3CMgdEJeobG2NTezK6T\n/fzR93dx7doWfvPWLRw6PcTTx/uoygS/89dP8frL27l+fStjE3nODI3zgRvWUFed5Znj/eRS4q8f\nPcp3nypcx3n/v7yZ8Vyen+zrZnQiz+hEjmXNdQyPTXDjZW2sbWvgzkePMZbLs2ZJA0d6hljVUk9d\ndZYf7znFDRuWsPtkP9esaWFwLMeJ3mFufdkKxiby3PGTA/zyjet4+GAPddUZrlvbSmtjzYz76NFD\nPfzgmU6uW9vKtvWtU+H+zNAY333qBL943WpqqjLk8omD3YPct7uLM8PjLGuu45o1LSxbVEtDTZaG\nmkKBwMm+EeprsvSPTEyF5dGJHH+74yTPnhrk115/GaMTeX6ws5PrNyxhVUs9+XziRN8In/3RPk4P\njfGh16xnfVsj9+3u4nWXt/OVhw7xijUtvP7ydgDGJvLUVGW46/Fj/HR/Nx+8fi0vX10Iyb3D4+w4\n1kvHojo2tjdB8ffhsUNneN/1a87vAGF6j/qzpwZZsbhuqoc7l08Mjk2wqK6a8Vyexw+f4fTgGG+5\navm05zh8eohP372bj928iY3tjfx0/2lesXoxDTVZHtjXzbb1S8gEVGUzHOoe4nP372NZcx0fumk9\n4xN5hsZyU/NqPv9kwdEzw3T2jXDt2lagcCImc5aTETPd3zM4RiaCxQ3VL9g+pcTO4/1sXbkIgM6+\nEbKZoK2pdtp2s62f6fkOdA/RWJtlWXPdWbedzXguT1UmGBnPU1/z4qsNRsZzF1y1kMsnhsYmpp0M\n03NSSqTEWX8nS42M54jgvE/kaWGklPj2k8d505UdVvxI52Coe4mbyOXJJ6ipmn4d3nguz/EzIzx6\nuIdsJmiqrWJzRzN/v/cUZ4bG+PmrV3L/7lNsXbmIux4/Rj6fePXGNv74nt2c6B1lZUsdP/+KlRw9\nM8z9e7rY1zXIDRuWcOtVy0nA0OgETx7t5dUb29hxrI+7nz7J6tZ6dhzrA6A6G4znEs11VTTWVNHW\nVMP6pY18/6kT03oi66ozbFjaxM7jfVPrVrXU01xXxbuuWcnh08N8+aFDL3jfrQ3VU2FtNpNtmKvL\nO5o42jPM4FiOTBTC4GCxd/R8VGeDtUsaOHZmhOHx83/cTGqqMoxN5Keti4BLdThmM0Fulp7jlS31\nUycShsdzZDPBypY6Dp8enrbtdWtbWL64ju0HeujsHyWbCRYVTxzM1Cs9+bob2xvpHR7nZN/otPue\n/5mU7ud4kHPFAAAgAElEQVSaqgzr2xo4fHr4vD775YvqyKVEz+AYEUz7fblh/RIyGfjp/tPTHrOx\nvZF9XYUe8ne8fAU3bmxjx9Fe6qqz7DrRz8qWeiIKJ0cOnx6mqTbLxvYm/sPdu1/w2m+4op1F9dV8\n7r79QOH3OpuJqRMyy5oLAfetVy3n1MAYf/XIkWmfUS6fuKKjmZUtdfxwVxdv3LKMHzzT+YL3ub6t\ngQPFEy6Tn1kmgitXLOJNVy7j8Olhvrr98LS2dfaPsKq1niWNtVy5vJmm2ir++rFjXNbeSHU2+Pu9\n3fzqTRuorc5wpGeYPSf72dc1QGtDDe+5dhU/2tXF1WsW86uv3UD/yAT7uwb4zb96kk+/72oaa6v4\n+NceZ2B0gq/92qs50TdCe1MtvcPj/Ks7n6Kzf5SVi+t41zWrePRQDy9btZhr1rTw53//LOvbGhkZ\nz02dzAD48E3rWdJQw76uATYta+LOx46xrq2Bm7cs48oVi9hxrI/P/nAvH7xhLd2DY2xZ3kwCfvev\nn+KGDUv4yb5uPvq6y+gfGWdjexPtzbVsWNrIQ8+eZsexPuqqs4yM57hsaSO3XbOKXEo8fvgMHYvq\neNWGJZwaGOU7Tx7n3/zN0/zc5qVcv34JB7oH+eANa/nGI0fY1zXIqy9r4y1XdbDzeD8DI+O0NtYw\nOpHn2jUtPHGkl58dOM1XfnaY+z5xMzuO9TI0luPHe09NVT7c+rLlPHmkl/e+cjUf/e/bWdVSz/9c\nrLwYncjx2V9+JQ/uP83B7kHedc1KBkYm2Ns5wMtXL+aHz3TROzzO1WsW8/CBHt7xihXUF0+cNNRk\n2d81yB987xnWLGng37zrKqBwEuYPv7+LA92D3HzFMp450U9rQzXdg2P8+hs3s35p47TfsZ7BsWkn\nerr6R1naVMNdjx/jm48e5fr1S3jz1g4GRye4YnkzdVVZMplgz8l+JvKJFYvrOHR6iL2dA7zqsjYe\n2NfNqze2saqlnocPnuYT/+MJLu9o5k//8bXsPzXI8d4RXrd5KT870EMmYFVrPQe7h1hUV0334Ci/\n8oWHeO2mpfzuO7fyxJEz1FZnaW+qZWlTDZuLly5A4f/Khw/2cM2aFmqrMvzpD/ZyWXsTm5Y1sbSp\nhramWlJK3Luzk4aaLFtWLKKptmrq/9yR8Ry/+VdPUFeV5Xd/fisANdkM1dmYOnHy6bt3c93aFm7Y\nsIRjZ4b5H9uP8PG3XEE+Fao4qrMZDpwa5KvbD7OpvYkbN7YRwI/3nOIfbVvNPTs72dc1wHuuXcXi\n+mrufvoktVUZrl3bSiLRNzxObVWWpU21JArVKQH0j0wwMDrBZe2N004g/fvv7OTWly2ne2CM473D\nfPimDS/4mzG57Xguf86w1TM4xqL66mkVKcNjOeprsoxN5BmZyE1VLwGcGhilrbGGgdEJ7tt9io/9\n5SN8+Kb1/M7bryQTQSYT5POJiOknnyaDfT4lTvaPcveOE7zv+jX0Do9zoneEa9a0TG0/ecJ80kzP\nN/mcO471Tat0GRqboCqTmfa9ateJfuqqM6xrm/57Px9SSpweHKOtqfYFJ8sOdQ+x41gvt76scIKv\ne3CMpec44XWpjE3k6Rkao2PRzCfVTg+OcezM8DmriM4MjXHo9BB11Vku72ieOgE6OpHjnqc7uXlL\n+9RJ3hdj8ndgdCLPkZ4hNrY3LdilSxfKUKc5mekPXy6feOpoL1evaZnTc42M56itml4+mM8n9nQO\nsLSphtODY1P/uT6wr5vG2sKXi3ddvXLaH7XB0Ql2Hu9j68pFPHb4DK++rA2ARw6dYffJfj5w/RrG\ncnn2dw2ysqWeA6cGWbOkgdaGaiJiqowxnwr/mRw+PcQ3Hz3KurYG3rilYyoULKqrIpMJljbVsutE\nPz/Zd4oPvWY9Y7k8PYPjfObe3fztjpN0D47xkddu4LfffiX/79/tY82SBk72jnDF8ma2rlw09Qc3\npcTukwMkEnfvOMnTx/s43jsy9QW7oSbL7pP9U1/gtyxv5vKOZqqzGSbyeSbyiU/euoW9nQP87MBp\nTg2McqB7iOvWtrJpWRMP7u9mPFfoYXjscC+L6qoYGc/x4Zs28O0nj3P7q9cXvqysbeGBfd08eqiH\n975yNVAoT62pyvAn9+5hVUs9mzuaeWB/N7e/eh13PnaMje1NrF/awIPPnmZf5wCrWurpHhxj87Im\nDp4e4pnjfbQ21nCwe4ilTbWcGngueF3W3sgf/OIreOjAaYZGc9zxkwP0j05w3doWljXX0dpYzdEz\nI4yM5zhwapDLO5qpq86yrq2BRXXV7OnsJ1H4UjAwOsFDz57mio5mTvaPcKYkyLc2VPPrt2zmyaO9\n1FZluXr1Yu7fc4of7upk2/olNNVm+U5xNNqaqgwffs16NrY38Wf37aN3eIJbX9bBvs5BBscmeOJI\n77Tf3avXtDA+kefpkpMNk5YvquPUwOisgXTSucL3hqWNHOkZmgqSr7u8nV0n+nj5qsVsbG/ib58u\n9EReiJaG6qnPavOyJvpGXhiOS5WeJMlmgjdf2cHatsL+f/LIGc7xVlnX1sCa1gbam2v5/o4TUyXi\nF0tddYaR8fy5N5zBbCXu8+VCTyYtlOd/ls21VfTPUilR6g1XtNPWWMu+rgG6B0c5fHqYdW0NbGpv\n4omjvXT1j3J5RxO7Tw7M+PjF9dX0Dp/9xBxAU23VrJUbr7u8nft2d53zOZ6vrbGGBDTWZhkczXF6\nsPA3+PmXNMxmUV0VN17WxpNHezlevHTi+ZY21dDSUMPezoGSddP/Vk7qWFT7guNz8qTN6tZ6jvQM\nv+Axc/XKda0c7B6a8fU/eMMa9pwcYGlTLUfPDHPLlcs4fmaEnx08zf6uQS5rb2TF4jpWtzRwy5XL\n+N6OE7z+8nZGxnOkBJ/8xpOsWFzHhqWN9I9M8JatHfznH+0lpcIX6EnXrW1hY3sT/+PhI7zjFSv4\nu11dL9i3y5prec3GNu5++iSDYzmWNdeyuaOJqkyG/pFxHimp1Hm+DUsLA9FlI9hT/NxvvqKdwbEc\njx7qob2pdur7yPLFdbzpyg5+/3vPAPB7v/ByqrMZjp0Z5tN37576/Jtqq2iqreJE3wg1VRl2/Nu3\nMjSa42+fPsFrNi3lR7s6qa3KMjw2wdKmWla21LOva4BsJvjSTw9xuGeIV65rpW9kgmvXtHBqYJSV\nLfWsa2tg14l+Tg+O8aUHCyeub9myjH1dA9RUZbhmTQvHe0e4f88pAP7RK1czMpHnbx4/xj99w0ae\nOd5HZ/8o77l2FatbG/jGI0emKrcW1VfxS69axzceOcIrVrfwxi3L+PYTx3nLVR2sb2tk+eI6HtjX\nzcMHe6ivyfKGK9r50a4ujvYUqr5O9I3w2s1Lqc5kuG9PF3/2d/v4hetW8/NXr2TrikV8+aFDPLC/\nm72dAzx7apCrVi5ieCzH21++gluuXMb6tkaO9Q7z8a89zjMn+vl/3vMy7t99iieOnOFXX7uBvuFC\n4G5vruW6ta288T/8aOpv8ifeegWfu28/n3zbFv7m8WP8ZF83AEsaa3jnK1bQPTjG8FiOX75xLY8c\nPEPfyDhLm2oZncjxxJFerl3Twm3XruKbjxxlYHSCxtosdz99kjdv7eCxw2fo6h9lUV012w/28Nlf\nuo7L2ptoqqti94l+Xr2xjdqqDAe6h1jf1lCWgc9QJ+miSClxamCMxtos399xgqtXt9BQU0VtVWba\nGfuTfSN8+4nj/NKNay+oFKr0zOXkGbyB0Qmaamc+czfT9ufS2Vcoa37rVctpLD7v5Ii0ezsHePPW\nDlrqa9h5oo8bL2sjl08MjEwwOpHjQPcQSxpr2HGsl9duWkqiUF65bV0r9+zsZMvyZobGcrQ313Kg\ne5DF9dW0NRa+8A2P5UgUztKuXFw/7WRGSomnjvaxZUUzXf2jVGWDJQ01DI7l+PMfP8uKxXW87eUr\nGBqb4O/3dvPWqzoYGJ2gtaGGqkxwZnic/pEJNhR7VFJK/P3ebl65rnB2//49p9i2rlBquaSxhrFc\nvnBmfiJNK5882TfCd548zt7OAa5b28rlHc08driHNUsa+P6OE/z8K1bymk1Lp7bf1zXAU0d7aW8q\nfOF/9PAZth/oIQJuvmIZvcPj7D7Zz/6uQf7pGzbyFz89yIaljTTWVrFleTP/5Uf7+P1ffDlXr2nh\n9MAYXQOjPPjsaW7auJTXbl7Kd548zms3LaUqG9zz9Ek2thd65jYta6KxtooI2NjeRHNdFacGRhka\ny1FTleHGDW30Do/T2ljNU0f7+LtdnSxprOHLDx3m/dev4dHDZ7hmTQtrWutZ2lzLT/ae4okjvfzv\nb7mcJ4708t7rVvOtJ49zsneEbz15nHVLGrjr8WNT77uhJssXbr+ezR1N/HhPoYftjgcO8OYrO7iq\neKa6KhMc6Rmif2SCN1zRzsHuIe7ZeZKbr1jGPTtP0tZUy/BYjss7mqnKBBuXNbJ5WTN/cu8eHjnU\nw42XtdHSUM3PbW4ngBN9I4znErtP9jMwOsEN65cwNJbjt7/5JAC/eN1qWhqqWVG8Lvmn+0/z1qs6\nGM8l9nT289P9p6eqJGqrMowWy5Ane8KvX9/KJ9+2hR/t6uK2a1bxpz/YwxNHe6nJFkZzPtg9NPW4\nScuaa+nsLwSHy5Y2Th0Pl3c0kVLhy/S1a1vZfaKfRw/30FRbxRuKvxfXrGkhE8G//85OXrVhCW1N\nNdz99El6hsb50GvW88WfHAAKJ122rmjmu0+dYGg0R2NtduqkxLVrW9hzcoD/8x1X8pcPHeL04Biv\n2djGY4fP0NZYy96uAda3NQCwuL6GXL5wYuxg8UTb1atbuPeZTpY11/LyVYt5+nhf4cthTRUP7C98\nwWxpqKYqk+E1G9uoygRvvHIZ7U21/Nf7n2VkvNDDeiGWFnsFFzdUs7/ruXB5/fpWth/sISV4/7Y1\nPHyoZ1pYvPWq5ezp7Odwz/C0KobJnvtlzbWsb2ukuqrQw34xvP7ydk72jfDMifOfq7etsYaxiTz9\noxPUZDNEFAaTOzUwxq0vW84TR85MOymQzQQ3X7Fs6u96Q02Wux4/Rm1VhtWt9VMVFKXam2vp6h9l\n7ZIGljTW8Njh2UPhTDIBiedO0GUCMjG3E0Nzra5ZvqiO7sHRaRUoz6/YOZvGmvOrLpqPE1A3X9HO\nD3fN/cRKOVrVUs/RM4UTKL9w3Sr+6L1Xn3e596ViqJMklZ3ZBhB6MdelXWqPHOph+aI6ViyuY3Ti\n3GVql8rIeI6+4XGWzVIWVeromWHam2qpqcpwenCM1oZqjveO0D0wNnVd6dleJxMxVaL30LOneeW6\nVs4MjTEynmdtMTztOFYYGOv5J1jGJgonEp5/PWPpyZh88ctzJhMc7x0mCDoWFXpcSq+zSymRT4Uv\n/hO5PFXZDJPfW+Z6xn22Ur3C6NODbFrWdM7neGBfN8sX1/HsqQGC4PTgGJd3NDM8nuOy9kbODI2z\nYnEdE7lEU12hJ6itsWba79DDB0/TsaiO1a0NdPaPsKiumrrq7NT77h4c4+njfVPXBo9O5Dh+ZoTm\nuir2dA5wY7Gq5fmf7eBYjm8/cYym2moSiW8/cZzf+4WX01RbRc/QOD/d382rNizhkUNnuGlTGwdO\nDfHk0V5es7GN7zx1nCcO9/K9HSe4Zk0L69saePe1q3jDFcsA6B0a57tPHee6da1TI3SP5/J8/v5n\nef3l7Uzk82xdsYhvP3mcN1y+jOa6KhKFErzRiTwrW+qn/jaklHhgXzcb2ht5+lgfVyxvZnVrw7T3\nc3pwjPFcnmXNtew62c+h7iFed3k7R3qGC+Xpy5vJ5dPUYGyPHuohnxL37Oxkx7E+fvG6VXT1j3Kk\nZ5i+kXGeOtrLx27exLuuXkln/yjVxRMYULhefPeJfkYn8mxZ0czDB3uYyBV+V7YsX0RddYb7dp/i\nbS9fznguz/17TnHVysX86k3rp8p3r1vXyo92dfJn9+3nTz5wLc11VdRVZ6nOZvja9sOsXdLATZuW\n0tk3wuhEnhWL69hxrI/f++5OfuXG9bxp6zIOdRdKFduba3nyaC9PHS2UZR/sHmLNkgb2dg7wX+/b\nzz974ybGcnnu291F3/AEJ/tHqM1m2LKimbVLGnnz1g7ufvoEoxN5tq1fwpNHzrDn5ADvvHol/+WH\ne/nejhP8o1eu4WTfCENjE/zc5naePTXItWsLJ19GJ3K8//q1hUqQ3hGePt7HVx46PHXyAwrH45rW\neratX8LRnmHefe1Kdp0o9EYOjBZOPG5sb+K1m5dOXfc+edLvVZctKVwqtKeLJY21XL16MX/50CEu\nX9bMb3/zSf6Pt17B/XtOsaqlnr2dA7z1qg4+8fUneO2mpfzyjesYHp9gVUsDLQ3VHDszzMm+ER47\n3MtXfnaId129kjsfK5yU+523X0n/6AQ/3tPFpmVNHOge4urVi/mdd2w953F+qZVdqIuIW4HPAFng\n8ymlT51te0OdJElSecjnE7mUnFNXL5DPJ0YnCiOOV13E34/ZqnD2dvaf81q58Vye6myG/V0DrGtr\nnPHk4kJOFXY28xXq5mXPREQW+M/A24CtwAcjovyisCRJkl4gUxzcRXq+TCaor8le1EAHs/e+b1rW\nfM4wNvm7e1l706zTTZVjoJtP87V3bgD2ppT2p5TGgK8At83Tc0uSJEmSZjFfoW4VcLhk+Uhx3TQR\n8dGI2B4R27u6XhoXYEqSJEnSQrqk/ewppc+llLallLa1t7dfypeWJEmSpJek+Qp1R4E1Jcuri+sk\nSZIkSRfRfIW6nwGbI2JDRNQAHwDumqfnliRJkiTNYuZZfucopTQREf8M+D6FKQ3+PKW0Yz6eW5Ik\nSZI0u3kJdQAppe8A35mv55MkSZIknZsTkkiSJElSBTPUSZIkSVIFM9RJkiRJUgUz1EmSJElSBYuU\n0sK8cEQXcHBBXvzslgKnFroRmuL+KB/ui/Li/igv7o/y4b4oL+6P8uL+KB+T+2JdSqn9xT7ZgoW6\nchUR21NK2xa6HSpwf5QP90V5cX+UF/dH+XBflBf3R3lxf5SP+d4Xll9KkiRJUgUz1EmSJElSBTPU\nvdDnFroBmsb9UT7cF+XF/VFe3B/lw31RXtwf5cX9UT7mdV94TZ0kSZIkVTB76iRJkiSpghnqJEmS\nJKmCGepKRMStEbErIvZGxCcXuj0vdRGxJiJ+GBFPR8SOiPiN4volEXF3ROwp/mwtro+I+JPi/nki\nIq5b2Hfw0hQR2Yh4NCK+VVzeEBEPFj/3r0ZETXF9bXF5b/H+9QvZ7peaiGiJiK9HxDMRsTMiXu2x\nsXAi4n8r/p16KiK+HBF1HhuXTkT8eUR0RsRTJevmfDxExO3F7fdExO0L8V5eCmbZH39Y/Hv1RER8\nMyJaSu77reL+2BURby1Z7/euF2mmfVFy38cjIkXE0uKyx8ZFNtv+iIh/Xjw+dkTEH5Ssn7djw1BX\nFBFZ4D8DbwO2Ah+MiK0L26qXvAng4ymlrcCNwMeKn/kngXtTSpuBe4vLUNg3m4v/Pgp89tI3+R+E\n3wB2liz/PvDHKaVNQA/wkeL6jwA9xfV/XNxO8+czwPdSSluAqynsE4+NBRARq4BfB7allF4GZIEP\n4LFxKX0RuPV56+Z0PETEEuBfA68CbgD+9WQQ1Jx9kRfuj7uBl6WUXgHsBn4LoPj/+geAq4qP+S/F\nk4d+75ofX+SF+4KIWAO8BThUstpj4+L7Is/bHxFxM3AbcHVK6Srgj4rr5/XYMNQ95wZgb0ppf0pp\nDPgKhR2giySldDyl9Ejxdj+FL62rKHzudxQ3uwN4d/H2bcD/lwp+CrRExIpL3OyXtIhYDbwD+Hxx\nOYA3Al8vbvL8/TG5n74O3FLcXi9SRCwGXgd8ASClNJZSOoPHxkKqAuojogpoAI7jsXHJpJTuA04/\nb/Vcj4e3AnenlE6nlHoohJAXfBnWuc20P1JKf5tSmigu/hRYXbx9G/CVlNJoSulZYC+F71x+75oH\nsxwbUDih9C+B0hERPTYusln2xz8FPpVSGi1u01lcP6/HhqHuOauAwyXLR4rrdAkUy5OuBR4EOlJK\nx4t3nQA6irfdRxfff6Twn0C+uNwGnCn5j7r0M5/aH8X7e4vb68XbAHQB/y0KpbCfj4hGPDYWRErp\nKIUzq4cohLle4GE8NhbaXI8Hj5NL51eB7xZvuz8usYi4DTiaUnr8eXe5LxbG5cDPFcvx/y4iri+u\nn9f9YajTgouIJuCvgH+RUuorvS8V5txw3o1LICLeCXSmlB5e6LaIKuA64LMppWuBQZ4rLQM8Ni6l\nYhnSbRTC9kqgEc9ilxWPh/IREb9D4fKKLy10W/4hiogG4LeBf7XQbdGUKmAJhUuNPgF87WJUbxjq\nnnMUWFOyvLq4ThdRRFRTCHRfSil9o7j65GTpWPHnZDe1++jiugl4V0QcoNDV/0YK13W1FEvOYPpn\nPrU/ivcvBrovZYNfwo4AR1JKDxaXv04h5HlsLIw3Ac+mlLpSSuPANygcLx4bC2uux4PHyUUWER8C\n3gn8UnpuImT3x6W1kcIJqMeL/5+vBh6JiOW4LxbKEeAbxbLXhyhUQy1lnveHoe45PwM2R2E0sxoK\nFy7etcBtekkrnqX4ArAzpfTpkrvuAiZHXroduLNk/T8pjt50I9BbUnqjFyml9FsppdUppfUUfv9/\nkFL6JeCHwHuLmz1/f0zup/cWt/dM+TxIKZ0ADkfEFcVVtwBP47GxUA4BN0ZEQ/Hv1uT+8NhYWHM9\nHr4PvCUiWou9r28prtM8iIj/n73zjo+juPv/Z+5Oki13XGg2tgGDKaaHEnpIoT0hnZZGQhLypPAj\ngYSS8AAJCSEBQggphBACplcDNrYx2OBece+9yrbc1KW72/n9sTu7s7MzW04nnSV/36+XX9ZtmZ2d\n3dubz37bpbDd9z/POW+QVr0F4BpmZ4UdCjtJxyzQvKtN4Jwv4pwP4JwPcX7PNwM4zfldoe9GaXgT\nwMUAwBg7BkA5gGoU+7vBOad/zj8Al8PO2LQGwF2l7k9n/wfgPNjuMgsBzHf+XQ479uR9AKsATABw\nkLM9g50NaA2ARbAz0ZX8PDrjPwAXAXjH+ftI5yGzGsArACqc5V2cz6ud9UeWut+d6R+AUwDMcb4f\nbwLoQ9+Nkl6PewEsB7AYwLMAKui70a7j/wLseMYs7Enqdwv5PsCO9Vrt/Luh1OfVUf8Zrsdq2HFA\n4vf8H9L2dznXYwWAy6TlNO9qg2uhrF8PoJ/zN303SnA9YIu4kc7vxzwAn5K2L9p3gzk7EgRBEARB\nEARBEB0Qcr8kCIIgCIIgCILowJCoIwiCIAiCIAiC6MCQqCMIgiAIgiAIgujAkKgjCIIgCIIgCILo\nwJCoIwiCIAiCIAiC6MCQqCMIgiA6BIyxOuf/IYyx64rc9p3K52nFbJ8gCIIg2hISdQRBEERHYwiA\nRKKOMZaJ2MQn6jjnn0zYJ4IgCIIoGSTqCIIgiI7GAwDOZ4zNZ4zdwhhLM8b+yBibzRhbyBj7AQAw\nxi5ijE1mjL0FYKmz7E3G2FzG2BLG2PedZQ8A6Oq095yzTFgFmdP2YsbYIsbY1VLbkxhjrzLGljPG\nnmOMsRKMBUEQBEEg6s0lQRAEQexv3A7gVs75lQDgiLN9nPNPMMYqAExljI13tj0NwImc83XO5+9w\nznczxroCmM0Ye41zfjtj7Mec81M0x/oSgFMAnAygn7PPR866UwGcAGArgKkAzgUwpfinSxAEQRDh\nkKWOIAiC6Oh8FsA3GWPzAcwE0BfAMGfdLEnQAcBPGWMLAMwAMEjazsR5AF7gnOc559sBfAjgE1Lb\nmznnFoD5sN1CCYIgCKLdIUsdQRAE0dFhAH7COR/nW8jYRQDqlc+fBnAO57yBMTYJQJdWHLdZ+jsP\n+k0lCIIgSgRZ6giCIIiORi2AHtLncQB+yBgrAwDG2DGMsW6a/XoB2OMIuuEAzpbWZcX+CpMBXO3E\n7fUHcAGAWUU5C4IgCIIoEvRWkSAIguhoLASQd9wonwbwKGzXx3lOspKdAL6g2W8sgJsYY8sArIDt\ngil4AsBCxtg8zvn10vI3AJwDYAEADuAXnPMqRxQSBEEQxH4B45yXug8EQRAEQRAEQRBEgZD7JUEQ\nBEEQBEEQRAeGRB1BEARBEARBEEQHhkQdQRAEQRAEQRBEB4ZEHUEQBEEQBEEQRAeGRB1BEARBEARB\nEEQHhkQdQRAEQRAEQRBEB4ZEHUEQBEEQBEEQRAeGRB1BEARBEARBEEQHhkQdQRAEQRAEQRBEB4ZE\nHUEQBEEQBEEQRAeGRB1BEARBEARBEEQHhkQdQRAEQRAEQRBEB4ZEHUEQBEEQBEEQRAeGRB1BEATR\nrjDG0oyxOsbYEcXcliAIgiAOVEjUEQRBEKE4okr8sxhjjdLn65O2xznPc867c843FnPbQmGM3cgY\n44yxL7fVMQiCIAiiLWGc81L3gSAIguggMMbWA7iRcz4hZJsM5zzXfr1qHYyxyQCOBzCFc35VOx87\nzTnPt+cxCYIgiM4HWeoIgiCIVsEY+y1j7CXG2AuMsVoAX2eMncMYm8EY28sY28YY+wtjrMzZPuNY\nxoY4n0c6699ljNUyxqYzxoYm3dZZfxljbCVjbB9j7DHG2FTG2LdD+n4UgHMBfB/AZYyx/sr6LzHG\n5jPGahhjqxljn3WW92WMPe2c2x7G2GvO8hsZY5Ok/XX9f5wxNpYxVg/gfMbY56VjbGSM/VrpwwXO\nWO5jjG1ijH3DGd+tjLGUtN3XGGNzE1w6giAIopNAoo4gCIIoBl8E8DyAXgBeApADcDOAfrBF06UA\nfhCy/3UAfg3gIAAbAfwm6baMsQEAXgZwm3PcdQDOjOj3NwHM4Jy/BmCN0zac9j4J4CkAPwfQG8DF\nADY4q58HUA7bwjcAwKMRx1H7fy+AHgCmA6gDcL1zjP8BcDNj7EqnD0MBjAHwMIC+AE4FsIhzPh1A\nLWBixDEAACAASURBVIBLpHa/AeCZBP0gCIIgOgkk6giCIIhiMIVz/jbn3OKcN3LOZ3POZ3LOc5zz\ntQCeAHBhyP6vcs7ncM6zAJ4DcEoB214JYD7nfJSz7hEA1aZGGGMMtqh73ln0vPNZ8F0A/+Kcv++c\n1ybO+QrG2CDYYuqHnPM9nPMs5/yjkP6qvME5n+602cw5/4BzvsT5vADAi/DG6usA3uWcv+yMZTXn\nfL6z7hlnPRhj/Zw+vZCgHwRBEEQngUQdQRAEUQw2yR8YY8MZY6MZY1WMsRoA98G2npmokv5uANC9\ngG0Pk/vB7aDxzSHtXABgIGzLImCLutMYYyc6nwfBtt6pDAJQzTnfF9J2GOpYncMYm8QY28kY2wfg\nRnhjZeoDADwL4CrGWFcA1wCYyDnfUWCfCIIgiA4MiTqCIAiiGKhZt/4JYDGAoznnPQHcDYC1cR+2\nwRZpAFxL3OEh238L9u/gIsZYFYCpsM/jW876TQCO0uy3CUA/xlhPzbp6AJXS50M026hj9SKA1wAM\n4pz3AvAkvLEy9QFORtC5AL4A2/XyWd12BEEQROeHRB1BEATRFvQAsA9APWPsOITH0xWLd2Bb2v6H\nMZaBHdPXX7chY6wSwFdgu1ieIv27BcD1jLE0gH8DuJExdjFjLMUYG8gYO5ZzvgnABACPM8Z6M8bK\nGGMXOE0vAHASY2yEY0H7vxj97gFgN+e8iTF2Nmyrm2AkgEsZY192kq70Y4ydLK1/BsAdAIYDGBXj\nWARBEEQnhEQdQRAE0Rb8HLbFqxa21e6l8M1bD+d8O4CrYScV2QXbwvUxgGbN5l9y+jaSc14l/gH4\nF4CuAD7DOZ8G4HsA/gJboE6E7Q4JOLFsAFYC2A7gJ04flgL4HYBJAFYAiBNr90MAv3cyh94JO9mL\nOKd1sJOn/BLAbgDzAIyQ9n0NwJGw4wwbYxyLIAiC6IRQnTqCIAiiU+JY27YC+ArnfHKp+9MWOC6m\n6wB8m3M+qcTdIQiCIEoEWeoIgiCITgNj7FLHJbICdtmDLIBZJe5WW/I12JbID0vdEYIgCKJ0ZErd\nAYIgCIIoIufBzmKZAbAEwBc55zr3yw4PY2wKgGEArufkdkMQBHFAQ+6XBEEQBEEQBEEQHRhyvyQI\ngiAIgiAIgujAlMz9sl+/fnzIkCGlOjxBEARBEARBEERJmTt3bjXnXFt+JwklE3VDhgzBnDlzSnV4\ngiAIgiAIgiCIksIY21CMdsj9kiAIgiAIgiAIogNDoo4gCIIgCIIgCKIDQ6KOIAiCIAiCIAiiA0Oi\njiAIgiAIgiAIogNDoo4gCIIgCIIgCKIDQ6KOIAiCIAiCIAiiA0OijiAIgiAIgiAIogNDoo4gCIIg\nCIIgCKIDQ6KOIAiCIAiCIAiiA0OijiAIgiAIgiAIogNDoo4gCIIgCIIgCKIDQ6KOIAiCIAiCIAgj\nTdk8htw+Gq/O3VzqroTy4+fn4av/mFbqbpQEEnUEQRAEQRAEQRiprmsGADw8fkWJexLOOwu3Yfb6\nPaXuRkkgUUcQBEEQBEEQhJEUYwAAXuJ+EGZI1BEEQRAEQRCdkl11zfjRc/NQ25QtdVdaxZKt+3DH\n64tgWaWRVY6mg8Xb9/hN2Tx++sLH2LK30bjNqPlb8NSUde3Yq/0TEnUEQRAEQRBEp+TxiWswetE2\nvDxn/44Fi+I7T8/GC7M2Ykdtc0mOz+BY6tpZU05asQNvLdiK+95eYtzm5hfn4753lrZjr/ZPSNQR\nBEEQBEEQnRJhYeLtrUaKTCZlT9lzllWS46fEOLb7ke0Dl8hA2aEgUUcQBEEQBEF0SlipO2Bgd30L\nXpi1Mfb2aUdV5fKlVTdtJY4553hm+vqAm6wnyqPbyOVLI3j3F0jUEQRBEARBEJ2SJKKgPbn5xY9x\nx+uLsHpHXaztM0LUlchkJQ7bVoefuW437h61BL96c7FvuUjQEsdGuLexY8dNthYSdQRBEARBEESn\nhLlZG/cvVVdd1wIAaM7lY22fSdvnkS+ZqLOP21aWuuacbWXbXd/iWy4kXZzT3qPse6BBoo4gCIIg\nCOIAZsGmvWjKxhMXHQ3XzmMQBZbFMXfD7nbrjyCV0IKYdmLqsiVyMRTdjCOuFm7eG1usClKG7Jph\nMZFzN+zxZQPd00CWOoIgCIIgCOIAZPOeBlz1+FT83yhzdsEOTUSCj6emrsOX/z4dH63c2W5dAqS6\nbzFFnXC/bCmRqBPiKcpSt2l3Az7/16m4561k95NpPJjh+s1Yuwtf/vs0/P3DNShP23JmH7lfEgRB\nEARBEAciYiK8YPPeEvekbYhKxb9qux3TtnmPuQ5aW5C07ptIlNKSK5Gljvv/NyHcJxdt2ZeofdN4\nMIPY217TBABYXlXr7psvUWbQ/YVYoo4xdiljbAVjbDVj7HbN+kcYY/OdfysZY53zyUAQBEEQBNEJ\nyVscjS35xG5z+xPZvGV0TzTF1Dleje0ecyfESlxRl2kDUdeUzccuZi7GpymXD7XW5Z11aZYs72iK\n6UsXeDF1XL+95V05UxKZxpaOe08nIVLUMcbSAB4HcBmA4wFcyxg7Xt6Gc34L5/wUzvkpAB4D8Hpb\ndJYgCIIgCIIoHsKStWpHHY67eyyO/dXYEveocE66ZzzOvH+Cb1l07Fppimp7MWTxtheWumLF1GXz\nFob/eix+Mzpe0W7Rz2ye45EJq8zbORumUoWJOlUwMoM4FOMhJ45pygbHZv6mvTju7rF4f9n2RP3p\niMSx1J0JYDXnfC3nvAXAiwCuCtn+WgAvFKNzBEEQBEEQBBGHxmw+kCwjymCUCknE0ZZ4CVziHbfM\niRsrlqVOiMMXZ22Ktb3czzc+3mzcToispJY6ZhC5pkQ3QgTmfKIuaJGbt2EPALR7zGQpiCPqDgcg\nX/HNzrIAjLHBAIYC+MCw/vuMsTmMsTk7d3b+wSUIgiAIgtifiev+11HxYuoM7pduyYP2Jelx00VO\nlJL0sstiK0yw5Qu01In9TG6WqnusGA+Lc3cQdaLOlGilM1LsRCnXAHiVc651XuWcP8E5P4Nzfkb/\n/v2LfGiCIAiCIIi2ZcLS7Tjh7rFoaMmVuitFIU4x64fHr8AX/za1HXpTfKKKj7tukO1c/02OCYtD\nsWPqkop5WRSbXCIBoNkRnZmEos7Lrulf7lrwlNPOaNwvmzVjk0oYu9iRiSPqtgAYJH0e6CzTcQ3I\n9ZIgCIIgiE7KH8etQH1LHht2NZS6K0UhF8Py85cPVuPjjR07B55pSs8MCTraGjdjY9Lsl0Wy1CVN\nFCn3MsyzstmJa0sntdQZipu77pfKFUylgmJNlxAlStR3JuKIutkAhjHGhjLGymELt7fUjRhjwwH0\nATC9uF0kCIIgCILYP+hsk8RsvpOciAFTSnxvvf1/qdwv44qrTNpJlFIkS11cMSmQxVMqzFLnZE8N\n20bbH9f90r9cfAzG1Hn7uZk5te6XpXGvLQWRoo5zngPwYwDjACwD8DLnfAlj7D7G2OelTa8B8CJv\n70hTgiAIgiAIoiBynby2l8nSIzBlXRTsqG3CnW8sil3qYcveRtw9arHPLVDbL6dj8vj/48M1mLl2\nl3b7tFN7oRiWOs45/vDucgB2cplH3lsZuv3s9bvxqJTxMswIJ1wgk1rqhGhU3STF55nrdmPkjA2B\n/XzZLzXXyJRopTMSK6aOcz6Gc34M5/wozvn9zrK7OedvSdvcwzkP1LAjCIIgCILoLDBD4oaOSq6T\nW+oERkud878p5urBsSvw/MyNeHdRVazj3PryAjwzfQNmr98dup0Qk7IoeeDd5bj6iRna7cuKGFPX\nnLPw0hwvB+Kj768KzcL5tX9Ox7uLvfMPt9RZkdvoEFo1YKmTPv/qzcXS9tz3PwBU7WsKOULnv8+L\nnSiFIAiCIAii09LZ3vwXq+7Z/kqUe6WIzTJdz4qMPVWubcrqN1CI69boWeribi9i6trmxtMlGRH0\n6lqm7Yu2HccFMp1QYeTdRCl6S52KWJzn3P171Y66kHaT9acjQqKOIAiCIAjiAEUnKtqyphfnHC/N\n3qiNf2oLREkD06zeVB9N0L1LBgBQ01TcbKc6S10YQuwUK/ulStj1OOKgSt/nzbsbjMW8i+1+qbts\ny7bVYIbjpipnDxXJi8ShF2/Zh+lrdmnb7YyQqCMIgiAIgohJ50uUEhQJ33xqlnbbuAIkjPFLt+OX\nry3CwxFxXMUiylInRJ9p0t+jwhZ1dc3FFnX2/3EtdaJ/xbCs6s61MUTUDehR4ftc25zDd/87R7ut\nEHWumI6JOVFKsK+XPToZ//xorb2f5lxEG1c+NgVjl9huo53l+xoGiTqCIAiCIIiYeCKhc8wSk8TU\nFUNQ1DoWr+ra5la3FQcxmY+qU2eiS1kaAFBXZEsdcy118cZUXKZiWJx0OlJXDiBse0Bv3RMJZZIm\n4DEmSoloJm/pBbvqxpk022dHhEQdQRAEQRBETJJaIEpJXXMOGyPq6Zkm35t2B/eLa1UKw8tG2T7k\nDWJBoLpBWhbHsm013v7Ocl1M3Za9jdjb0OJut6KqNna/XEtdTFHtip4iXIMoS11dcw5Ltu7D+up6\nAGYL7R7n3Fdtr3XdQkWduiQvC5ZX1bj7y11btq0m8p6zLK5N8rJka43vc2cv3QGQqCMIgiAIgohN\nR3K//Mrfp+GCP04M3cY02T3/weB+cQqVR+GNX/sMoBBBJkuNsLiKc3tq6jpc9uhkzHGyVwrrZF1z\n0Cp17gMf4KI/TQIAPPLeSnzuzx9htSZZhw6mEZNhcFecxmo+vC3NZZStbl9/ciau+MsU99xMgnh3\nfQt21DThM498hHvfXgLAc7/Mxuzoyu21uPTPk113XHGsxVv24bJHJ+Nvk1b7+x7TAnflY1N8n5vb\nKYazlJCoIwiCIAiCiEl7W5paw/IYlqMkQq0Y1o72LvYtRELe0Hdx+kKELNqyDwCweU+jvdzZz1Sn\nbm+DbcGbt3EPAFvoxEGNqYuySOUjxGkStJa6Fu8+mL9pr2+dyeq2pz6LGseCOWudLYJd98uY95Uo\nQ7DN+V/0TYz/ws37fNurdfosK54jdFh2z84CiTqCIAiCkOBc785DEDLtdY8U6340tZPEpbIYhcrb\nwn01bIyECDKdpxARqggRUkFY6uqbc6HWNFOWf1PfAm6fEddYHFruQ9h5i3WqeyLnXCsMTYlS8pZ+\ne8B2v1SHRIgnVQjq+gIExb1liXPUH1N9sRD3/o1bPL4jQ6KOIAiCICSG3jEGt76ysNTdIPZXnMn4\nF/82Dfsa4tUuS8LvxizDkNtHu5P3e99eiqF3jGlVm3XNOQy9Ywz+8eHawLok1rdiFiovpiY++/fv\n47w/6N1MrQjRJESVOg63vLQAa3bWuaJu3sa9OPLOMW6MYtykMUPvGIPvPD07sFytUxeVWVR3HkPv\nGIO7pILc6nHvfXspjrzT/l9w3ztLccZvJwS2N4m6bN4KjakTMXRiC/E5q7wAuGnkXBx55xgMvWMM\nXpYKn6sib8veRhx55xi8Pm+L9phqSYe8xWPdS2GJYDoLJOoIgiAIQuG1eZtL3QViP0U2yOyobSp6\n+/+abAsvMXl/etp6AK2zDIpkHs9OXx9Yl8z9sngxdcVke00ztuxt1K4TesRk0cm77o/Bc1uwaW9A\n7C2vshNw1CslDlQLpHy5Jq4I1v1Ts19GJgQRbqRKN5+fuTG4reW/d8T/APCfqesD2wPmOnXNOct4\nj7TkrIAYFO6R6guAcUu8unZjFm1z/zad9fil+jp4qqiLaz3eqEn809kgUUcQBEEQBBGTthAlOgL1\nulph2RKFoFs0lrZk7pdFtNQVraVw3Fg0Y0yd2VKWs3hAyIqxrG1liQPhfinGNCpRilrSIEzkFxJ3\nZxJ12bylvW8Ae8xUUScSkoS9AOjVtcz7kLCrartxi7HvacjGjnfsqJCoIwiCIIgOwDPT1+O6f80o\ndTeKzq/eXORmzusIyJqOFaDwxi6uwpf+NjVyEq+6CyaZqL88exO+9o/p3r4h1qgkcXJxLXWPTliF\nHz8/T7tOjFncemtV+5pw9u/exzonvX5SXAtXRMydzg01lw+Kuv/30nw89v4q1LeEi7qo9B0iUcqD\nY1fguZkbQq/v1/45HR+ttK19Vkh/BTqByjnHtU+Ynx8NLXm8OnczvvqPab7lLSGWupzFA26Nbkxd\nyP3ds4sn6pLWe1QTniRxH16zM15m0o4KiTqCIAiC6ADcPWoJpq3ZVepuFJ2RMzYaXcL2R2QhV4jV\n7qaRczFv4140GRI3cMUiI0hSdPoXry3ELCclP+C5wmU1Vo0kcXJxt31kwkq8s3Cbdl3SIXtn4VZU\n1TTh2ekbEu5p47ktGkRdXp8oxd7HCoiG2qYcHnpvZdD9UjmxKK0sb37XG4tDY+pEZkm7T2aBLtAJ\nquachelrzc+PbM7Cra8swOz1e3zLW3KWUcznLR6w8HmJUsz969k14/6d1KioWuaiEqAc2a8bbv3s\nMQCAXXVkqSMIgiAIgiCKSFRiDHV9axJPikm5zqqRKFFKEbJfusQ8bFk61apjC21hFHXC8hXT/VIg\n6tZVZPRT6bjZLL1+xhuQWJY6zbqoRCGm88zmg8JWkNO5X+aE+6V/n0zKk7HdKzxLXVKPXrWfUffv\nBcf0x/+cfBiAYBxkZ4NEHUEQBNGm7GvM4jfvLI0d+1BKOkspA8vi+MPY5W4NqP2NsYu3YexivSWn\ntimL+95eaozxKTWyhSUVYap7cvJaLFBqfgmiJrPq+iiRwDnHnyesxFqNi9mD41YACNb4ApKJJdla\nlrc4fv/ussTJYuJYNycs3Y63F2wF4MWwZfMc45ZUYbTBAqjyzsKtGLekyis+7vz/1oKt+GC5l4RD\nrNdZll6avQnvL9uhbb/OialrzlmYtro6sD7KXTbgXitd8A276vHQ+BXa55G4XHJ/n/hoDRZv8eq5\n6a6pKO5twhQ31xxqqbN8YnHO+t1Yu7Ne24duFRkUA909HEYmxdxjR7nMdnRI1BEEQRBtykPjV+Df\nU9bhjY/3/4ySRcwDUVLmbdyDv09ag1tfWVDqrmi5aeQ83DRSH3P12Aer8dTUdXhl7v55v8iiJOwl\nAOccvx29DFc9PlW7PjKmTlkfJRJqmnL484RVuEYTN/WeIZMgEJ5oQu3Dm/O3un9PXV2Nf364Fne9\noU+pH0VYLNWNz8zBT174GABQlnYSiuQt/ODZufiRIVZP5cfPf4wfPDvXq0PniIyfvvAxvvP0HHc7\n4aqos/gsr6o1pvqXXzpc9+TMwPqo6ytfzl5dy3yi7tv/mY3HPliNqpqmwD2mq7v3uzHLceVjU7xt\nNMd+dka4+6pJuLXkzaJOtdR9RRPHKTi0Vxf3b1nQJn2RlvTlYCadQndH1NWRpY4gCIIgCsetY9QB\nBFOSuKX9GTFBLUYK+vamtsmu/ZZurzSTrSBs3l4TkR0xqSWHR1xK4d22pyFZ3JBJtOj6ICMm13Hd\nBgVi+7hftUxKuF8W9t3MuzF14evDviv9e1QE94tMdBPeL3lse3Ut890P1XXNxnZ4jP4WMlamGLhs\nzux+mc97MXXqeOjG59PHHewcSxJ1CfuZ1FJXlmaoyKSQSTHXutpZIVFHEARBtCli8hLlqrY/0FlE\nHZfG/N1F29BQoNvR8qoa/HvKOtQ35/DWgq1t6kK7bJtd/0u8BDDFKiWhKZvHOwu3Rm9oYNa63dik\n1LeS65GNW1Jl3HePkz69Zxe921l0Cnv/+qqaJjcDorY9Z/NsnqM8HX/swmKtwoSnWCfcI9furMPc\nDbu123LO8faCrWjO5V0xF+erZlkc7zpuurKIkV0N47QBePXgTOubcxZmrN2FUfOD98vggyoDy1Th\npGZCNYm+uuYcxi6uCog6+X5ocK5Jc9YKuDHmLY7xS6rwhqY498TlO0KPHYbJ/XLDrgajhUvOfqlm\nJ5X7MHbxNuxpaEFFWcpZZ5/Tu4u2JS4KvnxbbaLt0ykGxmwXTIqpIwiCIIhWIH7bO4Cma1UyivYi\njruSGPPlVTX44XPz8KsCXeTufH0RfvPOUvx29DL89IWP8dB7KwpqJw6XPToZgJc9r0tZutVtPvDu\ncvz4+Y8xbU0w5ikOX/vndJz/4ET/Quk+/uO4FcZU+7sdi1nvynJ3mTxxj7LUqau/9Lep+OZTs0K2\n93YQLotxCLXUhXwfxKRdWFQ/9dCH+PLfp2u3nbRyJ37ywsd4+L2VnqUuho3mzflbMMGJaZOtO7Kr\nYRQiAYrJeiWWt+QsresqAFSUpTC4r1/YRcUiWpxrv6u3vDQfN42ci/XV3suCAT0qfP3LS0IzYAHj\nwPefnYuHNDFyNzw9G40t+YIsdSbL3y9eW2jcJ29xYxZX0YXVO2px08h52F7TjIq0bTHLc44Fm/bi\nh8/Nw92jkj2b/jB2eaLtRaKd7hUZN7lNZ4VEHUEQBNGmcLLUFZU48zVxHkIgrdtVWI0vUax3ryNQ\nNu5qCNu8KAh3rkwCYWJi695GAEBNY7bVbQnUXu2o0ScKEZY6udCyLOSSZr+sdywaJlEvb16ewMoZ\nlpAmTHgK4ZBWrpNwn5XZ12Av27a3KVG9PTkFfaHZL8W9a7IyC6EdFm9Vlk7hw9suRg/J6hpV3sHi\nXPtdXbrVtkjnOcfxh/bEkf27oTyT0t4Pzbl8YHnUS52mbN5olQwjrASBcR+LG+9j8QxqynrtlmdS\nSKcYchbHPuc7GeWm3FpE1s1uFWmy1BEEQRAHFusLLPJrwnW/7AC/OEkmnKUizuR2gyPixOQ+b3HU\nNeews7bZt43JBbCmKYvqumbXpSzjvO1WC/+2Bc0JY7U458Z7Nsl7hB21Te7EXv4b8KdCV9vc60xO\ns3nL56opBHHvSknUSecUdauZXjCYxsVvqUvgfhkm6izu3kvBdfZ1klPVA0E3PMAbMw5PRMX5qsnW\nvCSlF2Sqax1RZ8rg6HRk9Q5zYWoxnvK5Rn0P8xbXXkMhevMWRybNUJ5Oua6fKnXNOWxQXqREfS+a\ncnlj/GAY6wp4YbN0W42b7VLFteRKY1aWtkVdTWMO2w0vQ8I4qn+3xPtkfJY6EnUEQRDEAcKHK3fi\noj9Nwqj5wXiNQhFzkI5gqYtKRrE/EKXpNu1uwK9HLQEAN7Yqm+f49EMf4hP3TwAArKiqxYV/nIR/\nfLRG28Ynf/8BzvjtBPezmMxGFfptLZbFpTpX8S7GyJkbcdGfJmHuhj3GbeIIiDPvfx+X/vkj9+8r\n/jLZXfc/f/Xc/ZhiqxMWh9+8sxTnPzhRsm7ay32WOo2LnQnTdTa9eJCbSyTqQmKa1lXX48I/TvIt\nE+JRWKrEpF1kN1RFiIrof1KJZhJRUbGJ252SC2EFtKMQ36O09GYqysXR4norlhAWzdk8GGNIMYYP\nlu/Ab0cvC2z7qzcWB1xNo45ru18mf5CZSm9E7TNznT6OUgha2UIqLHUvzNqI2141u3WaGNqve+Q2\nyjsG1xW5G4k6giAI4kBi1XY7CH3h5viJCKIQkzg1kcD+SEdwv4yyJu6QrHFCjOXyFqqkN+Ob99gT\n7znr9UJITH7EFXPdObNtq3prm3KupS7KvU0wf6M9GV2jqc8mBFjcq7p5T6P7tyxOTNYIwHPtnLzK\njtsT7n4ipq6y3IsN9LlfJsx+6S43XALZUpfM/dJ8TXVWOmExE/0T95hIbBNm+eOcR4owGVlAq5Y6\nNwtkhIAR4trkfhlH1AlrqxyrqCvwLWNZ+msoDtecs5Bi4R4MazVWzyg3ycZs0GWztfzwoqNib3t4\n76744UVH+eICBWVOTF2hyFZvExllQMXvzl1XHIcHvjyi4GN3BIpTCZAgCILoFIgfwGKKGzH56ggp\n6juC+2XUhE2eM4kt1bf7nvU03jGFmGtr98vdDS2u5SuutUFMEnXj0ha3nNqm6K8YS9EPEVMn31Ky\noEma/TJqud9SV5xEKQ0aK17OslCOlBdT50yiU641N3jd5Bc6SUsauMdVxExzzkKXsrRR/PfqWuZe\nG6B1oq6Pk+xGdiVUE4SoI543WOoEtqhjiZ+LUW6oTY4FsJgc3rtr7G0P6laOsnQKFref/bJ1X1jq\nCqV7jALmmTSDfNs2O/f38EN6FnzcjgJZ6giC0DJ1dTWG3D4aq3ckSx9MdGzE722SCdenHpqEKx+b\nbFwv5uat+C1vN6LE7N8mrcaQ20cXpf7bb99ZiiG3j068X5QYkN1cxemoAsmz6sS7KGICG5ZUoxjM\nXLvLtZCZJq9TVolnk22ZE4k6wibQnAMn/t843PjfOcZt4vD8zI2YtsYf+ySEg7AQCNEl3DDlbvnc\nL6MsdRbX3h9RiSmAeJa6X766EENuH43Gljy6lOm3l0WdEIriungxU/Z6IU6awyx1kMcjmapTX0wI\na7JO1A25fbRP0Mn9VpHH8/hD9RP/ygrb2ipbmeqVTIofKuUmLIsHrKqi5ABguzKnGXPFcFyinj1f\n/vv0opceSVIiY0i/bu69YHG/db+ilaKuW0V0Rly1/faIA95fIFFHEIQWUdvJ5C9PdE5SBVjq1u6s\nx+ItNcb1Vgdyv4w67cc/WA0g3LoRlyenrCtovygx4BN18Mc/ecttIi+Js769LHWyu5nJzeytBXa8\np6iJJiaQYZY6DjtRzIRl21vVv8cnrg4sE8In5bq6Opa6BmGp0wu5KEOkaaxNol5eGiem7qU5mwDY\ngr1HF71bm5wgpiJjT6jFdRHjLcRsOsxSJ3VSPA+SWuryFveVFRB9i3K/FJjGU74mA/voLVJdnfIa\nGWlcozIpWjz4XZVdhLN5DsaSezDEKb5djOeTTFkmfh9//6URrtC3OFfcL5NbJgUvfv9sdItjqSNR\nRxAE4cezruz/E3GieKguZMUgqatfKYk6byFM48Z7xSFJjFGc7eWvrFyQWkYIjZiaznWhKkailLD+\ny0XSTQkh1MQ7QkwUUptLEPd+15VGEJP7jCJqPEudXshFvTgxjbXR/VI6h7DrqrbLOdxU/aqFJsDV\naAAAIABJREFUr75FFnX2OjHOuuyGdvvRWSGB5IlS8hYH516MYm2T2VKno8VUT00at77dK7TbiJqJ\nsiDRuab6+suD2S/VRB2pNrDUAeHW0kJQ49RMDBvQHd0rMu5zMm8p7pfpVKAERlxOGtgrlvtlWulr\nWyd32p8gUUcQhBbxhr8jTMSJ4iEmGG0RU9cRXhDI5z1tdTW+/uRM7YS/mO5NcS0NgiRFq8XYq3Wr\nxDZxL4lIpmFKqrGrrhmXPzrZl9LfhHy+qsBrbPHWZfMcm3Y34MrHJmNXXXNgH3E/CTGlE4tuopSI\n2znORPnLf5+GWo11RkzUPUuVPYkUCTp87pdKnbr/9+LHuOP1hfjGv2di4vId+Ma/Z7rr5bGQMVrq\npMVhAre+OY/X5232LTNZ6uTMmELUibESLwrUmMawSTQHd8egrimHq/85PZDgRraGyufR4hTi7un0\n1bXUxXSFNrlfyseQk9rICNErC9jRi7aFHs+yOG59ZYFvWZ1Sky2VSm6py+ain803jZyXqM0okmRT\nBbxxCljqMqnYAlElxVisfdV4UjVbbWeGRB1BEFrE79yB9EAkvAlGgXV+tXSEjJICuas/fG4epqyu\n9sXmqJarYpDU6hdlVdIlGDG6X0Z8v8Ubd3G+pmv59oKtWLqtBk9OXhvaHuCfXKviQ47Zy+Ut/Gvy\nWizeUoN3FnoTaLXuYailLm4imBgi3VQyISjq7LaEAPRb6vyumG/O34oXZm3C5FXVuOHp2W4GTcAc\nv2hOlOItD8tSWteUw89e9ouNnl30FhBZhFSUCfdL+zhCTKnjrzu2fM+KMZi1fjdmrtuN376z1Lft\nH8etcP+W3Qhb8hYszl3hJdwQ41poTW6L8jjrYhF7V5bh0hMOAWAn4YiLxTkmrfDi7DjnPssnICx1\nsZsEEF/EFpPyBO6XgN8lWlgNLxk+ABce0z/0RXGFNP4jv3tWsN2QsRIvF8Q1OqRnF/zwoqPw408d\nnajvHRkSdQRBaEmYR4HoJBQSUxeFmHN1BHGXVywDgNJv5l9XDJJO0qIEt28CLdwvlZ2SFoQXQsX0\nOEhyZeVYOVWgyu6XWal4s86lVHW/DLu/ou691kyU61VRl7UtSuIekQ+tEzcm1OyKujZkfKIu5KWD\nrlZXD4Ooq2kyu1+qYyY+6wSy2IdzuIWxhZDcEGLdbZTuB2GpE1Yj0WZUin9B3tJno5QTnugSgtx+\n6XA3li5JOn71WDmLo05JrpJy6tQlQSdOD3NqBLYVca1r4lRcjw/Lux8eu+5UDOxTGdqWXLLgvGH9\ncM6Rfd3PUWPVtVwks3GKjXfJ4JeXDo/lstlZIFFHEIQW4X7ZGTXds9PXu/XYDmSmrKrGuCVVvmXi\nN7OYZY7EZFNuc19jFg+PX1H0LG0mXpmzCQs378W2fY34+6Q1vuQVMvLEWExSdX0sZvC9bpLGOcc/\nPlzj1pOTkS01czfsxi9fXejbTp5Meu6Xakyd/X+UpU5kmBTnW9OUwx2vL3LjxQLtSZOuD1fuxHtL\n7cQkTdk8/jRuBZqyed/5qolL5DilsYu34aOV1U4/PdS6h7L735hF23D3qMWYsXaXbz/dNRw1fwvm\nrN+N6rpmPDTesw4ljXGsa8rh5dmbsHybnSzomenrMW+jZ9WT7yn52j3xUbhV0+TqaqxTF2NfAHhy\nSvC4PSr07pfy9fFEnf97MWvdboyav8W14OkEpRBe7y6uwt5G+94RgjGsWHm9dD9kHUudsKaJ6zR2\ncZV2Xx068S6LXJ2lTk6OksR1UH2RkMtz1DfnfFbRFAvGJEZR2xQU5X26lSdqIylx3S/FKQuDZl5y\nv/QKuJvPt1dX/30oW0ajxkoksxHbVCSo1dhZOHDkK0EQydBM0joDnHP8etQSVJansfS+S0vdnZLy\ndSd+Z/0DV7jL2sZSJ97SyxPaNXh84hr079kF3zh7cNGOZeK2VxcCAE4e1BsLNu3FZ084GEf1767p\nq/e3sATIgsAVCUV0gdK5X26vacYD7y7Hq3M3Y8LPLvStkwXak5PX4d3FVThxYC93HH2iThxDsRC5\nn2LH1HmT6xdmbcSFx/THpSceErrPt56aBcC+v0bO2IC/TlyNTJrhq2cMcrf5yQsfG4+zcrsUa+Ur\n0+Ak6HCWpST3v/99zo4lemb6Bqx/4Ar3+dWkEXU3vzgfAPCp4QPwgZRqPmmtwrrmHH7x2kL387Q1\nuzBtzXT3s8n9cvzS8EycSd0veUxL3evztgSWmSx1Ml72S+d74XwH5mzYgzkb9qBfd1tY6Nwv5fvv\nP1PX+9aFuRPLMX0tOQsVZWk3Zkq0+dB7KyP7LlBfxqgukWVphm+cPRjPztjgWyZIIsDUR0TWslDX\nnEOfbuWuoC1WnPFBbSzqErtf+mLq8sikmCuOw8ZQ3GMC2TKaYgyXDD8YA/t0xeY9jYF9K8v9ZScO\nRFEX64wZY5cyxlYwxlYzxm43bPM1xthSxtgSxtjzxe0mQRDtjfiZ7WyJUkQ8T1TmsgOVtJL0oBgI\ny4Lcongju2ZHXXCHNqSuyUleEcOFTSC/3Rcioa3dL8V1UC1igL+PYmKrxmoJxJ9qEo242S8F6mQ4\nbmFwgfjeNbbkQ93lTN9LuZ/e/eQXd2oyGJnGFnP6eTWjZdJ7vz7iWWJKlBKFUdRFZAUFkluS46SK\nryjzJ0pRvwPiGqtxY0DhzxPZHbcl73e/tAzulGHI3zXL4mhoyfu+G+XpFH7zhROx/oErcOEx/QH4\nrXPCchTnd1G9frk8R11TDr0rPQHGCsh+qUNusy1ImtyEubHZHM1ZyyewwkSduk7OZMkY0KuyDFN+\n+Sn84+unBfbtWu6/h+PUauxsRH6LGWNpAI8D+AyAzQBmM8be4pwvlbYZBuAOAOdyzvcwxga0VYcJ\ngmgfdLEsnYEWJbif8GPKfsk5x4RlO/Dp4wYktt567pdem/172KnD1++q1+7TVkT1XSfqmnMW9jVm\nsXRrjft9SDJpnrF2F4Yf0sM48dKJOnEcnXgUE9kpq6rdiaNsCfFZ5TTnIy+Tx2PT7gYs2aqvN6j2\nQ7Yu2vdGuNVJvD1fub0Wy7aZXZ+FqKvIpHxjLFs0RP/FOKTcFxHB9sReaqFoGVVoJS2NECUsfHXq\nErRtrFOn9Le6rhnrq+vRXbK2JS0SH6eos7CivL9sB447tKfmnrA/N0hj/cbHm3HEQd0Kjlls8Llf\n2iJOTNbfXVyV+Pdp8ZZ9XtvZPJ5SakWWSUJA/ETILoBuMo5UKtJaP3Odv0h9zrJQ35LDkB7dfMco\nhrXOlOimWBSa/XLSyp3Y25h1k+zI6/THYcbP8rNKN2Zdy/yxlqrV70Agzl1wJoDVnPO1AMAYexHA\nVQDkdEXfA/A453wPAHDOdwRaIQiiQxE35qajkc2RqAtDDIuqBV6eswm/fG0RfvfFEbjurCMStSna\nkuezwqhSta+pwJ62DTpjTzZv4XvPzMGsdbvdSUZcS11LzsI1T8zAyYN6Y9SPztVuo0u1LibuOje6\nvMWxcVeD6z5r91sSDnJ7Gg2RkxKQyF+D8x+cGHou/j575//2wm2YtsaJYTN8rYTwmrhiJyZKGQFV\nhBipLE/7RI0uUYrqthpmqWtQrEfc4BIp96FY6O77OMS11F37xAys2lGH0T89T3vMOFSWx7fU/XXi\nauyqbwkUuBYWS9lSd8tLdpbNOy4bnqxDDo2KFbQ5l3etPm8t2Iq3FmwN3T+TYj6R/u3/zHb//mD5\nDjzsuG5+6bTD8fq8LThrqD8xh/w/AHztjEGYuGInThrYC3MM2VAFM9bu9n0WMXWyq2Q6lTxRiuC4\nQ3timRPHeUjP1iVKufqMQW4xeh2FZr/8heP2LvcviaVOJD9Rd9G1IbYVzyZyv9RzOAD5Sm92lskc\nA+AYxthUxtgMxpg2UIUx9n3G2BzG2JydO80PdYIgSo/4GeyslroyEnVahIhXrQFV++w6Ydv2BWMZ\notDF1ImJaWsKRrcG01F1lq2WnIVljgVL9DuuqBPtLdNYwMR3S2fFEN3QCb68xVHbrLgMGpJx6M4z\nn+fSS5vCkK/b2p3RLrRxM8ELodClzP+WPeUTdX5Lnfe/uV3VrVMWjKqlThUSrcWUKCWKuKJulePC\nrEugofK984dql8fJEChPktdV17l1+FTqNdk1dcvioF63bJ4HrEaXDB+Ax649Vbu/2FZ3flXSs+zy\nEw/F+geuwNEDvDhb5r7g8sb7shH2dkP7eda2uOTyHHXNOV+GxxRjxt9YeTsdN19yNNY/cAXWP3AF\nBvTUF01XEdur3HvVCaH7JXW/VF1K5fp/YRlE1Ws7tK89zurPhM5lVfRRvLitKDvwLHXFkrEZAMMA\nXATgWgD/Yoz1VjfinD/BOT+Dc35G//79i3RogiDaAlN2wI6OmIxnErqTHCiIOCVV3DCDBU/H3oYW\nX3ZR0da+xqxrMRGT27Yoc5C3OHbU6C2AUdpCK+rylvSSw7HU5c0T/5achWqnWLZnpQy2K97Q60Rd\n2LjohIE80c9HuF/mOddmq0xCLm9huzPGNY3ehJ2Bob45h9om/4Q/HfP71pi1kyqokzuviDjHNse6\nm7Us1DRl3eyFapxfQ0vOvW9VN19ZuKnDX+x4W4vb41W1r8kdsziYMljurG323TM9HMGyqy4Yf6li\nKjJuKroto7qz6eI9AX2M4aqI2Nk99S2ob86hRrlvVGsgEJz4H9q7S8BtTyAEhE7U7ajxCtrrvgbi\nu6H7JgqrZRI27WlAU9byZXhkIRkdB/QIF2pyvFmfVsbU6Uo5yJQltHqpzXWJ6X6prjtqQDCZFaAv\n2C52bckL98sD7zc+zhlvATBI+jzQWSazGcBbnPMs53wdgJWwRR5BEB0UL1FK57JoCUtdknpDBxJC\nD6gTXdctM0ZFsmuemIHPPPIRVu+o9bV596glOOt37wPQJ/goFv+eshZn/u59rK+2J/I8wnIlo+tO\nNm+5bbhukSEp4295eT7O+O0EcO65OeqOm3ZFXbhIC/RRsy6JqMtZVqtjZmev34Ozfvc+Xp+32TcR\nZww49b73MOKe8e6ybN7STsJ0cG7HMJmKPL+9cJvrcpa3OE66Z7xbGkAdx888/JH799TV/vgmWSyo\nbpt1zXoLVCF0LUuDc457316Ks3//Pn7w7NzY++oEDQDc8PRs3PH6IvezyFy5q75Zu72MKfYqVqIU\nZZK8p0Ev6lRBDwBrIqy5p/7mPZz/4EScJN03gN5qqoq6gyrLfQJHRlh0dDGDO+u88dKVBBB3oO4F\nZyHxWtc/abtLd6/IuCI0xZjxu9Gve5So8/5ubfbLqGQtJtFsbE85p67l8URdJsV8FsohffUWUV0b\nYtnQfpUAgNMH94nf4U5CHFE3G8AwxthQxlg5gGsAvKVs8yZsKx0YY/1gu2OGF2AhCGK/hrdy0re/\n4lnqOtmJFQlVvAjcbGYhqkjsu7zKFnP7HAuOPCkSLmJWG7pfLtxsJ0MQtcJ0AslkCdNt25LzLHVi\nt7AkCaMXbgPgj13THS+O+2XcPppEna5cgmVJiZAKdMBcstUe41nrdgeyR6pj05jNB97ch1GWSqFM\nmaQL6+QSKdGFKuJUl9gtexuNZ+cXdf524li84tKtIg2Lc7yboJaaICy2T9xjANDTsfxUK/2+9swj\n8KYSx2my1LmT7pD7Ti57wLnZUqezMO5rjBbKuvaac3kc1b8b7rzci8lTsxr26VZuvL/E3F8XM7ij\nphmH9eqCCT+7AKcdERQAqZBnXmusQD26ZFxXwRTzBNX5w/rhxMN7+rYLQxZOhdape/SaUzDllxdr\n18miSP0+RhEQdWXx3C8zqRQ+vO1izLrzEgDmBD66l81iTM85qh8m/OxCXPOJQYFtOjuRV4lzngPw\nYwDjACwD8DLnfAlj7D7G2OedzcYB2MUYWwpgIoDbOOe79C0SBNER6LSJUlxL3YHnmhEHk7tgHPfL\nYIFrJ9ZJay1qO0udiHcRljpZOIq7WSd2AP1b+RYpBs1dFiOmriVneen3NYcTExOt8GqF+6UpE6a3\nzHKXF/rSRuzPOQIucypNLflEFn+dpU5kVuwlvcVXLWw6oW1yL5UtQOoQqeKoNVSWZ2BZQXe0OIQV\nEJct5q6lrs5vqevZJYMjDqr0LTMJBTHRDrvveijZNXXZOXsYLH51SrxfVLyYoDlnoW/3ChwsJdpQ\nBRUDzJY65/rrRNjOumYc1L0cRw/ood/X2UU3JK3JrNhNttSlPEtdZXkah/fu6m0XkbxG/g07qED3\ny2EDemBgH/89IgTY4L7e8uTul/7vnex+GfYsSKcZenUtwwDnepvKEmgtdVK5iaMHdO90NXbjEOsq\ncc7HcM6P4ZwfxTm/31l2N+f8Ledvzjn/Gef8eM75CM75i23ZaYIg2p5OW9JAsdT988M1GHL76P0u\nhvCO1xfhrN9NaJdj+TIBupYl/zZyTJPg2idm4Lp/zXA/z16/B0NuH+1+zrvCLXhMMSFPkjji3Ac+\nwG2vLIjcrq/z1nr9rgacct943D1qcWAb0+RVpzFtS51/RZySBk3ZPE6+b7xxvZiXPPDuchx955jI\nfrjrNIf+68TVOPW+8fjVm4twa8QY5S3uiulCvZCFEOXgvgQduuYas8lEXVk6FYh5FSKyd9fywDJB\n3KyVP395Aa58bIr7WX0ZUV0X7cYYl24VGUxfuwvba5K3GVZAHACe+GgNjrxjtGt9Uy1d6RQLTH57\ndtWLKeF+eZgkKlRkK98eQ5KU/oaEHWqcXVQMl6A5Z7vuyqJMdQXsUpY2Wn/E91yXkn9nbXNoLNph\nveyx6K4RwoXE1Am6VWRcsZKS6tSVpVO+e7FSY6WSv0ayjjVdV5khfSsDy3RaWFhtZbdQnftll5Ax\nKNT9Uk1gZiqloFss+tvZQkaSQK+qCYLQ0trsePsrakzd799dDiB5CvC25oVZGwuaCBaCv66Z/b8q\ncl1LnbRs+tpdbip7wO6zjGhLm6zD8m8Thy17G/HK3M2R24kmm7J57G3I4uU5wX1MMWtG98sCLHU1\nEdkIxeRjxfbagECJstTpVu9pyGLkjI3BFer+FvcsdQV+w72Mpmarp6Axm0+UEKcsnUJ5wFJn7y9P\nsNXj6kSd7uxem+e/H9pK1A3uW4neMSbbJsJEKgPDg2NXwOJe8XTVxTGTYuimJEAxZbk8qn93/O36\n0/DgV04yHlNO8GFKJhOV3EMQt+5Z3uJIp5jPYiP//dNLhuErpw80Cgxxn+ssPvsas6GxaLd+7lj8\n+epTcMGwfoF1Osvf5044GIMOMotiQfeKjGvpSzFPoJSlU77ngC7OUR43WXSlUwxP3/AJPH/jWe6y\nI/t78Wj/+fYn8PJN5wTa033/haVOFkc698v3brkQd11+XPAEoSlNIF2fMM2lWlzNljpv+fhbLsDr\n//tJ95gHcrg8iTqCILRw5f/OgmupU3482iILY0dBjulS08ULvPp15nFS3fC4NPFXEZa6tnC/9MRk\ncJ2YUJhEne787EQp/mVxLHVRadzDJjdh49LaMctb3D3/Ql9qZ11LXXTynMaWZKIuk2aByZzn7ml2\nLS20FEFbibrPn3yY1hISlyj3S2FVM5U0SKVYwOIZluXy8hGHhpY2kAWqyYo4oIe/XpopMUuScUkr\n2VDlv6/+xCBk0qlACQyBuLamRB9hlrouZWl84dTDtW58OvfLc47si+MP7RlYrtK9IiPVX/Pq1JWl\nme9Fhc79UrZIqi7KFx07AIf38UTlVSd71ccuHj4gcG3s4wf7J+4ROXmKLpHKoIMqceGx+kz2qmaX\nY+rCajWqFleTRVdsNbhvJY45uAdOO6KPO44HotulgEQdQRBawibkpWDxln344ci5bmxNoZgSpeQt\nDs45fvbSfExfEz8keOLyHbjrjUXRG8bs2/efmYOVUjkAXRKNYpPNeReZG0SdeKP7r8nr8O8p67Tt\nqJYCU9mCv36wCs/N3Ojbpph452AeO5OoM7lfxlkmHxsITrLV+0SdKOU1FlPB+CVeoo3mnIWbRsbP\noqiSU0Tda3M34y/vr0rUhhhbzv3PiGdmbAhs29iST5QQpyydClhy5OMJ1GeBLltknPtLFSg7a4sj\n6srSqVa5gkW5kx7W256ki++dmnVS55IYN5ZY1205ntH0UqO/YqkzZdWMmw0VsEVduUHUCXe9rhE1\nyUyWwUKzRuosdekUi+wH4Ig6ZzsmibpMOuUry6ET4PJ5aJOFSOt7do3OaKoTQKaC3zpM26jtdpHO\nJewlkPq7bBJ1e517fpgUDyn6Qu6XBEEQCmH1tUrBT1/4GO8ursKG3Q2takdYGNQJD+f2ZPf1j7fg\n6/+eGbu9G56e7QqU1rJoy16MX7rdl6680KK9SchKEwlxudXLLv9O/uadpdp2VFFncr/80/iVbq2x\nKNc9t60EokAcT+ci5pZsMGW/NNap48qy6MLQdcq1e27mRt95qJMPncVU8H0pFf7yqhps3pO8CLzc\nR09kMfz8lQV4+L2VOPZgb4KkFwTeMnGeXBkZnditqmlKdP0yKRY4vvje+gp5q5Y6naiLcVz5PulW\nno5VxDsO5ZlUq6wGTRExdapVTb3fdMlDdN3RXWud6JLdL9XrfMO5Q3D5iEPwjbMH48unDXTT8ZvE\nVJKJd4ox9JPEoiyohMudaqn7yukD8a1zBuOaTxwBwOzGV2jWyLOP6ovLRxzi72eK+WLHTFSUpVx3\n0YpMyjuHTNp3v6qC+OozBuHQXp61TRebJsek9TRkOvX1WXMZhOBMpxje/NG5vsyjAPDyD87Br67Q\nu126fQvJfin69enjBgT2U+9FU6mFc47si2+dMxgPfHmEd0xyvyRRRxCEHvHTsr+IumL1QkzGVbck\nOU6pVOfsZkOUftiLNcEMwy8mxP9qTF30L6VchFpuI2w448SmAdETXP9x7f91ok6cq9lSp4+pUzc3\n9VtOs6+r1yVbONTJhz+20ftbtdbGcf0Mw5QoxZ+EIXi9v/XJIb42AGGpC/++rNlZF0tcCcrSQTHk\nJt2RLXVqohStiDcfV2QalMeza3naWB8uKbalrvD9G1vCr3OL8kJEjeHUiTXdddUlAtFuF+KaefmI\nQ/G360/HkH7d8NDXTsaN5w8FEBSRwj1Rbl8VDSqZFPNl8ZTFjHiOqxaynl3KcO9VJ7oJTYyWugKz\nRh7euyv+dv3puEhyP0wzFhCXR2uKZ5dL7qLdKzLu+XQtD4+pu/Vzx/rW60Sd31IXR9QF26iUXENP\nGdQb37/gKN/60wf3wY3nH+l80t/gwZg6b1xEVs2j+ntjIzZXf5dNlGdSuPeqE321/FKuqDtwVR2J\nOoJoR+Zv2ov3lm4vdTdisb+5XxYL4WqYSTG8MmeTu9ySC0WX4Jw55/jvtPUA/G6Ddc05PDl5LfYa\nCv2Gkbc4/vHhmkhr31/eX+26eql11aatqcbU1dWx0mmoMXWW5W9LR4tU2NvE+CVVmLl2d4weAGMW\nbcMip5ZZQ0vwvEXRcJ3IGDljAx7/YHWsPpqElWz11Anyxmwea3bW4dW5mwPCRXYnlA+nXr+wwudx\nyHOuLWkg6guakJNuyDFuUV+XNTvqE7pfsoAYEuMq30ux3C9DjqtLq9+lLI0Nu1rnDSAoz7TO/TIq\n+6Xqnqm+aNAJM50FThZrYQmyTHFrQFA0MeV/d7nrIhevXcCLqRPXyyfqXEHkb0NsEpb9EgD6xCyt\nYEL+nqY07pc6US/3pXuXjPucDFjqlHOyOPet14s6b1lUnTu7f2Hul/p7V15qur3Dsl8OcgS6/D0T\nMYphNeyiEPf2AazpSNQRRHvyhcen4nvPzCl1N2Kxv1nqikWzyH6ZZrjt1YXucsvSZxSMSxJLhI6F\nm/fhzflbnba85RNX7MBvRy/DXW8E0/JHMWbRNjzw7nL8cdyK0O1emLURj0xYCUAuPm6vu+5fM3H9\nkzNjWRzUSWWUq6NALSKt8v1n5+KGp2dHdwDA/z43zy3MrEucIbKfqvd1S87Cr95cjDkb9gT2yeWt\ngHAxWupyfkGu0pjN4zMPf4hbX1kQFC7SOIS5cSaxWurI+4qi+9edP6wf+veowE0XHBnYT46L8dwv\nEWlG31bTlDBRSiowYc0L98uQGnyqqOvfowJhIam6JBlxYqLiUtFKS12UeI+KuRMT5PuuOsFdpuvP\n/V/0XNiOHtAdh/Tsgl9cGrSehRXcVmOfdEkrvnDKYViytQYAQuvOqQhxeoizjywYhIhR23AFLRf9\n01+IONasMG7+9DD3b9VSd9vnjjXEvTH3+9OtIuM+k7qWp33u6HLB9MF9K9GnstwXc6cT6HKWyjju\nlzoB1LXMPq45Xs77+/DeXTGwT9eAtVX9/srnctGxAzCkbyV+cKH3jBHuqGHlDqJIk6WORB1BEHq8\n1Pal7YdAiI3WPq7FZFyNN7F465J25MJSesVAnqDlLcv9gaqutS10UQWedQhRoxMXKuI4YWUIkiLa\niIqba6tkMA2aSa+w7qh92ri73tiOxYPfgzjul7prZmeCtP9W25TvIXn865v959FaS10u71nqssp5\n9O1Wjtl3fRrHH9YrsJ88cZeLj6viSi1A3ZzNh4orlbI0C1oxde6XgZIG/oP06loWeh+rST2AoMWn\nNZRlgueRBF0xdZmobJ/iGfLNc4a4y9T+HD2gOy48xnMh7Fqexow7L8HZRx4EABh+SA/jvjJqzJrY\nVN7jz9ec6v79wJe90glRhbyFOK2QYr28dSlt38THKEtdHGtWGKcd0QefPf5gt1/Cqn7rZ4/Bjy4+\nWjtmZSmvHl33irT7fe5SlvY9A+Qx/fC2i1GeSbkvN8TxVGRLXZxEKTprrnC/NAks+Zy6lKUx5Zef\nwkXH+uPj1OE+qJsnMHt1LcOk2y7GqUf0cZe5lrqY7pf6ftn/d7YX0UkgUUcQhI911fXYvKfBFVE5\ny8K01dUl7pVHax/XQkCoL25l60UhtNZSJ++et7j75rmu2RYGhUwOhWNcnJefQlSasl+Wa9nZAAAg\nAElEQVTqTi+qgPCUVdXgnEda4lpyFlbvqMXWvYUl/1hRVYsdNU2B5bqYOhF3pF7r1TvMok53bXfV\nt2D+pr0AgBlrd2HaGvs7IgtUnfulLN7VZmWRIq8T94Agyi0vCtmNa0+DWrDavqY6l9gKjRWLIzg+\nagHqldtrsXZnXez+ZVJBt8WWvIWpq6vdFy/lSk0vHXLpBh39ugctdVGugEkoT6fbLGlDU9bCzojS\nC9qYOmWRyfVZjJuajdCE+ixgOlUncWgSS53TVkVaFOyW14XvIy5/meEYYXGCcREjmE4xbHGeYYc6\nhct1/UulmCTqylzxbos673ronq+RMXXSsh4FJkoRAjjJb04wsZZ/37DSEYB3nxXD/ZJEHUEQhMPF\nf5qE8/4w0f38n6nrcd2TM/H+sv0jFrC1NbqEZUKdNHLOwVthAIkSLlHIkytZ1AlhUMhPnRiqOAWm\nRfyZqcab7odSl2BB5tkZGzBuyfZIK2ZL3sKnH/4IFzw4MXQ7E5/780c483fvB9sNSSiiGkG2hAhK\n3cR3/qa9+MLjU9GUzeOaJ2bgun/NRC5v+URdnSGmTqBaKLO+mDrZ/dIv4gqtxyaQSxrsafALRjGP\n1N3NFZpJpi3a/efRr5sn6npUZGBxBIrG9wpxe9MlGHl+5kZc/+RMTF1li+fyTCryvspZlva+FZNl\nOcmCoJiizo4NbDtXsL0N4dZ73aRf7c/Vnxik3VfUwPvq6YN8yUBMqJY6+dCnDOrt/n3m0IPAmN9C\nVGEoHC4Qt504hnwOJuEhmhd9P/eoYAFxwFxyIQniFkunGC5xMjqeOfQgd5kO8XKiW0XafU6VZ1L4\n2hne9TikV7Cu3LVnHuH+rbu3GGOoLE8jk2KuYP22lOAosL3023CNcy+I69GaFxKqa2hU6Qgh5uK+\nRNAe02mjHaoA7be0/m4mCKJTIn6oROr5ldvrcMlxB5euP87/ra1rZnq7n+eltdTJ55WzuPu2VFib\nCpkbiiZ1palUodKoJEpR1xd6fht310e6XwrhmiSZho4kgl8VBKECMOS+2F3vWbqac1Zk9ktZkKkW\nN3/2S2+5miilXpMAJgl5y3KvpxqXJSx1uu+CzlWLI3jdKis8YdSjSwa1Gvffs4YehM+ecAhufWVB\nYF1ZmrmTwge/chIeHr8SVY4lVhyrLM0iM6fm80FL3ar7L8MX/zYVi7fUoK9G1LViThmgtYlSWotW\n1EnLVt9/mVF09OtegTW/uxwpBnzznMFaS71MwP1S+v/1H37SfX6/+L2zA/dWlPuluCfFMeLEXYlx\nP39Yf6y+/zKjK2uUlTAJKcbwhVMOx5UnHRZp7RLPqq5labdv5ekUfnDBkbjxvKFgTP8q7v99ehj+\n8eEaNOcsowCafdenwWGPU9g1tvvs/f37L43A/V8cgX9PWQtAn3jIhHqa6jGjSkeI7VtjqRP3Nlnq\nCIIgFITrnvDLV2uQNbbkW+0GVghxxEXe4qhtyrr/y4gHfiBTI/f/GNQ2ZbGvMas9nmhbJmlR9Jqm\nrE+EyM1ZkqgTP6zyT11LzjJaa+Tr5J1P8IdSPS3Rnqmsg07YxLkWLTkr0qKyeoc+62JDSy4yGYRM\ndX38otE1zjjVN+eQzVuh1y/sNHfVqaIu3P2yWnKZUzNoin2zect336oWGZ1baRJqm3LutVOFUcad\nGMVrS2epk4smmxJRpBgzTqgzUkkDBjs2Te1feSYVaqmyLXlBUVeWTrnJUHRJUYo5HbTr1BWxwYTo\nLXXe3/I4m/ZnzP4XJaTKFIEhJtiMMaRS3v6pFAvETUUJK9dSl44v6uQtdIl33O2KcoE8N3fGmFIg\nXL+HeJ6mU97LiQqnrqHor+4lity+qYB7t4qMa6WLusZMsXqmUwy9HVdJ9Tc/CerLDDXOVkXERupq\nK8ZFjEdrX7B2ZEjUEQShRczDe1TYk7J9jf7Ym+PuHovPPvJRe3cr1gP7/tHLMOKe8fjVm4sw4p7x\nShISe//Z6/1ZDi2L+4TLiHvG4+R7x+PXo/xZJxtb8hhxz3j8fswy3/IkVqadtc046Z7x+NskL32+\nLCpsSx1zjwf4fySvfGwyjrt7bKDdpVtrcPK94/HGx7arm7C26SYWqtBSLXWBmDrN+cUSdXkeaalb\nud2Ot1Jd8o6/exwu/8vkyGMIzrw/6IJp4tejlmBvQwtO+L9x+O5/5yAbci5hFkC/SMv73S81Fqqf\nvexZpgKJUpxx+t4zc/Dd/3pZcquUeMFCJltyQoibX5zv3q+qBUNMfkUNNxmdGyrnwYQlXTSFhlXs\nNPX6yaZc0sDi3JfRT44/mr52l3Z/wHYVNcXJnjW0LwDg8D7BcyzmfLA8XVpLXUYzQU4xhiP7dSv6\nscIsdVFEWuqYJ+QBc/IueahVIaMbi2KjE0+nSclAZE53lh/UrdznfqlDTlZjH8f+31SYOwm6Jno7\nz+GaBM8Z8ew+Y4h9XqqIjhLP4txNz4Q4iPEgUUcQBKEgLHXirbtuIlmsek5JiPPAfnWuXX/uhVn2\n/zpRp2JxfUmDl2Zv8n0WFr63Fmz1LY8SLjLb9tnxW2OXVLnLZIuJXTPP/lu42sm/iUIEqczbaAvV\nWevsmm6iR7qJpToOQtSJpeow6QxZcTJ+2pa68LER95ZuUrN2pzmBSWsRrpMfrdwZYalT3AslS5Sc\nrKIl4H6ZzE1SjOekFTt9y7fv84u6Qr53H912MZ785hnuZ1ELUc2kKW6V0wf3wTfOHhzZrp390myp\n66tJRiKOY5pol0mJUizunyAK0TyoT6V2X4FsqRugZLm85TPH4J2fnIeTBwYzfOqE682XDAssi4Pt\nfhm93Y8uPsq47rQjeuP1//1kQcc3xdS98aNzMenWiwpq04QpUUocTSu76+oQ1hth0TO53Q6URLr6\nzGtNqvwowrz9br9sOEb/9LzA8ruuOB7v3nw+BvapdF9U6CyWE2+9CC/fdI5vmTgTk6UuCbrfhkIs\ndQf37IKx/+983PN5u3yGfDvozl9FFJdvjSCjRCkk6giCMCCerWJC3hpXjGIS54Etfhi8FMfBdbp9\ndG2r24sJhZoiO0lJA9Gk/KPcoljqhMjw3Cyjf8DFNRIub5YyDjIBUdeiLz7ubq8ZmzinHMd9UiQU\n4TGuk0pSt1cZ+e1xmPBUDyHXXAp3v0z2nTEl29mmyeyZlD7dyjFEstCIbqqWOvkajDjcL3p0veMI\nZjeVx8eUICHFmDEmKJNmbhyoxXkgbhGIzlooaoHlOTBUsUylUwwnHt4rtuvd2Uf2jbWdSpnG9a1S\nUzJh+CE9jW30rizHsAHdjetFfS/dqeiEDGO2VWVIka11ppICcZI0RV1LNVGKye1/aD9vnNpQwxnR\nHbIsncIJuvIgmRSOO9S+7uJ8dC+1hvbrFrB2F8NC57aluXGE1S0qEY/K8EN6ulZX+X44qr/5/vW2\nse/HzXsKy4AMePcJWeoIgigZO2qaMOT20a51pVB+9Nw8fPs/s4rUK2/ylN8PRN2YRdtc64TJInbO\n79/H4xNtd0a5hhbgf8ibkl7YMXXmPjw5eS2G3D4a5zsZGtUfYNMPSUNLDkNuH40xi7ZJxxJiy/vh\nky0meamOmEiSIX7H/2+UuQi5sCKKSUCYpe6Wl/wJKhoiYupUF8QR94yLrKMFxLNW1WkSf8S931qT\ndVQ+R1OtPMaC1ptukmVhl+x+mfWLupqElrrHPliFU+4bH1j+0cqdmq31fQ1D7ttr82wX3WZFdPuu\nu9KeLi5m3JJgVlzZ/VInYgDhfmmw1Elui5bFfeclzuEwjXuor33GkLMs5C1LW4rBhO7FTu/KwgpU\n62LqhEVCRnU5k49XHhIPBgDHHGy75lVqzlGXdKItLVYyqQSWuqgMlELEeKJO/109RbK8FnrNCqG1\nEkJkYY2biVNYJIvh2ss0X0HxIkZ1h09y78gvLOMkPznReYHUGiub6355AFvqKPslQZSYmY6Y+++0\n9W4a5EIYLYmGYiCsDF6R4tI9KB8av8L92/TA3ravCX8ctwI/uvhoTY01SdSFuF+GxU79drQ/hk6d\niJnExcbdthh95L2VuHzEofaxrGCsW7M04c5LdcTqleyX/52+wdjHGtVSF3LJJiglKsRkWfRNtcKp\n4x7XtVCtsabdxm3LO4ZsnVHJW9ydYERlQAxD3tf0sqAikwqcu2yJCsbUFf49mbraHCMWh65laW0S\nlQe+NAKAHZvTq2uZTzCrwlz+rojbc/ghPXD3/xyPs4f2xf1fPBGH9e6KG/4z29gPWciZSgQwZi4I\nXZZmyFue++UjV5+Cl+dsxtsLtrrX7OZLhuGpqeuMfUgLS50VXk/xme+cibzFccPT9vnoHi+F1jJL\nsWBJg2e+eyZmrN2NikwKP3h2LoDgOIz60bm48I+T7HUhGTS/cfZgrKu23ZMrKzLus0IQp6RBUsbf\ncoH7kuGYg3vgm0/pXyTGOco7PzkPdc05rSCVcZPjOONkepn0408NQ59u5UgxhuvOCncd/srpA/HN\nc6Ldi5NQ6NA+8rVTMHHFjlgWLQD4z7fPxLQ11ehVBOGqux/696jAo9ecgnOO8luoP/j5hVhlcP1X\nke+9OGLwM8cfjAe+NAJXnHRoYN27N5+PPSG/B+5xnHM5gDUdiTqCKDXiocqLmnet9YiJtoi92V/6\nF8flT3Wlky0UoaIuwa+BOhEztSvEsJzxTWwq/6D6BIblZRTMuwIw+oexptG+ZmIS5CVKid5XiBHR\nN9U6VWh9wPrmGO6XzUH3y70N5h/xbN5COmVPBJvzhWeC9I+5/sYqT6cC4ribJFp2BUoalK5IUmW5\nXtR9arhdO4sxhm+dMxh/+cBL0KOKUPlchSX5+EN74pNOna/rzxrs1jQ0IWeVNIm6FDMnSsmkU0g5\n18biHOcP649De3X1ibrKijROGtgLCzfv07ZRlrJj6iyLI0TT4YJj+qNKilnUPQK6GqyNUaRY0A1w\nQI8u+PzJh/mWyVb/7hUZDJTiBcOSrXzh1MPx2AerANj3pGrPjVN8PCnHHNzDtQ6G4VnqzAc88fCg\nW6IONVGK6UVOeSaFG84dGqvNTwzpg5MG9o7eMAamAu5x6dOtHF86bWDs7fv3qMBVpxzeqmMKTPeD\nrv3BfbthcN94bruyi2gcN2fGGK6RavDJCDfVyGNS9ktyvySIUuPGfbXBXPCVOZvw0uyNBe0rJto5\nZbIfxr+nrMPYxVXRGyZEntQkiV0TyA95k3CzY+r0+y/STBxVUZd1+jVtTTX+PGFlYLk8gdUJNXmi\nktekYtf9Lj45ea3vs3C/FPu6deoY8PaCrXh2+vpgIwpu9ssi1ambsrrauE5M0oSLKQfw1JR1GLt4\nW6ilTn5T3xrLWFg74u0yYywgaCsly83OWnP2y/bGJD7kFwom65hAnqCKeZk6wlGZBOV+mIRbmjFj\ntr+yFJPq5fnbEeOb1ljBfO2nGDi3v39RlgJ5te7lla70QRx0ljodZb4XPtzXn7BkKxWZlLtv1/Lg\nO3p9TF07BZsx33+tQggE8YIgSVIqE20x7y9l+YpCiRPzWAjFSOKSFMp+SaKOIEqOePS1hSXstlcX\n4pevLSpoX/HGX4gSWQyZrDa/eWcpbho5t6DjhSH/PhTicy9b7kwTAs7Nbd/wdNDFSHXpEj8k1/1r\nJv48YVXgePJbc9eCJjWhZr9UU+zrfnxVl1CRlET0xYvdA37ywsf49aglvvU6xBp1m7aIU6hwxrDW\nTZTCcd87S3HTyHnYE2Kpk69ha9wv5ThGNeHKyO+ehe+eNxT9e1QE7gu5PEB1XQv6O9kV7Zi64o7T\nr688Pva2lWVev+T7U05IYhJSAvmdiZdoyH9OUWnHZffL684ajIuO7R/YJpUy1ycrS6fw00uOxldP\nH4hrzxwEAAF3W8bC3brEuqp9TW42PxOy0NHd5iZro+C2zx0bWHbi4T0xsE/XWCJKFXWMMTcmrDxt\n1w77wYVH4q0fn+vbryKTcq9zN42gb4/4uf98+xO4W3OPJompk9Gdh+BbnxyCr5w+EN87/8hkjWoo\n5uMsTlN3XDa8eAcsIm2lvdozplGQNjyvDiRI1BFEiREP1f31OZTP+60+gDmmoT3QHTrK/UUWASZx\nkre4sZ1KzVtwuSAyYE60ISahUe6Xaka3OJY6FbGLa6lD8DhAeP0hMQaqC2uh7pdhuJY6jTvf7npz\nH7M+C1vh96KcmVMV0ccd2gO/vvJ4ZFIscC16SwkEdtU345CeXQC0jfvluUfHz7zYRZoQy4JJrvMW\nZanzx9TpY1SihIps2epekcFj154a2EYt0gx4IiSTTqF3ZTn++NWT3e9emRtPZSdOYYyFWgNEWw0t\n+chYJVn8iFMVcYjqeh0/uvhonHqE35Xv3s+fYBfejvG9Ldc8G0QtuXKnIPUdlx0XcBesyKTdvums\ntO0h6i4ePgDfOS/o8iiOnFQ0lGmEvrj/uldk8KevnlyUWLJiTvxFU2FWrx9caC5bUUraqo5i1IuQ\ntiBNljoSdQTx2tzNPheq1sI5x3MzN7iucFGICdL++hjKKVYfoP1Fnfxjmde4X0Y9w2WXTZM4kWvD\nqahZwABg694m/H3SGqlf+p1F/Tef+6Um1k22OHGuE3X6H1/OOZ6dsQH1zblAOQLLm2342B1iBXPd\nL/P+xDFhCVoKxU6WwbySBtK6MEtdS85CTVMWz83cgHGtcPdtkoR0Lm/5Jtcp2f1SubR9JMsP58Ah\nvYSoK777ZZJJl5xwoqKsQEudL6bO/j/ps0l1V9RN8HTul+I7orMEepa6vDsmYV6gsmVcpEs34XO/\ndO7/pHF0qgeA28c4ljrpBZE4vhCiYSK8oszLrtlNevEkxq89Cm6bEIdO6t6nE+pt8dvY2ji4zkIp\nSj+0FeI3kix1BHGAsqOmCT9/ZQG+98ycorX58aa9uOuNxbjj9Xhuj677ZRs+iOLUCjOhlgcAWufy\nVgjy77xuzhz1Zk6ecJnqkVk8GMcm0Im6ddX1+MPY5dpjyAhRJ0+whDCVg8mjhLLpt/fDlTvx6zcX\n4/4xy9xrpF4zdWJpylzJJWGbs3hk0fDWUtOYQ5eytPYeC4upa8zmcefri3DXG4vx0HsrjdtF0dgi\nizru1vwCPOtWOhWcJKiuRYf2ki11xR2zJKJO7r+oFwX4BU60qPP6f45Tn+3bnxwSuw8AMLR/N/Tr\nXu66TuqESYoFl1918uHG7cU5tOQtdyIaZomSLeNqvb1AX6R2fvKpYcikWMAqNvyQYHKQo/p3wy2f\nPgZA8Lki+iZ38VdXHKc9fpnGUnfBMf3RrTytrXEmqMik3EREB0lF3kV77VW+QIcQc3Fv3+vPOgKX\nDB/ge3n12eMPtv/4/+ydd7wcVd3/P2dmy+2pNz0hhfQOIUHA0DEQpSrNhvoIFkSxohQLoDz4KD4+\nqI+IFX88dgWlg3QEEukBEkIIkEB6L/feLfP7Y/fMnjlzpt27e0vyeb9eeWV39uzMmdm9957PfL7F\n8Lfx5NkjcOKMYZ2e31GTh3T6vTru7PqgQKqVUwcAFx1zIOaPDa/ofcGR4zFrVLyCOVHIglDnBBRc\n2R9g9UuyXyNDrjZUobmvRAqejTuSuX+1vLm0bU8Ow/p1LhxC5hoF9fTKF4qeBVStMTbBjgq/jFEo\npRiSU2cSdWHHAEoCSQjhCmrVfZALf3XNFSWUg9ZnMvdx6+4O98ZApVCK/zil183HyhUqFUDzxWKi\nojSWSF58oKNQRP+GtCenThJW/XLr7g5PxcLOoodf1mdst7ecFEiW8Idf6t8H16nLFauee5hkXa6K\nA9WpUxfKYeX9Ae/PwJCWOqy+ZnH8CZQZ3q8eSy87PnSM0Jy61dcsdgv/mJqSy98xuYLjCjy5IL3h\ngwfj3pfW4w9L17jjpaB5z+wRGFTuAxaEurBdOKkVK799klsoSnLn5xZi7CW3ebbd94Wj3Md6TqZe\n/fG0uSPxHwG5YBktp07O+z1alUydbMrGmq2llilTFdGZSVnY01EIbO7eHVSaj8fj6tNK4a7zr74X\nAHDlqTOwZVcH7n5xvdGp+6EhpDcunflO76vUsp7J50/w55rqfPVE842OzjCif/1+/9nSqSP7DLva\n81ixfmen3lvNZZhccMRdEMs/4kFzeObNbV3OZwpzPaKIcuqCGsHWCpMgiXLqlr1VqV4Z2NKg6AQK\n65b66Ptfz6/d7hEJhaKDZW9tx/Y9pTBc1anLu6JOzanzn5cswAEAW/fk8Prm3b4x6pzlqbm95gJy\nPYJMwTe27MbarXtLcyw67uM4dPaOrxrmpl7+Lbs7AqsOPv3mNk9/uM7SphRK2bK73XM8oYTPvfT2\nDs/79MIb0ql7cvUW5Kr885DkuqoiSXXqgsaY6K50FNsSPoEpf3emDWGDKSVfRl4TKdxsS/iccnmD\noKUu+mfXFPIXVMQlCP33ih5+Ge4qhhdqCSKTstw+mGrZdynua+nCROEeO+EcKtet9+ebS+R3rQ8a\ndd1XDZV0CxR1ZJ/hvF88iROueyjRe2rx68xN1o35hyjnFiLxv+GRVzbh1B89il8+trpLc9oeUhhD\nxTSHvGF+3S3q1D88xvDLiL/6V9yyzFcZ0rSPIKcuThjTD+97BV/+03Pu8/U727H4h4/g6ttLFSrV\nhZsU/EE5dZIhiqh7cMVGtyGxilrhsuKy6eGX3vcE3XA47vsP4R/Pve2+9/gEP0+dWUBOH9GCOkV8\nqDcvtu/NYXCzuWrhNXe8jNWb9yQ+no4qwl9Yu8OY+2UJYIOWc6uHX7Y2lUTdPS+ux55cAZaAG3qo\ncvrc5L2lEuXUKQL5tLlmlydJoZRaIuB3DWWRDL0IEeANIZUhzVKMFR3gyHKFzQsWltywEf3rAQAt\niqtqCqEEzLrD1OMtjJPnlK63vDGgh1+G7S9J+Xf1O2Rbwu0nNmaQt7edfszjplYv3DAOndUKbmit\nUmSmmpWh1Rtl1eKE6aUw0PGDo5uHLxgXHo7YXZyRoC8e6Tsw/JLsMyx9fSuASthbEqq5jqlUYIon\ndvRKhSryLuwrnXQg9WN0ZlzebWlQ2abmf8mqjbXMCVQ/TZNr6SRoSB50LUotDczvlQ3Eo/h3+TsI\nwHXoJOpi2hR+GeXURSFQCRP0F0rx/jzIr+b/fuAgfOK3T8U+RujxEy7irn3vLJw2dyRO//Fj7ja1\nAmWu4HiKPwClkEjVXTMxZ3R/PPPmtlhzaNMqjsatINhfC78c2JjBBUeOx08fXIX1O0ol9K86dSYu\nf/c0TLviLgDAXz51GGaP6o+/PL3WOJfpI1qw7K0dvu1Jruu48qJy8tBmfPyd4/Ht21/2jYly6pL+\nHL985SLkCkVkUzYmXXZH7PcJ4c1lAyoOnanAh+lzsJTftafMGYljpw5FUzaFzxw7Ef9zX6mtSEtd\n2p1n0M2ZavRzu+iYifj4O8fj2O89iL25gtvwXM4xLBTSsgSeueJ4zPnWPZHH+e77ZuObp0x353zV\nqTNw2eKpHjEuP2P1vP73AwdXPd8zDDf8NOH7XIfcEpUiYlWa9vKrFtWkL9sHFozBaXNHoikbvqR+\n+cpFiW8W1Ipr3zsLV546vaenQaoMnTqyz9HToRryj1ncBqm5gl80SSouTLI/BHp5/KLjuNv019T3\nmPPVvHMBNKeuvMg2FdXIFYqxBGXccUDFlcsViq7Ai5PHVGmqbX69LVcIyTWLJ9DD+ump51cwOXWG\nY7RG5AIB3iR9OU/pQAXl1EmhPiCif1cSkhZlkI2TVZGhXqOOfNHnnNWlbY8bZWJIAiG8t8N7zU3h\nnqafPT38ckBj2m1rsG57GwY0pGFbwtMKozGTCr1Gw/vVG7cnua4HDimJuvqMHfg7Ix2xvwRplABK\nn0lzXTpSLMYhFVL90nQ+qlMHwF1UN2VTbvVhGTpdl7YDXcpqhClalkBjNuX+DtD7tIVVorSFQHNd\nvDL9tlUaK79bdvm46vV3nTrlOqZsK3FFz64gj5z00lYcTiUktUpzyqbsqnxPdYQQkYIOKH0HuzP/\nPAz99xPZN+gd3y5CqkiSQgWVfLbqKUHdLTGh3g3Xi1p4xpX/T7JeXrp6CyZfdiceW7nJ3fbEa5sx\n+bI78f17VmDyZXdiyeotnvfcv3wDJl92J55+I9jh8BZKqTyWbodJxE689A6c+dN/Rc554qV34Lxf\n+ht8S9SFgRSPEy+9Axf+X8lliiMIZb+9oPzEj/16Kb5+6zLja3oPsyDUhYg+JzXkUV4/dcHeYRDb\nQ1qiBYoUiAKVa/Ozh1/Drc++5X5//Dl1pVequcDp7LJYDcFTr9m6HW0+keU4QGPE4imJCNqbC+8N\nGESzlqc1oCHj5rCt29GGgY1+sRw1LbVypfd9AiP7mwWfjhR100eU8qtMAjjqDCcNjQ4hqxUpO9ip\nM2HblTw7nVEDSuGIcULiwj4b/bOO21RZFydhDo1lCXf87NH9A8eFof4cyfDVJGGd1UZ00qmr5ElW\nfu/vzyXqCUkCZTrZ5ygUHcTte5n0rnSs4wc0b/Yc1wHkTdQwwVBxWuL/aXzitZJge1gRdUtWl8IC\nf1gOSXps5WYcopQafnD5xtK417xiT0UVcqpTJ0tqB5XkV0MSw3j4lU2Br3kcMOV63f58qUdZnD/6\n8vMIK2Dzwlp/+BuA2MUv1HWbfnNBvX6yUp56Xqbwy7GDwvtrleZWcXNVYX3nC29jXLmBcUfBLF6i\n8quSEPQdfeCLRyGdsnD4Nf/0bJeXx9RsWGJyFkzVG0cNqMeaclGXJD8r7ZqoM7V6MN1sqUvb+OqJ\nU/CdO1525yQLa6zb3oYDDc2u9VBDnaDCJpYA/vGZI/DQKxvx2d89AyH80Qgnzx6BC485EOMGN+LP\nnzwMM0aWRN2DXzoa2/d6iySF/ag016Vw0bETQ+fZWR75ytG46h8v4c5lpZ9Zk/OWkU5dzJsNFafO\nf1IXLByP+eMGen7PBRHkat5z8UIMUAT63RcvxKDGDA6+6t7gfZX/17+HYQ6z/EGkCecAACAASURB\nVGrcdtERrhhNinoOvaKlgVsnJdkcpONlCVGTUElC9mUo6sg+R5Kbeq5TV8UbgW7lwVBR58Au/8Eq\nGFoG6PtK8nfRMix0mjV3Qw8zjKrAWXqPIuoUkbC7XPpbL+ldK0x35dVtQTlBbp5ZJ6YZN/xSXcjp\nQlC9PlJgep06/zF0l8CEdJsE9FYTlZ5zeh5awXD8rhL0HR072CxMpTseVmLf79Q5Rnfx8AmD8ful\nb4bOQ6cubfmcOr2MfemY5vfPUHqfWZZwWwjs6SgYw1qjxGaQUyeEwIDGjFvd0DSf1uYsJg0tFQE5\n+IABnu16XmbYDZBDxg6sWXjYqAENGD0w3HGUDl1UiKhEDjP9TkjZVixBF8bEod7CKpOGmgutqLgO\nVXluMhS6yfCznLYFcgXH/TkM60mXhExCx7MWdDanTrYLsYSo/CzTqCMkFgy/3I95+o2tmH7Fndhc\nhdLgvYmw8Mub/rUaJ1z3oG9sV/9m/M99r+Dcnz1e2md5gbF68x53m466sDK1DKiMK/2fxH2QCx1V\nVOoha/6eaqX/v19u5GwKFZIO1ydu+je+ceuL7nZX1EWErn30V0vc/Qcx9pLbMO2KOz1NoR9YvsHj\noEWJuqBiAG6hlIQK3hLBbqpe9lz9mM66wfvZ5w1ztITADQ+9ijN/+i+jqAtyb1Rknzoh9Ly9SjN1\nVbw4TqWpeDWT9vvFDEtzQ6rKpxtWOt5UjdIkAlVBFFeoZmy/qNvZ5q8SGySC9J9J9bPq3+i/FqZp\nqXMNc+pKr5fOcbAhzzLJxxh2vWvti0T9HpOCPW5YsHTRapEnVS32lCMZTGHDMo+y2o6UWyilJ/vU\nyf8TTkGKuqLjuPtg+CUh8Yj1m1AIsUgIsVwIsVIIcYnh9fOEEBuFEM+U//1H9adKqs1PH1yF3R0F\nPBkSctcXCcuLufyWZVixfpf73KmSU/e9e1bgsVc3l46v7Exu01GPFybq3JyoTjl1lW36Qtcn6jRZ\n+5VFU/DVE6d4FtAytO/OZevcqpxAxd2IcrP++fIGN/zTc2ztxPd0FLB2W6U/2rV3Lve8HtV8PGge\nRTf8MtmHnU3ZgeGXenGDsEWr3rAdKH2u3779ZTz52hZ0FIqYNLQJJ84Yphzbwt8vPCJ0fns7Stdf\nd+pyRcf9zNo6vP3z5PVSvxefOmpC6HGi+OSRB+KzMUL3pJCUn4KpKIZED1lzUMkXUsvTq+Ivzg2Q\nuy9eiGH96vDmFm9bhJ1tefzwnLm49/NHeo4pOWnmMPzzC0eWj+PdpyqWRhtC6EzzUnOegpw6+Rkd\nMKgRV582A7d/9ghceeqMyH0HMX/cQFz+7mn43HHVD7P80yfegd9+bEHwAGF86LJg/EB87aQpmBMz\nr+xL75qMS0+aihNnDE820S7yk/cfhLs+tzB0jPyVtKd840Cv5AoA/3f+obj2jFlVL2BiamnQ3UiT\nMKlglTeHduzN9Zk+dYT0FiJFnRDCBvAjACcCmAbgHCHENMPQ3zuOM6f878Yqz5PUgGoWB+lNJCnJ\nXYuIwTjhfeoUKy0NDIVSOpFTZ0ou1/Pd9KImus5pzKZwwZETPAvufNExXtuKqOvc98kkwtVFjr6w\nLxQdX2ir+jSob54Uc0kbuWfTliuW3newt7eP3tg47HNSr7l0/tTxO9vymD2qP06aWVmgZtMWZo7q\nF9rbqOLUCY9gLRSL7ndAdaTyithTRd2XF03BqXPMvc3iUJe2cMGR4yPHyXOW36Uwl8UkdOSC9Vun\nVIRNNqGomzS0GRNam/DqRm8z93zRwcmzR7gFRwDvd+t980ZjfDlfTr9Rooq6CTFz6uI4dWpO0vsX\nHIAhzXX44KEHRO47CCEEPnbEOHzuuEmx3xOXeWMH4oiJg4OPHbHAz6ZsnL9wQuwQ0IZMCh9fOL7b\nc8dOnDkckwN63unImy6mnLqR/etx5iH+foZdRf5M9WTzcfez7qRTt31vzt3HvrlSIaT6xPnNOR/A\nSsdxVjmO0wHgdwBOqe20CEmO/PsVt4IdoAof/3uefG0LfvbQqsTz0J2kmx5/3TemLVfAFbe8gN8v\neQM3/av0+uOrtmDjzna05wu4/G8vYMvuDnd+lii95/K/vYD1O9pw2d+e9/VBk8gFjipe9NA+GUr5\n16fX4O/PvuW7Eyrv8O7uiK4OuLs9j40723HpX583zgcAvhFQVRIwF1hxHAevb96NK//xom/R/78P\nvIrHX6s4oEtXb/HMa7chL6o092LgOYSRTVmuCNPnoue8LQ/pJ7j09a34+G+W4uYn3nAdS/Uz2rK7\nA9m05RHScqEf1uPqxkdecx+rwvHRlZvxq8dWAwDueGGdu/33S950v6P6Yrgri0DHifd+v1MXP6cO\nqHwGqiupir+46/vxrdFFaAB47sCozrVeAEIVlhOG+PdtmpfqpARXv4yeYrU0Ta01QC9p0dWtyJsu\n3Vk+Pt0LnDrROU3n9oDcTqeOkMTE+S0zEsCbyvM1AEzxFWcIIRYCWAHgYsdx3tQHCCHOB3A+AIwZ\nMyb5bElV2dcqSwmUFopJcqbCFvi3PrsWtzzzFj6+MNp9UNGdoMv/9oLvzvqfn1qD3/zLL/Z+8sCr\nmD6iBTc9/jra8wXXFbCEwJ/+vQY3Pf66KxKzKRuXv9tvmpvCL/WQROmqXfz7ZwEAZ2t3i4Pu/JtC\nF3e1F/CNvy/zhZqq11aKCxOmXDLHAb5+6zI8sHyjzw3b2Z7HuT97wn3+3v/9F+6+uBIKpedJVebj\nn1cQM0f2w/NrtwPwhl/qoq6lPl4emeSeF9fjnhfXu8/1XJGMbXuKG2TdJsLxnItcDJv467cuw3dO\nn1nerybqtOdThjXj5XVmoXrc1CGwhEDRcXDvSxtKOTAxfqV8edEUPPbqJiwuO5JhTp0u+HKFIv7z\njFn43t0rMG9spSCI6nL5hWrlZ+ETR07AvHIhkXdNH4Yf3f+qO+6IAwfjfMPPuvoJqYvkMKfO1F9Q\nhlre/PEFuOuFdWjPF3HWIaNxWrn5elCuW5BQvvFD8/Afv1kaOiaKn7z/IFx37wo0ZlOh7UxMXPve\nWdi2pyN6oIJnmuXH3zx5eo9Waaw2P/3gwfjFI69hRLkNhbwx1p094tK2ZWzu3p3oBWPics6CMXh2\nzTacv3ACsmkLT7y2BZ/sYmg4IfsL1cou/juAsY7jzAJwD4BfmwY5jnOD4zjzHMeZ19raWqVDk86y\nr4VfCjesK3qsnksXVKQkKJQviGLRiZWz9erGXcbtg5szrovmON7m43EdJrdQSkieWVD1S0mQeaKf\nW9oW2N2e91W+dBwnMLdNPw+TU1d0HPeO7Q5DmfmwfbbngsIvy05djC/I1acpoX0py32vLkD0JtRJ\nKTjesKxMyvK4clKsxKl30J4vxL6jbaq+WTqO9/nQljpcVc7fSlnCI/5bm7O44UPz0K++dA0cxBMX\nw/vV4acfnOcWjggTdXqhh7ZcEQcMasQPz5nrEXKqy6U7aGoo3yUnTsFx04YCAGaN8uZtXf7uaVg4\nyf93Sb2maql9/VqposxUxl1uO2zCYHzzlBm45oxZmDtGEaYBfViCrulx04bizHmjAo8XhxNnDsfd\nFx+JTx4pF83x93PmvNE4f2GyxbbpRuKHDxuLD2g3vfoyM0b2w/fPmuP+bIWFX9aKTMrqUZcOqPwd\nSnrzuKUujR+//2C0NmfRUpfGzz40z1fBlRBiJo6oWwtAvY0/qrzNxXGczY7jyBKKNwI4uDrTI91B\nLUNuHn5lI97YvCd6YBWQpxGrEXWMSoiO46AjX0yUg9VRKMY6vp7LIxnUmHFdBSGAPy5dAwD4y1Nr\nfI5W0N1tWSlSnYYv/FLLf3trW5u2b/OvBl28DWjIYHd73icm8sVgUffWtr3469NrsLMth1ueWYsH\nyj3yVIoOEvVrUq/5XcvWhY6J83mqC+lMynKL62Q1tds/oVOnUyw6bl8meSzVnZJl8uM4dbJnXxx+\nv+QNAP6S5/ph6tKW0gxYeMSDpd+Jd+JJAv17G9bSIB1x3lIQ1nmcOu+YuIvboBDXYmD4pXdckCiT\ndLr5eMglkJ9B9dbvtb3Rtw8ZcrGR4ZemQim1ImOLHnc/pZjrwbQ+QvY74vyWWQJgohBiHEpi7mwA\n56oDhBDDHcd5u/z0ZAAvVXWWpM/ywZ8/CQBYfc3imh8rSU5dwXGQQnh/NmlmdRSKqLPi3WXNFYqx\nyi+v295m3K46Yfcv34iNO0v3SjbsbMd193rbAQTdwZf9ujw5dZqI00v0v7LBG2KnuxCSPVqOXUt9\n2rcNKInGoMIpn775KTy3ZjsmD20OzEErFJ1EixL1ml9//8rAfQLxql9aQuAri6bg2rte9ghifeHe\nP2YZ/yCKjoP+DWlsKH/OWe0Ou3R/qn3XXQp//XPWv1P1adtdiKcs4VmgyTnJ1x04sZw6fUyYqIv6\nDmRTFjryRVf8mvYf98oN71dn3K7+OKvCLyz80kT0uSRz6oBKeF3Qz2tcZLXJD71jbJf2E4kyz86E\n/49vbcSqgBtivZWLjp2IL//pOQxp6T63afrIfjhogzkapLuhqCOk+4i8/es4Th7AhQDuQkms/cFx\nnGVCiG8JIU4uD7tICLFMCPEsgIsAnFerCRMShFspK1b4Zel/KXxMVR2li9cWkKNloiMf7NQ5IeGQ\n7nbFGWzXjquLp6gCcZ7wy7w5/FJWGlu/w9urMGjfezoqoZApSyBlCaPbmSsWA8/xuTWlXLW3lLYF\nOo7jGMMyg0jkzsYRdRbwyaMm4LXvLPacny5A5PWbOKQJIwJEgYlZo/phyrBmFIqOp39VNmV5wgXd\n8Msa3XXXwxv149SlbVdU2JbwOC3SPVRzOOMs4PQ8H+m2HTikCbNHeZsvh7U7ACrXR3XqdBEU1GNQ\n5TcfnR9YyEL9OVJd1KSiLipEMqhgTJiok4Vkupo7NaSlDquvWWwMP60mXf0W3/Lpw6syj+7kzHmj\nsfqaxcaei7U85s0fP7TbjmdCpnfsa7n7hPRmYsUDOI5zO4DbtW1XKI+/CuCr1Z0aqTW1qCiVKxTx\nxpY9vpLer27cZSzzHYc3Nu/B4OZMaPWw1zfvdkVAwXGwpyOPTTs7MGaQOYTPDcULuQZyMZckr64j\nwKnbvieH3Yog0sMh69M29uYKyBUcd/FXl7ZD88nk3fnl63Zi0lD/tQ0rlLJuexuWr9sZ2P4hKNxv\nd3tFWFpCIGULFIuOb1G5eVdH5II8rKJj0fEL0TDiRMju7ijggeUbPD3wgghaSOvnJHPqio6DtwLc\nV/N+LOQLpX5xaihsKfzSG/oJ1E7U6Q6gft51adsTfqm+LjWI2kIjTm6XfipSzBSL/vdHhZ1KIRXW\npy6qf2LpOPGuryrq/X3quhZ+GeTGhr2vsZynFeccewNdLbGvhwuT3ov800KnjpDug78hCbp+/7TC\n1be9hGO/96DPhTn2ew9iw874i16J4zhY+N378YnfPhU4plB0cOR3H/A8/+ivlmDhd+8Pfo/jdW1M\nmkD+UYpy6jwOXN4xOkHvvPafOOyaf7rPfaJOLs6U3mJRd3Zty8L9yzfgXT94CH9+aq3v9bBCKU+9\nsQ3v+sFDgaIxyKlT2wUUHAe21htNcsJ1D0b2rQsLgywanLpDxw/05J/p46O46V+rcd4vl0SOA7wL\naXXXevjlgHL4peOUGlPHJWNbsKyyeFXOc2BjxrNwlWKjVkUP9EW2/vzQ8YMUUWd5flNUBFd8h9x0\nDClcC47jEzDyvEeWKwnqVESdes3K+y0/iDOvMLGhfrfUGxH6e6QYf89sc6+/oGMcO2WIb98qYUK5\nvnyja68hBLo3MndMpThNZxb7YTeCqsHkofF6z5Fo9q0ybIT0DSjqSFV5fFWprP1WQ6nroL5qYews\ni4hHXvEX05DogsVxHDy+akvofp1iZWwQcZ069fWOQsEo6nTxpJeel2FUqig09ehSsS1gZbmAx0tv\n7wicP2BuGxBGUMiM2reuUHboio7jWzjnCsGFUtT3B1EsF6lR+fVH5+P+Lx5lLCgRJ6Ryy+745dfV\nhbS6bz38UubUFR0HPzhrLn77MVO3F+DKU2d4nmdSFuxyRdOOQhHHTxuKOz77Tpw0Y7jR4awLqZw3\nsLHzFTh1sShPb+KQJiy59DgsmjHMFSP1GctzXeRYN6cuQj3Jaxco6gxOXcoWeP4bJ+C+Lxxp3qfB\nyZT713sIhhHm1HmqX4aEXwoh8PTlx+P7Z85OdIyffOBgPHvFCZ1yY2VFRVNea29k4aRWfOTwsZ1+\nf1dzB8N47hsn4JYL+154Z29F/j7obGVWQkhyKOoIanFPzSQKkvSPk2wtL8Sb64ILUvjK9cc4jhwj\n1+uOU2p2qiJfi3Lq1Nfb8/EKpeguViZlwRKlc5FvT6fC/xhallDyFvyoYkQvlBI9P7MgU3PqgJIo\nCBJUUaIuzKlzHG+rg/q0jWzKRmtzFmMG+kNq9WqeKoObMuW5x1/4qovHIKcGqOTUFZ3SZzg0oBhC\nP61KZtq2XEGcL5QqYE4d3gLLEp6cOkldSGhfVLGWxhBBqIfNVqopCreMuBQbDemUFn5ZmqfbIDh0\nFpWefrp2ySjhl/prtiXQXJcOdK2lU6d+RvKckvQQDNNT6r7V74XJeRvQmAnMjQta22ZSFvo1pDsV\nWljfx0QdAAw29PCLSy37rrWEfM9IcuRPDSUdId1H99XYJfs0Yy+5zRN+dtIPH/aFIcXts6ayxRV1\n/q+q4zgY99Xb8b6DRwUex5TvpY6R4m773hxmf/NuXH/uXLx71gj3vUC0U6c2u178w0ciz0mfI1Ba\nvKZtC8vX73SbU0clmK9YtxN/e+atwNf/8dzb7uOkOTdBoZOf/d0znueWEL6m45Jzbng89BhhrQV0\npy7KxdjVHuwCS9GQpOCNumBX56kXw5B5VPLz1MWbRHddsykL2/fm3IbPh44f6L5m6mdVnwle8IcJ\nvtJ7bY/DGob8WVEFiLz0dRnbI35GDSiFRMYtUNSvPoVNu9oDC4x0FPxOXZBAkkwb0Q/PrtmOpmzl\nusvdJ3HqwsSCelpqn7qkAiMqn0y9YZCxrViFguR3ZW8uupdjb4OL/eozakA91myNzhnuFhh/SUi3\nQ1FHUK0/r7c/vw5ThlVyEv7+rFdwdKYwiwzjNDl1ciH9x3+vCTxOwXFgGc7PcZ0676TWKn8Q5WtR\nYiCX7/pfL1uURN2jKzdV5hjxV/GJ1yohplELzKThlx2FeCIgTGxFNQ0Pz6nzCtGo9fPekM9ILsTD\nxuio62/V+W2uS+MPF7wDQ5qz2Lqnw73u8vs0pKUOl797Gq78x4ue/emiLpOysF4prKKKl6EtdfjJ\n+w/ylEAPC8XNpi088pWjsbMtj/U72nx5g2EtA3SkE2XqR9eQtt3zXTBuoHszJW74pepqqowsi8NN\nu9oxobXROx/lg7/9onein+ZKfv0903DSzGGYrPzekefQEuLuS4Qo/b4IC+uTp/XlRZM9OZ1JTaOo\n0EE1FDZtC8TR4X0t/BKI/p6QznPLpw/HG1u6py9sFG4UCdU7Id0GRR3pNjrn1JUcGNNd96AwS49T\nFzRGijptTqr4cXPqcuGCSM+P6wxClBZyW/fEv+OunmfU383ETl1MoWoSdYdNGBTo3sUlqVMX9hlJ\nUbO3owA7JFxURRXJ6nAhgPnjSq7aWDTi7e17fWMOP3CQb3+605bWmgPrjtSJM4d7nodVVqxL2W6j\n9qnDW0LPJQo5VH2LFHj1Gdv9nh01eYi7Xf4fdVllpdAdWpjzuMEVIae7WaoQmjbCf251aRvvnOgt\nwy/nE9ViQO4/74T3RJQi5LAJgwPnFoeo4Wr4ZTplIY6qq0/3rUIppLYMaspiUBfCW6uJW/2yZ6dB\nyH4Fc+pIIM+t2YZjvvcAdrVXJ7SnKzl1LQZRF6Sl1OMEjgloaaCGPLk5dXnzgqktV8DCa+/Hsd97\n0HyQBFhlpy4JqjiJurJxGm6rxF2vmhbDjQEVKpNw8e+fwf3LK8Vx1MW+6WsU5qbKYhptuSKGNsdb\n8KinpQp/fSEvF+JNyvfTVKlSz9XJpCyP2Ipq/xD2+sCm8EIpScrImwSgvLb1GVsRcP4PIeobJpt7\n6+HMqgtfjYr1SQqOyPMNr35Z+t/X/iHmcaTLGlUwQg2/HBSz+I282ZWJIWB7G3Rw9m0qLQ34QRPS\nXdCp24+JWoR9967lWLVxN/79+lYcWYWmtJ1x6na0le7qm5yKIJGohvcEjzHPSRV1ToRTt3LDrqqF\nuliW362J0sBJhVoQDRnbE7712WMn4tS5I2O91+RWVKP8/uubvdc1agFtyntsyqawqz3vXteOQhH1\nGRtXnzYDl/71hdD9qeelfod0wdDanMUV756GE6YPrczVcE184Ze27SnuYiqOopIOWbRfrVXW1Eny\ncZg+T+kC1adtY6ilPN+osLqvnjQVrc1ZvEu5VpIfv/8gDGrM4Pr7V3q2d+Ybrp7vdWfNxoGtzXjP\n9eZcV3m+oU5deRb6mLhi+R8XHeFWBQ5D/bn59UfnY2dbHs+v3R76nukjWnDJiVNwesyf194Aoy/3\nD1gohZDuh6KOBN4xlYuWsIIWSehMg1zpEuYNlluQSFQPExh+KfvTaa+rIX9yTJBTZyqt31lKOXXe\nDyLqsnucui6slPrVpz2i7uLjJ8V+r2kx3JkGw+MGN+K1TbsDwyOjbgi0GYR3Y9bGrva8J6csbVt4\n/4IDcPVtL4XmIQW1NDDddf7oEeM8z01VDOu14ifplPD8PES5tOkAC2vhpFY3rDGIzjh16tdJVjxt\nyNiKgFP3D982E03ZFD53nPm7dVI53NQn6jrxvZafkQPgtLmjQsfarlMXPEb+6vG1f4h5XSe0NmFC\na1PkOPm9GdGvLjScVkUIgU8cOSHWPHobUYWgSN+m0tKghydCyH5E34vZIN2GXMPEKdEveXndzsDX\noppRm5DNrk0l64PEproIv/GhVeYxsvm4dm45Q/hlkFPXGfEShDCEX+YjRLBprpKocD6VoIqNcTCJ\nurDLElReXzpZQQtlVWybPvXr7l3h2ybdXTU0TeZZRX2lg5qPxwnts0195jSnOWtbns8vExV+GdHe\nIowkX1NLEUSSveXvf71S/VLPMyxt6/rNn2r8TCUKv5Q5hHE+V1/4ZaJpRe/f9l97Qvoq8TO+CSHV\ngk7dfkzUGkwuYqJckrh303MJKzACFacuZ3JvYoRf/vCfK3Hx8ZN8Dkul+qX3vaZCKUFOXTUWsRJL\n+EPwkvR50+dSn7aRK8TLhYzqc2binPmjMWNkP2NBlKDLMn/cQFy2eCp+eN8rWLHeG7oqq/hZFgDD\n5U7q8rbUpTC0JYs3tuzxCFwZpmn67H553iH4yK9KlSOtAKcujjtj0ge6U1fqUVd5Hhl+mSDf8psn\nT8earXswakAD3t7ehvteKrXIOG7qUKzZugft+SJe27TbHf/VE6e4Yc6mw7xv3ijc99J6fPTwcRAA\nHl65CecsGO2+/tEjxmHJ6q04Q2stcuHRByZqKwD4r11Xwi/V3wNnHzIaC5S2Ee7Y8uCwz1V+V3QH\ntpo3dYDK0ndfD0/cx0+PlKnk1PXsPAjZn6CoI4G44ZcRq4y40ZmmEMoodrWXVvgm1yrQqdPmmy86\nPudK7i6s+qXcTZBT14lo0kAsIXxuTZSzqffjU2nIpCJbCkham+tizrLCFe+ejvqMjSdWbfG9ZroJ\nMKgxgz9c8A4AwI0fPgQPrtiID//iSfd1KXqCFtfqRxpnjXDTxxbge/eU3DvVqZPiUJ/hD86ag6On\nDHGfe0SdcvA4CxTT11KvxLh+R7vneZRoS9KY+sOHjfU8v//lDQCAAQ1p3PjhhQBKfSUlFyjhe/K8\n1VDDwU1Z/OmTh7nP//qpwz37H96vHn/7tHcbAHzxXZNjz1lSjaIKJrF1zRmzjGNj5dSVP0/dgU3i\nCMah4pLuH7KHi/39A37MhHQfFHX7MVF/VOUi444X1mHRjOGB4+KKtY6E4ZePrdyE1WVHQQ2/3Lyr\nHS+9vRPrdrQZ3/egUjURKLkzW3d34NWNFXei6Dp1evilUmQlIqeuM4VfgjBVv4zTfDhorKmBdRCt\nnSiBLYWSqSiKyUHVw9t0kS3DL4PC4JK6opmU5QqpjBL66F4nbXcpbT6qhlIdnzgLeV1gW8IvVtZs\n9RaCiQy/DHg9zoJJHjrO3OXPfJX1Smx8Tl0nfsRMIaSBY2VOXcgJy++efsOh6k5dzNxEQvoGzKkj\npLthTh0JXETIReAtz7yFp97YGvj+uAZckvDL9nwB5974hBuip/aC+8DPn8QHfv4EvvjHZ43vvfGR\n17z7yhVw8vWP4pyfPe5uk4JMF2btCfrUVVPUCeEXFklCDvU5JilxPiikJP7YQQ3G7XbIYvjsQ0b7\ntunD9IbYE4aUCkkcfMAAz/ZKw+r47RuAkvMlRZ0qiGT/vc8eN9EzPiy0Tv2c4yzk9es5Z3R/AMC5\nC8a4296rhSo2ZMLvr80Y2S/yuEG4Qi1B3li1Xai46OJ35qj4512XtnDa3JGJ5u42Ww8ZIz99fbfV\nvkTyu95XC5/Epaui9YBBDThsgr8XJOldzBxV+r135jz/3wNCSG2gqNuPkX9cg3Li1EXgBi1cTCWu\nU5ck/FIvaa86dSvWBxdjMdGeL/pcPSkS9FPPFQzhl0FOXRVvqduW36lLJoK9Y3WBGIbeQ03lgS8d\nHfpeU7jksVOH4jwtBFC/VHoO2bFThmD5VYvweaXy5jfeMw3fOX0mgPghvpKMbVUKpSjHkk7dp48+\n0HMHWXfCVPGmHjtOaltDJoXV1yx2n/+5HLr47dNmYvU1i7H6msU4ZY63BP241kaEMbSlDquvWYzR\nA+ujJ6Ah9WocESLH9JioUx5ff+5cjOwf/3xfvvJEXHfWnNjVOIF4ecPu70ftklT7GtWlbay+ZrGv\nmuq+Smev3oNfOho3f/zQqs6FVJ+R/eux+prFOHaqv4UJIaQ2UNSRQOdDXwfn8wAAIABJREFUXbPo\nzZ037Wp3K1PG1WpR4Ze5QhFvb98LAHh1wy7fa+t3tKEtV0i8GDD1MCs6pXPSxZ6pUIrugu3pyGPj\nzvaqh1/q7lWSaqG68LQNOVhBIXwJ9F9sopxCfS6psghTxVTKtjrd8y6dEsimpVOniLoAoayLzKg2\nH0mIkyc2YXB0yXvA3+8uDnLOsYq8lK93TzUMVq9vZ0vex20KXhpb+j8svLei6bz7ZVPlzrG/5AwS\nQkh3Q1FHAhc06iJwrybq5l11L979P6WGvnEduCjn6Wt/eR7v+M4/sacj72vqnS86WPDt+3DhzU8l\njtE3OW2FooMP/eJJfP8ebyn8joJf1Ok5daf96DEccvW9NQ+/TJJTpwtXAb8zE1SMI8kiWCdogRbV\nUkEXsHK8+tlmbMs45zjVVtO2hXT5vNT8wiBRl9auQZB4q3YelaRfzAqkE4c2J963MIRfBollU6GU\n7kStUDl2sDn0N4rmutK1HN4vugDQsVOGet5jHDO1VEAnKE/16MmtSae4XzNjRCmkdnoXQooJIYT4\nYaEUEhjapi4Ct+/N+V6XZdHjipuoHLE7X1hXGpd3XBdQf++9L20oC4L4gsq0kC86Dp58zV+5UZ2j\nNMp0p255Ofyz2k6dDBc8anIrnli1xSekw9BFnW0JpCzLIwxLAsm8z2euOB5zvnWP8bWnLz8eu9rz\neOe19/teC9JXGdu7ANaH6c6YzGlTRVM6JSLDSK85fSYu+cvzvu1p28Km3R0AgLGDK6GNQUJZn09Q\naF0twhKXXHpc7LH/ecYsjB3UgB/d/yqAeEUI3JBKZfBTVxyPgsEJjlMNspacd9hYHFcO1xo9sHOi\n7qQZwzDyk4dhyrBoAXzZ4qk4f+F4DGwMziu9+rSZuPj4SWjM+v9cPvG1Y7vU53F/5LhpQ/Hwl4/u\n9OdLCCHEDEXdfo3MKwvIqVPWdVvLC2QTcXPL8hEiyF1wC78zuKdDeZ7YqYvfDsHb0qB7+9TJwh4D\nGzIY1JTBmq17Y7/fKOpsAfWyBYVEOg7QvyF4UTugMZMoRy/sWBLdyZPX3RN+aVmRpfzHDTbnomVs\ny71+E1qjQxt91S+Dwi9rIHZam+NXH23KpjB39IDogQqWQai1BDhTbjXIHgotFEJ0ebGfsi1fwZ2w\nsSMi8vbStoXh/cxjhrYkbwdCOi/YCSGEBMPwyz7KCdc9iPf+5LGq7Cu4+mXl67ElRNTlY+Z+BYW+\nufspC62fP7wKP3vYW8Fyr6JOEufUGapXnnXD44aR5vDLoOqXUSI1CZao5IClbJE4/K1dE8G2ED63\nRQ95lMQNZzS+N3B8svBLKQLVKadty7gf9ZjZgByztC0wuOy+qBU8g6p5psvf9QnlgiVqvtQYZQGa\n5GOJaivRXW6YPEwcQdrThVIIIYQQ0jno1PVRVqzfFT0oktLCLTCnTll3h4UCxnWsosIvZTjjD/+5\n0veaevxq5NQF4SmUUn4Y6NR1QtTZljCGbQol/DJtW7EdoevOmo1L/vy8TzCXwi81URfk1MWct/G9\nAW/Wm22HVb+84YMHY3I5VE4VU5mU8IVF6qjneNniqbjqtpfc+f7X+2bj2TXbMKSlDjd/fAE27mzH\nOwJKoUun7vcXvAPL13mrq/7pk+/A/KvvK+03wZfvvi8ciTe3BLutD37pKKzbbu61GEbS77+bUxfj\nfW6rCmo6QgghpE9Bp44E5tSpC3FTCKMkrmPVFWdLFUJJq+KFzV0nTvVL05yCaNbycIIWy7YFpa+a\nFVs8nDZ3FGaP6h8QfmkuRqITR5MndQ6ThF+eMH2Y+1g9TCn8Mvy4qoOols4WQmBAYwZHTS4VuThs\nwmCcMmckhjSbw+XkfAY3ZXH4gYM9r6nvSRJ+ObxfPeaPGxj4+qgBDZg3Nvj1INTPK85sTDl1wWN7\nNqeOEEIIIZ2DTl0f47p7VrhhenG49s6XMagpi11tebTUp/CRw9UeSKXVYZDTpooWKRou/9sLmKlU\nLfvHc29hUsyKfKpgWrJ6C877xZOYO2YAPnX0BPzvg6vinlJip+Ifz70Ve+yGne148rUtuP7+lXi5\n7NgEOXVxRKouAkqLZv/76tK269RZhtDJMNIp4XMjUwmcujgElW8Prn6pH8uJeL2Ep1BKQPVL734q\n45O4aEBJEMlZReXumebX14gjSOXpUdQRQgghfQuKuj7Gf9/3SqLxP37gVc9zr6grE6BNVNEic7Zu\nevx1z5gLb34ad3z2nbHmooZfXnjzU9jdUcAjKzfhkZWbPOOE8LoRlvC6iUmXm7c/vy7WuCnDmvHy\nup3407/fxEMrNrrbg5y6oEqK1587F7c88xbueXG9b3FsEgXvXzAGXzxhMn6/9E0AJZGdZFGdTdne\nQjIoLeB1QRTU4yypf/qbj86PfLN+LL3nXhxRlwmqflne1TsnDvYUSumK3opbCCapcOwNyJ+lOHOX\nP2fswUYIIYT0LRh+uZ9hKoqRxKmLGheGWlAl7C36clJ1mIQwLzhHRlSwi8PcMQNgCWC3JpD0xusS\nvTiJ5B3jB+HMeaMB+EWcSatdungqBjRmPMVDkoi6+rRf1NlC+PLaGjLmezhxCqWoLJwU3Zerqc57\nLD0nM+j8VMMsZVluARMTFx8/yfNdSOouCc0VjENMQ6+mJNVb8tON49TJPNGe6lNHCCGEkM7RC5Yo\npDvZtKtSxVKu5YMEVj6GqBOic33qkggJGZYIlASfabmpC5jOsKs9j8ZsCrc997Zne9C5B7mmtlXJ\n+tO1gmlhLcWI/D9p/7s6gwNn28IXpttk6LPVVYJmqvf0iqp8KtHDL8McNN156krIYFwR09vCL2M5\natKpi3GO8me+LzqShBBCyP4MRd1+xvod/mp7wU5dZSEeVEHyoDEDYhdA8bYLCB6nL1TrFHFiCWFU\ndV3JF5PsbMthZ1vet709XzSK0KA+curiWRcBX3rXZP94WZ3QqlQjfW7Ndvf1i4450PeeEf3q8IFD\nxwAA6jP+c7eVapqSxmxA+GUXOjOo1+WYKUPc8+usgIwVfllGXuejJrfi2vfO6pLgiqqyqR+zLxIv\n/LL0eTL8khBCCOlbMKduP8PkAgWt6fMFB1OGNWPaiBY8sWqLcYxtidgtDbzhl/GVRGMmBaAdQDn8\n0jCmOqLOL+gk7fmi0REzkbIsN0xPdflOnj3CU2RGopeR1z+iz58wGY3ZFL5zx8vutktOmoqTZ48A\n4M1fe9f0obhrWSmXL3b4ZeKsOj/XnTUbp80d5T7Xnbq46NUvw8Iv5XX71UdKOX5hvRSjiOqrV5lf\n3xM78vONM3WGXxJCCCF9E4q6/QyTqxYUClkoOkjZJccnKASxPV+M3XxcDb9MEmKoCoSgdgZxc6LC\n2NmWC3ytPVfEU69vxYgYuXuWVZnnno6KUGzLFYyioNJHrOzUGa6N7iSp+XeqqJNvtYTwCd0gUdol\npy5ge1OAgIzCk+eWigi/9BWh6dQhASSpftn5Y/QUTifCL5O0biCEEEJIz8Pwy/2MvKFiY1AT7XzR\ngW1ZyKaswPDL9lwhtkDr8OTUBY/T99eQUXLqAgqlZKog6s46ZEzgays37sS5Nz6Bo/7rAd9rc0b3\n9zxXBcLYQZXqjO+ZPSLU6ZHhcSYXU3dORvSv9E6rU65PZQHvzzMMqn552IRSX7bBTRlMjtmeQj+e\nLraDQj11jps6xPNcPc207a/gCSiFP/QiNN2QU9cbwi/V0z517sjY4+PMXd7g6cppDm7KYNLQps7v\ngBBCCCGJoVO3n5Ek/LJQdJCySgU3ggpddOSLKNQg/PJ9B4/CvS+tx9Y9OU9+VknU+cenNQHz7dNm\n4mt/fT7WvADgte+cBCEErvzHi57tGdtCR6GILbuDXbwbPzwPg5uyGHvJbQDKC+LyHIe21OHOzy10\nx76wdrthDyXkeZk0slyQnzJnBK48dQZa6tLua16xVi50YVm+nDo99+6SE6fgE0dOcJ8vvez4wLlF\noX8mcXLUVl+z2LfNUyglovm4fszOFvdYcdWJsQVhb8o1O3pyqxuCG4Z0aOOEjhaqEH7Zle8RIYQQ\nQjoHnbr9DBletbMt5zbVDq5+WSznZpXCLzfs9BZZSdsC7fmip6BKGDlPoZRwUVefsV2x2aCFXxpz\n6vTwxIQ5dkGLdVmkxeRwSnQxoe5LP8uwhbUV4tTJnC9bCI+gA7yiLolT15WwS3cfXd+FB0sLvwxz\nl/RXOuui9SKdVhPk587wS0IIIWTfJdbKVwixSAixXAixUghxSci4M4QQjhBiXvWmSKpJvizAZn7j\nbjy6cjOAiJw6peDG/Kvv87zekEmhPV9AiN7xkItZ/RLw5n81ZWOEX6aE9rxz9ytmjfIWMpHFRXa1\nBxdRsQ15X3KLfm3DBMTYciPtGSP7+cLfXLFjeH+9En4pr1vKsnwtDfScuolDuh4iF9WaYkBDSYAO\nbsrG2p9Qppy2RSJnLGkRk6Mnl/rtxXnXgnEDE+27lgzvV8rrnDtmQKzx8vsRR6dNKH8npo/wF/Qh\nhBBCSO8lMvxSCGED+BGA4wGsAbBECHGr4zgvauOaAXwWwBO1mCipDqaiJkGuWb7ooC7tr6Ioacqm\nsGNvLoFTVzlOlBhoVAptqFUbBcyLUz33qrM5djd//FDM+PpdyrFLC+KwypimsL8gMRImPA4+YADu\nvnghJg5pwulzR2LulffEmrMq1uaM7o/bnn+7VCjF1sMvK8/v+txCTB6WLH/uya8dG1iQxnS+j3/1\n2FJj9FweDel4kd56+KWJoO9OUqfu+nMPwvodbbFCRX/5kUOweVfnq2tWk6nDW3DPxQsxoTWeKJff\n4TitR46ePAR3fW4hc+IIIYSQPkacle98ACsdx1nlOE4HgN8BOMUw7koA/wnA3wiN9BrM1S/NYys5\ndeaiFw0ZG+2FYuw+dUmqXzbVVUSAp/qlMLcf10Wc7lLFRe+vVh9H1BnERMWpM79neL864/ZJQ5sh\nhMCAxoxnu9yNKfhUipyjJ7e6At22/NdAzYtMKugAYEhLXeC8TAzrV4d+DWkM71ePfg3pkJEV1EsZ\nFQKoC8mkEYN1aRsHKIVswmjIpDB6YEOyA9SQiUObY4dI1pcF9d4Oc7EjncnDmntV7iAhhBBCoomz\n8h0J4E3l+ZryNhchxEEARjuOc1vYjoQQ5wshlgohlm7cuDHxZEkwZ/zkMZz/m6V4ed0OTPja7fjm\n35cZq1p+6v89hc/+7mnPNjns+O8/iEv+/Jy7PV+oVL800ZBNoSNfxIU3P218XSdJ+KUactnoq37p\nH6+HW2arUA0TqOQjhbU7MIk6KUqHtnjFm6wiOj9pOJ+sMmk4d3lZZ4zsh371JfHU2pzFsPKxR5QF\nZIIuErEZ2lzad3NddWouxQmhHDWgJK70z5xCxIwskBNX1BFCCCGk79HllZgQwgLwfQDnRY11HOcG\nADcAwLx582qwxNx/+ffrWwEApx80CoWig9ueextfPXGqcewtz7zleS7dnVc27MIrG3bhmjNmAag4\ndSP6mXuzNcUsWy/JxexnB3jdOW+fOnMOlC/8sgrNyIGYTp1BTBw0ZgB+cNYcHD9tqGf7zJH98F/v\nm43FM4f7Poc4mM590YxhuPaMWTjtoJGwhIBlCZw+dySEEKhP2zhl7gj87em1OHXOCHzxj88mPmYY\nX140GdNGtOCoSa1V2Z9J1P32YwswRnHJrj93Lh5duRkjY/QMJJUbE3tzFHWEEELIvkocUbcWwGjl\n+ajyNkkzgBkAHijfKR8G4FYhxMmO4yyt1kRJPKQbJkT8Bt9BOUr5YhG2LTBhiDlErSFhg+lc3Ioq\nKIVBymk1egqlCKNbpbuJ1RJ1bk5de7BTFxQGZ+ohJoTAew8elXgeTkigo20JnHlI5Uf0zHnK4/L2\nsB58XaEubXfqfIIwXcojJg72PO/fkMHiWcOrdsx9nTqKOkIIIWSfJ87KdwmAiUKIcUKIDICzAdwq\nX3QcZ7vjOIMdxxnrOM5YAI8DoKDrJj7+m6XYoYQG5pWiJfmYBUwcxy/sXt24C69u3A1bCDeMT0fP\nP4tCirqrb3sxYqR33/VprU+dwa+qlVMnhevtz6+ryv46i/x4klZ47Gvs6+fXE0inO8lNFUIIIYT0\nLSJXvo7j5AFcCOAuAC8B+IPjOMuEEN8SQpxc6wmScO55cT3+sKSS8pjLl1b/AiK2U1d0gD1avs1T\n5XDOeWMHQAiBd2puCZA8j0pW3vzZw69FjlVDLm1L4IKF40uPhQjo45a8+qU8p7TWkuCPn3iH259u\nSHO8UvxAKUzwmydPjz3+lx85BN85fWassW6hlH1c83T1/L6yaAr+8qnDqjOZfYTT5o7EBw89AJ8/\nfnJPT4UQQgghNSLWqtxxnNsB3K5tuyJg7FFdnxZJgqpxOpTwy7hVKYuOg91aHzb53hOmDQMAfOyI\ncXj4lU2eMbIoR1w6EoZfSmwL+OpJU9GeL+KvT681jteduThO3cXHT8LDr2xCNuXNDTxk7EB85piJ\n+O5dy1EoOvjkURPwkwdejdzfERMH+0IFwzh68pDYY6vRKLwv0NViJ588akKVZrLvUJe2ceWpM3p6\nGoQQQgipIdWJUSNdJlco4oaHXvWUnY+L6lzlE7QNkPz8kdewUxF1z63Z5oZqSRfLVOExqajLFYrG\nipwmmnxtDEpz2L43h827/f3CdLctqJ+aiixwYqruKfOQcoUi6lLJCsLUAplTt687dYQQQgghJDkU\ndb2E3z7+Or59+8v4+SPRoYk6qk6SFSYF4jt1u9rzuO25t93nJ1//qCsuZWNmU4XHlrqKqDOFZ0qG\nNGfRrz6NogO0xxStaqNseWzZDsCEKswmDmmKlZs1qCmDkf3rcfVpfhdDhl92FIpuSfie5LipQ9GY\nsfGhd4zt6akQQgghhJBeRs+vVgmASsl8PQwyDqpTVwm/FCgkaCGwcWe757kUhDI3zVThUW1uffTk\nITh59gjjvv/+mSNwwZGlnLjdHfHOL6UcTwq01zfvCRwvnbnxrY245/NHGp1Fnfq0jUcvOQaLZvgr\nKcrzbs8X3ZLwAHDTx+bHmn+1GdpSh2XfWoSpw1t65PiEEEIIIaT3QlHXC3AcB4+v2gzAX9JdvhbU\ndkCOkagV7uJWvwT8zbVz+ejwSzUXLZ2yAo8nBJC2Sl+1x17dHGs+tkfUlf6PI+oqVSKjj5Gygr/+\nMievI190QzGBSosDQgghhBBCegsUdb2Avz/3dkXsaGGDf1y6Bmff8Dj+roRH6qhRlm25krAqFJ3Y\nOXWAv7m2FIdSXKnhjDLUcuLQJndbxhaBzcXr07YrDi/6v6djzUcI4YpV6RIGOYFARYQVtfeEOXa2\nHfyadOpyhaInFPSAQeaefbVgQmv3HYsQQgghhPRdktWkJzXh9U27A197deMuAMDarXsDx6jiTYZv\n5ovF2Dl1gL8xca7oIGNbniIlko8cPhY3fnie674BJdcrb6hu+c2Tp6O5Lg07RuGSIKSg/MIJk/CZ\nYw8EAEy+7E7PGJ+oK78nY1v47QXzccZP/uXbbypE8KVdUed4wi8HN2Wx/KpFcJzSGFN7hWpx98VH\nhjq0hBBCCCGEABR1vQJVe+ULRbTnC25ooxRsYQJk255KNchdZVGXKyRz6vQ+dXs7CkgpTpZ6/JRl\n+doAlMIv/cfr31AqppKOEw+pURGUlef6cSXSWdMjQIWAJ3xSJczFU8Mv67X3q3OwDY3Qq0Vpfix3\nSQghhBBCwmH4ZS/AQUUM/fiBVzH7m3e7z6VQChMgv/7X6+5jKeryBb9TFyYM2zSn7lePrfa0BVDD\nL01zKYVf+p06KYjiFC7RkS5VnN5llZw6rwheMG5g4LFNFT0lnpw65tERQgghhJBeDJ26XoDeu03m\nxQGKUxeS/6Wyq5wblys6KCQolKI7dYC315sqjEwiKW1byBty6hoypa9Y3PmbCBNfleOXxsgZ1KVt\n3Pm5d2LMwAa8tc0cumqq6FnZX7n6ZcHv1PVlHrvkmFjtHgghhBBCSN+Boq4XEBYlGcepU/E4dQla\nGujVLwFvQ281Jc40l5RtIWc4EdnjLazSZBRxRIh01tSQ0ynDWmK/37c/mVOnhF+GOZ19hRH963t6\nCoQQQgghpMow/LIXEFZsQ7ptKUvEKpohRV3RQWA1ShM72vz94+KEX8qHaVtgUGPGt49+9aWcuq4I\nojh6sFIoxf9aZwRlU13pfsfAxoy77zmj+yfeDyGEEEIIIbWGTl0vIJ5TZ4WOk+xVwihlntzFx03C\n0VNacfqPHwt8X6HowLaEx+nyOnXmoinZlI29uQIytoXvvW827n5xHb539wps2NmOTx01AQcOaS69\nx1D98uxDRmNE/3p8/54VoecUy6lz9++/SHrrgpH963HZ4qmh+xs3uBHXvncWjp0yBIOasvjO6TPx\nrunDIudBus7PPzwPBwxq6OlpEEIIIYT0GejU9QLCHDhVZMUpn9+WL/geL5w0GLNGRbtMAxszWDxr\nuPs8yKlTH0sXK2VbGNCYwVmHjHEF4NmHjHHHmZy6d88agfExerHFCT01hV+679dEYXNdCifOHO4b\np3PmvNEY1JQFAJwzfwwGGpxIUn2OnTrUvRlACCGEEEKioajrBYSJNenUFYtOLFHXrhRZkQVX4oYf\nZlOWp/VAUKEUtehJtiymVFdPij5VS5mLq4jQsEx5tnEiN+VcTW6mfuzdHf5QU0IIIYQQQvoqDL/s\nBYSFVRbKeXH5ooM4fahVp042Is+mS4LHtkRoQ/JsyvK4cEHhl6rzJfedUQSgFH2qa2aqfplJWbBj\nCM6w8MuffWgelq7e4u7f5HrKqfdvSOPUOSPxvnmjIo9JCCGEEEJIX4GirhcQx6krFIuxmomru9q2\np1TRsilb+pjr0jba88FtDrIp25ORlopRKCVjyJWTok8VkCa3MG1bMLzdR5ioO2hMfxw/bSg272oH\ngFDhKwB84+Tp0QckhBBCCCGkD8Hwy15AmBCR1S/zMcMvVbbt7QAANLqiLvzjzqYtj9OVCQq/VARa\nNlUq96+KRdn/TZ2vyanLxnTqwnLqpOCTczJdI9m8PNnVI4QQQgghpG9AUdcLiOfUObGqX6psLzt1\njZmS8KqLaKKdTVke4eMJv1SdOmX754+fBACeaoVfKG8bqfREM+XOpW0rVmPxsCFSQMo5FQzXsrku\nhbQt8LWTwiteEkIIIYQQ0hdh+GUvIEzUyddKOXXxVF2qnDu3bW8OdWnLDaOURU2CyKZsj3D0hF8q\nb61T9nPctKFYfc1iz35OnDnct83ktllCxKpsGe7UlccI6Q76x6RtC69cfVLkcQghhBBCCOmL0Knr\nBYT2qSsXSnnmjW2xnbr+DaXS+8vX7URTNu1uj+XUKcJR1VKqsMpG7MdE2pA8J4Q5LNPFkfMIHiPn\nZQW3qSOEEEIIIWSfhqKuFxCnT92dy9bhjhfejrU/GQq5dtteNGUrAqwuFS7GGjLeQilBvemiHD8T\nJretX0M6VmPxsDF6Tt0ZB49MPDdCCCGEEEL6MhR1vQDpxplQQzNXb9oda39HTWrF/LEDAVSKpACV\n9gNBjBnU6BGYw/rVuY+9hVJiNI7TSGsFUZ77xgloqUt79vXsFScY3xt2OCnqbEvghW++C1edOjPx\n3AghhBBCCOnLUNT1AvbmCr5t+UKpmqTaxsCKKaYasykcfuBgAF4BFhV+2dqc9VTiHDWgUvxELWgi\nYrhrOrYWZtlSVwoLVcViS705xTPcqas8bsqmYuXoEUIIIYQQsi9BUdfDvLB2O/7xnD+s8sBL78AT\nqzZ7er3FqRQJAE11KUwa2gQAaMhUhNL0ES2h75s4pMkj6mYo4+MKyiCC3D1VhAWJRZOomzumf+Br\nhBBCCCGE7E+w+mUPs3LDrsDXHlix0ePUqQJo4pAmvBLw3qZsCsdOHYr/PnsO5o4e4G7/zDETMWd0\nf2zfm8NDKzbhz0+tweJZw3HJoil4c+seHDp+EH756GsAgPMOG4sF4wd19fRcgkRdrFBOw5Bff3Q+\nVm/a3WWxSQghhBBCSF+Hoq6HaW3OBr6WLxQ9Tp3qSr1zYmugqGvMppBJWThljrdoiG0JHDV5CIBS\nZUwAmDK0GaMHNmD0wFKopTzcoVUUdIC3YblKZ0VZS10as0b178qUCCGEEEII2Sdg+GUPE9ajLldw\nAp26sKhDteJlEFIsprRWA3I61Y5qDGpdYHLq5LEHNZVaM9CMI4QQQgghJBg6dT1MPqT5XL5YRL5Y\ndJ+rok4VOr/6yCHY1Z7HhTc/DaDURDyKXLkQS9ontpzy/qurpIIKmOjHue6s2Zg5suTA/fY/FuCh\nFZvQXJc2vZUQQgghhBACiroepxgi6nJ5BwWl3YHabkAtKnLU5CHYvKvdfR7a0LuMdAB1sSWnU21z\nLDCnTpvraXNHuY9HDWjAuQvGVHkmhBBCCCGE7FtQ1PUwhRBR99en16KjUHHqcgVV1HnHevvIRUfV\nyn35wy8d4/67SpBTxxYEhBBCCCGEdA2Kuh4mTNSpgg6AJxRTaF6aWnDEH1LpR/bBS2ui6uvvmQ7b\netHtc1ctVGfxxg/Ncx/HbdNACCGEEEIIMUNR18MUQgql6Kj5dz6nTtmgu29h+9LHjh3ciBs/fEjs\nOXWG46YNdR/HcRUJIYQQQgghwcRaUQshFgkhlgshVgohLjG8/gkhxPNCiGeEEI8IIaZVf6r7Fi++\ntQPPvrkt1KnT+dPSNe5jPWpRDWPU3TcTwYVSuhdqOkIIIYQQQrpG5JJaCGED+BGAEwFMA3COQbTd\n7DjOTMdx5gC4FsD3qz7TfYyTfvgwTvnRo6EtDXQ27+5wHwsIzB7dH0dOagXgrSIZx6k7+5BSAZJ5\nYwfGPv6wljqcNW907PE62ZSF8xeO92yjU0cIIYQQQkjXiBN+OR/ASsdxVgGAEOJ3AE4B8KIc4DjO\nDmV8I2RdfBJJLm++VBnbwvHThuK25982vm4J4JZPH+4+9xRKieH/Ph6nAAAYDUlEQVS+HTFxMFZf\nszjRXB//2rGJxussv+pE3zYWSiGEEEIIIaRrxBF1IwG8qTxfA2CBPkgI8WkAnweQAXCMaUdCiPMB\nnA8AY8awVD0AvL5lt3F72hbIpoJdLKEl1anaKN2H3C+KOkIIIYQQQrpG1Vb/juP8yHGcCQC+AuCy\ngDE3OI4zz3Gcea2trdU6dJ9m1UazqEvZVqjg0QulCJHMqestUNMRQgghhBDSNeKIurUA1ESqUeVt\nQfwOwKldmdT+QH3aBgBs25Mzvp62hSvczpnvz2OzQloBBDX67o3ojiMhhBBCCCEkGXFE3RIAE4UQ\n44QQGQBnA7hVHSCEmKg8XQzglepNcd+kPlMSdTvazKIuZVmucBvQkPG9HiaFKJQIIYQQQgjZf4jM\nqXMcJy+EuBDAXQBsAL9wHGeZEOJbAJY6jnMrgAuFEMcByAHYCuDDtZz0vkBdOV9u2Vs7jK+nbOGK\ns7ShmqXVh9y4OAxrqevpKRBCCCGEENInidV83HGc2wHcrm27Qnn82SrPa5+nrhx+Kbn1wsNx8vWP\nus8ztuWGX2ZCCqbsC/z5k4dhzMCGnp4GIYQQQgghfZJYoo5UHz1CcuKQZs/zTMpyi4hkDE7dvhRh\nefABA3p6CoQQQgghhPRZ9m0LqIfZsrsD77ruIazauMv3WqHo7U+ndyHIpio5dSYBV5ey/RsJIYQQ\nQggh+x0UdTXk7mXrsHz9TvzkgVd9r+U1UZfSVF0mZbnFUPTCJ0dOasX7D2WfP0IIIYQQQghFXU2R\nBU5yhaLvtaLu1GluXCZlBVaxvOI905ClU0cIIYQQQggBRV1NyBWKuPbOl9GeL5afewXc/cs34K3t\nbZ5tuoDL2JXwS8fxvr85y1RIQgghhBBCSAmqgxpw6zNv4ccPvOqW6ZfiTvKRXy6J3EfJqSs9Lmqi\nrpGijhBCCCGEEFKGTl0NkCLOQUmMmcIvAeD0uSMD95FJ2W5Ipqbp0JBh6CUhhBBCCCGkBEVdDZBi\nzi5bbR35Iu58YR3ymrirCxFnavilln4XmGtHCCGEEEII2f+gqKsBUoRJLfavVZvxid/+G798dLUn\nPy6sLUEmZQEB4ZeEEEIIIYQQIqGoqwFSuOlibNOuduxoy7vP06lgx03tU0cIIYQQQgghQVDU1QDZ\nrkAPmyw6DlZv2u0+T+l9DBQyKcvNqdPbHxBCCCGEEEKIhGUUa4CUYHorgp89/Bp+9vBr7nM7xImb\nM7q/K+qmDG+p9hQJIYQQQggh+wgUdTVAGmtRBpttmY3S+794FMYNbvQ9BoBnrjg+cH//vuw4pAL2\nSQghhBBCCNk3oairAUE5dTop2+zUqSJOfQwA/Rsygfsb1JSNO0VCCCGEEELIPgJtnRogtVxU0UoW\nQiGEEEIIIYR0FYq6GlCM6dRR0xFCCCGEEEK6CkVdDSjGdOrYf44QQgghhBDSVZhTVwV2tOXwoZ8/\niS27O/D//mNBbKeOmo4QQgghhBDSVejUVYE7nn8bz7y5DW9s2YPr7lmBfKGk1goB5S8/eOgBANh/\njhBCCCGEENJ1KOqqQHu+6D52AOQKped5g2g7fe5IDGhIAwAKtOoIIYQQQgghXYSirgq05Qru43zR\nwfX3rwRgdupStoAoV0ihUUcIIYQQQgjpKsypqwJtuYpTd9eydaFjU7bltjJwHAcfO2Ic9pZF4UcO\nH+u6fIQQQgghhBASB4q6KqA6dVZEm4K0JdwxRcfB5e+e5r729fdMr8X0CCGEEEIIIfswDL+sAqpT\n15QN18kp24JlMfySEEIIIYQQUh3o1FWB9nzFqYsSaqWcOjk2vqob3JRFXZoanBBCCCGEEOKFoq4K\nqE5dLh+eE5e2LNhuTl38Yyy59NhOzY0QQgghhBCyb0NRVwVWbdrlPm6PKHTiceoSxF/KipmEEEII\nIYQQosJ4vi6ydttePP3GNvd5VPXKtG3hwCFNAIBJw5prOjdCCCGEEELIvg+dui6ydXeH53lUSGXK\nEjhmylDcdtERmDa8pYYzI4QQQgghhOwP0KnrIkHFTrKp8Es7fUQ/hlQSQgghhBBCugxFXRfJB+TF\n1aXtROMJIYQQQgghpDNQ1HWRoGInQe0HChR1hBBCCCGEkCoSS9QJIRYJIZYLIVYKIS4xvP55IcSL\nQojnhBD3CSEOqP5UeydBIo1OHSGEEEIIIaQ7iBR1QggbwI8AnAhgGoBzhBDTtGFPA5jnOM4sAH8C\ncG21J9pbKQTk1NWlzKKuUAyvjkkIIYQQQgghSYjj1M0HsNJxnFWO43QA+B2AU9QBjuPc7zjOnvLT\nxwGMqu40ey/BTp350tKpI4QQQgghhFSTOKJuJIA3ledrytuC+BiAO0wvCCHOF0IsFUIs3bhxY/xZ\n9mKCRF02IPwyScNxQgghhBBCCImiqoVShBAfADAPwHdNrzuOc4PjOPMcx5nX2tpazUNXDcdxcNO/\nVmP73lys8UlbGuQKFHWEEEIIIYSQ6hFH1K0FMFp5Pqq8zYMQ4jgAlwI42XGc9upMr/tZsnorLr9l\nGa645YVY4/MBIi2r5dQdNbkVGdvC2fNHG8cTQgghhBBCSGdIxRizBMBEIcQ4lMTc2QDOVQcIIeYC\n+CmARY7jbKj6LLuR3R15AMC2PZ136tK2QCblbSw+on89Vlx9YtcnSAghhBBCCCEKkU6d4zh5ABcC\nuAvASwD+4DjOMiHEt4QQJ5eHfRdAE4A/CiGeEULcWrMZ1xiZ82ZbJVH20IqNWL5uZ+D4Jau3+ral\nLAspiy0ACSGEEEIIIbUnjlMHx3FuB3C7tu0K5fFxVZ5XjyELn1hCYM3WPfjQL55EJmVhxVV+l+2J\nVZvx80de821P2QJpm6KOEEIIIYQQUnuoPDRkOKVtAbvbCwCAjry5t9wbW/YYt6dtyxd+SQghhBBC\nCCG1gKJOo1DWb7YlkI9oFB7Ucy5l+Z06SjxCCCGEEEJILaCo05BOnRAisLKlJEjUpW1/Th0bGRBC\nCCGEEEJqAUWdhht+KWI4dQXz6ylbIM3wS0IIIYQQQkg3QFGnUVCqX0Y1Cg9y8lKWQIbhl4QQQggh\nhJBugKJOI69Uv1RF2zk3PO4bmwtw8hh+SQghhBBCCOkuKOo0HKX6pSra/rVqs2+sKvpu+th8zBzZ\nDwCQTVkMvySEEEIIIYR0CxR1Gp7ql5HhlxXRN2d0fxw9uRUAkElZDL8khBBCCCGEdAsUdRqFsjtX\nqn7pDa/8yp+ew/m/WYoNO9oAAB2K6LOVNgYpy0LK8so4hl8SQgghhBBCakGqpyfQ25DFUWwhkNNa\nFvx+6ZsAgHTKwo/OPQhtuYL7mm0JpFMlUWdZQMqmXiaEEEIIIYTUHioPDdnGoBR+GdDSoKz1PKJO\nVJw6SwhYwuvUMfySEEIIIYQQUgso6jSkU6dXv1QRAnh53Q7cv3yDu60Ufinc92qajuGXhBBCCCGE\nkJrA8EuNjnzJnbNEcMsCSwgs+sHDnm3C49QBDlUcIYQQQgghpBugU6chwy+LTnBzcdsyB1NKUWd6\nneGXhBBCCCGEkFpAUachwy+LjoNcQE6dHlopkeGXwhB+SQghhBBCCCG1gKJOQ4ZfFooO8kWzU6cX\nQZGkLIZfEkIIIYQQQroXijqNSvilE1j9MiD60t0eFJ5JCCGEEEIIIdWGok4jl1fDL5M5dYWyPcfw\nS0IIIYQQQkh3QVGnIfPoSuGXQTl1ZsUmozUtITCspQ4AMLJ/ffUnSQghhBBCCCFlKOo0OlxRF1z9\n0hLAAYMaMKgx49nuOI77+tFThuA3H52P8xeOr+2ECSGEEEIIIfs1FHUa+UJ0+KUDIJcv4pgpQzzb\ni06lcTkALJzUCov5dYQQQgghhJAawubjGjL88q9Prw0eky+io1BEOuXVxBnbBgA011Uua115TGOW\nl5oQQgghhBBSfag0NDoCKl6q5ApFtOeLyNheUbdoxjB88YRJOO/wce620+aOxPodbfjoEeP03RBC\nCCGEEEJIl6Go0wjKo1PJFUuNyTOaU2dbAhceM9GzLWVbvm2EEEIIIYQQUi2YU6eRi+PU5YvoMDh1\nhBBCCCGEENLd0KnTiCPq2vJFFB0gk7Jw9Wkz8Na2vd0wM0IIIYQQQgjxQ1GnEVTxUnLQmP7Y054H\nAKRtC+9fcEB3TIsQQgghhBBCjDB+UOG+l9bjxbd3hI5J2xZ2dxQAwJdTRwghhBBCCCHdDVWJwh0v\nrIsck7Yt7C47dRmbPegIIYQQQgghPQtFnUJ92o4ck7YF9nSURR2dOkIIIYQQQkgPQ1WiUJ+JI+os\n7GyjqCOEEEIIIYT0DqhKFOoMTt2h4wd6nvdvSKM9Xyw/znTLvAghhBBCCCEkiFjVL4UQiwD8NwAb\nwI2O41yjvb4QwA8AzAJwtuM4f6r2RLsDPfzylDkjcOrckXh81RbMO2AAbvzwPKRsC+89eDTq0hZm\njOjXQzMlhBBCCCGEkBKRok4IYQP4EYDjAawBsEQIcavjOC8qw94AcB6AL9Zikt1FfdprXI4d1AhZ\nCqUhm3KdufnjBoIQQgghhBBCegNxnLr5AFY6jrMKAIQQvwNwCgBX1DmOs7r8WnTn7l6MHn6ZTVsI\n71pHCCGEEEIIIT1LnJy6kQDeVJ6vKW9LjBDifCHEUiHE0o0bN3ZmFzVFL3ySTUUXTiGEEEIIIYSQ\nnqRbC6U4jnOD4zjzHMeZ19ra2p2HjkXK1kVd5Tk70hFCCCGEEEJ6I3FE3VoAo5Xno8rb9jlSlle6\nZVIWGH9JCCGEEEII6c3EEXVLAEwUQowTQmQAnA3g1tpOq2ewNVE3tKUOTlnVCVp1hBBCCCGEkF5I\npKhzHCcP4EIAdwF4CcAfHMdZJoT4lhDiZAAQQhwihFgD4H0AfiqEWFbLSdcK3amb0NroPqamI4QQ\nQgghhPRGYvWpcxzndgC3a9uuUB4vQSkss0+j59SN6FePFet39tBsCCGEEEIIISSaWKJuf2HeAQMw\nfUQLDj5gwP9v785jJCnLOI5/f7KwHCoLrKKyxAUFCRCBDSiIGETDHdaoiSgJqCQeUVHjEZBE4n94\nxCvxiPFYDwLqikgwiog3hnOF5ZZVEBdBUBAPEkB4/KPeYZth1824PVNd4/eTVKbrreqet/uZp6ue\nqrdqeOChR3jSk0J5TZ0kSZKkCWZRN2KbhQv4/imHrHdZvKhOkiRJ0gSa039pIEmSJEkaL4u6jdjj\nmU8F4FXLBn/JoCRJkqR5yOGXG7HToq247cxj+u6GJEmSJK2XZ+okSZIkacAs6iRJkiRpwCzqJEmS\nJGnALOokSZIkacAs6iRJkiRpwCzqJEmSJGnALOokSZIkacAs6iRJkiRpwCzqJEmSJGnALOokSZIk\nacAs6iRJkiRpwCzqJEmSJGnAUlX9/OLkHuAPvfzy/24x8Je+O6HHGI/JYSwmi/GYLMZjchiLyWI8\nJovxmBxTsXh2VT1tU1+st6JuUiW5sqr277sf6hiPyWEsJovxmCzGY3IYi8liPCaL8Zgc446Fwy8l\nSZIkacAs6iRJkiRpwCzqnugLfXdAj2M8JoexmCzGY7IYj8lhLCaL8ZgsxmNyjDUWXlMnSZIkSQPm\nmTpJkiRJGjCLOkmSJEkaMIu6EUmOTHJzkjVJTu27P/Ndkp2T/DTJDUmuT/LO1r59kouS3NJ+btfa\nk+TTLT6rkyzr9x3MT0k2S/KbJBe0+V2SXNY+928m2aK1L2zza9rypX32e75JsijJyiQ3JbkxyUHm\nRn+SvLt9T12X5OwkW5obcyfJl5PcneS6kbYZ50OSk9r6tyQ5qY/3Mh9sIB4fbd9Xq5N8N8mikWWn\ntXjcnOSIkXb3uzbR+mIxsuw9SSrJ4jZvbsyyDcUjyTtaflyf5CMj7WPLDYu6JslmwGeAo4A9gdcm\n2bPfXs17/wbeU1V7AgcCb2uf+anAxVW1G3Bxm4cuNru16U3A5+a+y/8X3gncODL/YeATVfVc4D7g\n5NZ+MnBfa/9EW0/j8yngh1W1B7APXUzMjR4k2Qk4Bdi/qvYGNgOOx9yYSyuAI6e1zSgfkmwPnAG8\nEHgBcMZUIagZW8ET43ERsHdVPR/4LXAaQNuuHw/s1Z7z2Xbw0P2u8VjBE2NBkp2Bw4HbR5rNjdm3\ngmnxSPJSYDmwT1XtBXystY81Nyzq1nkBsKaqfl9VDwHn0AVAs6Sq7qyqVe3xP+h2Wnei+9y/2lb7\nKvCK9ng58LXqXAosSvLMOe72vJZkCXAM8MU2H+AwYGVbZXo8puK0EnhZW1+bKMm2wEuALwFU1UNV\n9TfMjT4tALZKsgDYGrgTc2POVNUvgHunNc80H44ALqqqe6vqProi5Ak7w9q49cWjqn5UVf9us5cC\nS9rj5cA5VfVgVd0KrKHb53K/aww2kBvQHVB6PzB6R0RzY5ZtIB5vBc6sqgfbOne39rHmhkXdOjsB\nfxyZX9vaNAfa8KT9gMuAHavqzrboLmDH9tgYzb5P0m0EHm3zOwB/G9lQj37mj8WjLb+/ra9Ntwtw\nD/CVdENhv5hkG8yNXlTVHXRHVm+nK+buB67C3OjbTPPBPJk7bwR+0B4bjzmWZDlwR1VdM22RsejH\n7sAhbTj+z5Mc0NrHGg+LOvUuyZOB7wDvqqq/jy6r7n9u+H835kCSY4G7q+qqvvsiFgDLgM9V1X7A\nv1g3tAwwN+ZSG4a0nK7YfhawDR7Fnijmw+RIcjrd5RVn9d2X/0dJtgY+AHyw777oMQuA7ekuNXof\n8K3ZGL1hUbfOHcDOI/NLWptmUZLN6Qq6s6rq3Nb856mhY+3n1GlqYzS7DgaOS3Ib3an+w+iu61rU\nhpzB4z/zx+LRlm8L/HUuOzyPrQXWVtVlbX4lXZFnbvTj5cCtVXVPVT0MnEuXL+ZGv2aaD+bJLEvy\neuBY4IRa94+Qjcfceg7dAahr2vZ8CbAqyTMwFn1ZC5zbhr1eTjcaajFjjodF3TpXALulu5vZFnQX\nLp7fc5/mtXaU4kvAjVX18ZFF5wNTd146CfjeSPuJ7e5NBwL3jwy90SaqqtOqaklVLaX7+/9JVZ0A\n/BR4dVttejym4vTqtr5Hysegqu4C/pjkea3pZcANmBt9uR04MMnW7XtrKh7mRr9mmg8XAocn2a6d\nfT28tWkMkhxJN3z/uKp6YGTR+cDx6e4KuwvdTToux/2uWVFV11bV06tqaduerwWWte2KudGP84CX\nAiTZHdgC+Avjzo2qcmoTcDTdHZt+B5zed3/m+wS8mG64zGrg6jYdTXftycXALcCPge3b+qG7G9Dv\ngGvp7kTX+/uYjxNwKHBBe7xr+5JZA3wbWNjat2zza9ryXfvu93yagH2BK1t+nAdsZ270Go8PATcB\n1wFfBxaaG3P6+Z9Ndz3jw3Q7qSf/L/lAd63Xmja9oe/3NdRpA/FYQ3cd0NT2/PMj65/e4nEzcNRI\nu/tdsxCLactvAxa3x+ZGD/GgK+K+0bYfq4DDRtYfW26kPVGSJEmSNEAOv5QkSZKkAbOokyRJkqQB\ns6iTJEmSpAGzqJMkSZKkAbOokyRJkqQBs6iTJA1Ckn+2n0uTvG7Mr/2BafO/HufrS5I0myzqJElD\nsxSYUVGXZMFGVnlcUVdVL5phnyRJ6o1FnSRpaM4EDklydZJ3J9ksyUeTXJFkdZI3AyQ5NMkvk5wP\n3NDazktyVZLrk7yptZ0JbNVe76zWNnVWMO21r0tybZLXjLz2z5KsTHJTkrOSpIfPQpIkNnbkUpKk\nSXMq8N6qOhagFWf3V9UBSRYClyT5UVt3GbB3Vd3a5t9YVfcm2Qq4Isl3qurUJG+vqn3X87teCewL\n7AMsbs/5RVu2H7AX8CfgEuBg4Ffjf7uSJP13nqmTJA3d4cCJSa4GLgN2AHZryy4fKegATklyDXAp\nsPPIehvyYuDsqnqkqv4M/Bw4YOS111bVo8DVdMNCJUmac56pkyQNXYB3VNWFj2tMDgX+NW3+5cBB\nVfVAkp8BW27C731w5PEjuE2VJPXEM3WSpKH5B/CUkfkLgbcm2Rwgye5JtlnP87YF7msF3R7AgSPL\nHp56/jS/BF7Trtt7GvAS4PKxvAtJksbEo4qSpKFZDTzShlGuAD5FN/RxVbtZyT3AK9bzvB8Cb0ly\nI3Az3RDMKV8AVidZVVUnjLR/FzgIuAYo4P1VdVcrCiVJmgipqr77IEmSJEn6Hzn8UpIkSZIGzKJO\nkiRJkgbMok6SJEmSBsyiTpIkSZIGzKJOkiRJkgbMok6SJEmSBsyiTpIkSZIG7D+/vIi/pLBIWAAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2256071050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation for epoch 3\n",
      "-  epoch 3: validation accuracy = 0.624\n",
      "train for epoch 4\n",
      "iteration (1550): loss = 1.009, accuracy = 0.656\n",
      "iteration (1600): loss = 1.033, accuracy = 0.594\n",
      "iteration (1650): loss = 1.071, accuracy = 0.641\n",
      "iteration (1700): loss = 0.915, accuracy = 0.641\n",
      "iteration (1750): loss = 0.919, accuracy = 0.727\n",
      "iteration (1800): loss = 1.085, accuracy = 0.680\n",
      "iteration (1850): loss = 1.119, accuracy = 0.680\n",
      "iteration (1900): loss = 0.911, accuracy = 0.711\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAALJCAYAAAATcQqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZYxBHRERERERURn7/8+evy/onqB6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2254b04bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation for epoch 4\n",
      "-  epoch 4: validation accuracy = 0.628\n",
      "***** test accuracy: 0.594\n",
      "Model saved in lib/tf_models/problem2/csci-599_sample.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Train our sample model\n",
    "with tf.Session() as sess:\n",
    "    #with tf.device('/cpu:0'):\n",
    "    model = BaseModel()\n",
    "    model.train(sess, X_train, Y_train, X_val, Y_val)\n",
    "    accuracy = model.evaluate(sess, X_test, Y_test)\n",
    "    print('***** test accuracy: %.3f' % accuracy)\n",
    "    saver = tf.train.Saver()\n",
    "    model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_sample.ckpt\")\n",
    "    print(\"Model saved in %s\" % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2-2\n",
    "\n",
    "Implement your own model. \n",
    "\n",
    "You can modify the template code as you want and you can use GPU for fast training.\n",
    "\n",
    "These are the techniques that you can try:\n",
    "- Data preprocessing\n",
    "- Data augmentation\n",
    "- Dropout\n",
    "- Batch normalization\n",
    "- More convolutional layers\n",
    "- More training epochs\n",
    "- Learning rate decay\n",
    "- Any other models and techniqes\n",
    "\n",
    "Your model should achieve >= 70% accuracy on the test set of CIFAR-10.\n",
    "\n",
    "If the accuracy of the model reaches to 80% on the test set, you will get 5 extra points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try is to add more layers to the base model, achieve 80% accuracy when converge\n",
    "# second try is a vgg model, achieve 84% accuracy with 50 epoches, very slow\n",
    "# it is the third try, the nin model, achieve over 80% accuracy within 25 epoches\n",
    "# I always keep the validation data out of from training\n",
    "# Please make sure you are connected to the internet. It is going to render the network by cloud!\n",
    "# Please make sure you have enough memory and disk space. It will save the best model during training!\n",
    "\n",
    "class YourModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.num_epoch = 100\n",
    "\n",
    "    def _input_ops(self):\n",
    "        # Placeholders\n",
    "\n",
    "        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "        self.is_train = tf.placeholder(tf.bool)\n",
    "        \n",
    "        self.keep_prob = 0.5\n",
    "        self.weight_decay = 1e-4\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Your model  ' + '-' * 5)\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Implement you own model here                                        #\n",
    "        #############################################################################\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "\n",
    "        w_X = tf.map_fn(lambda frame: tf.image.per_image_standardization(frame), self.X)\n",
    "        aw_X = tf.map_fn(lambda frame: tf.image.random_flip_left_right(frame), w_X)\n",
    "        fw_X = tf.cond(self.is_train, lambda : aw_X, \n",
    "                                      lambda : w_X)#close data augmentation when eval\n",
    "        with tf.variable_scope('nin_1'):\n",
    "            with tf.variable_scope('l1_conv1'):\n",
    "                conv1_1 = convBnRelu(fw_X, kernel_size = 5, stride = 1, num_filter = 192, \n",
    "                                     weight_decay = self.weight_decay, is_train = self.is_train)\n",
    "            with tf.variable_scope('l1_conv2'):\n",
    "                conv1_2 = convBnRelu(conv1_1, kernel_size = 1, stride = 1, num_filter = 160, \n",
    "                                     weight_decay = self.weight_decay, is_train = self.is_train)\n",
    "            with tf.variable_scope('l1_conv3'):\n",
    "                conv1_3 = convBnRelu(conv1_2, kernel_size = 1, stride = 1, num_filter = 96, \n",
    "                                     weight_decay = self.weight_decay, is_train = self.is_train)\n",
    "            pool1 = max_pool(conv1_3, kernel_size = 3, stride = 2)\n",
    "            cnn_drop1 = tf.layers.dropout(pool1, rate = self.keep_prob, training = self.is_train)\n",
    "            print('nin1 layer: ' + str(cnn_drop1.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('nin_2'):\n",
    "            with tf.variable_scope('l2_conv1'):\n",
    "                conv2_1 = convBnRelu(cnn_drop1, kernel_size = 5, stride = 1, num_filter = 192, \n",
    "                                     weight_decay = self.weight_decay, is_train = self.is_train)\n",
    "            with tf.variable_scope('l2_conv2'):\n",
    "                conv2_2 = convBnRelu(conv2_1, kernel_size = 1, stride = 1, num_filter = 192, \n",
    "                                     weight_decay = self.weight_decay, is_train = self.is_train)\n",
    "            with tf.variable_scope('l2_conv3'):\n",
    "                conv2_3 = convBnRelu(conv2_2, kernel_size = 1, stride = 1, num_filter = 192, \n",
    "                                     weight_decay = self.weight_decay, is_train = self.is_train)\n",
    "            pool2 = avg_pool(conv2_3, kernel_size = 3, stride = 2)\n",
    "            cnn_drop2 = tf.layers.dropout(pool2, rate = self.keep_prob, training = self.is_train)\n",
    "            print('nin2 layer: ' + str(pool2.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('nin_3'):\n",
    "            with tf.variable_scope('l3_conv1'):\n",
    "                conv3_1 = convBnRelu(cnn_drop2, kernel_size = 3, stride = 1, num_filter = 192, \n",
    "                                     weight_decay = self.weight_decay, is_train = self.is_train)\n",
    "            with tf.variable_scope('l3_conv2'):\n",
    "                conv3_2 = convBnRelu(conv3_1, kernel_size = 1, stride = 1, num_filter = 192, \n",
    "                                     weight_decay = self.weight_decay, is_train = self.is_train)\n",
    "            with tf.variable_scope('l3_conv3'):\n",
    "                conv3_3 = convBnRelu(conv3_2, kernel_size = 1, stride = 1, num_filter = 10, \n",
    "                                     weight_decay = self.weight_decay, is_train = self.is_train)\n",
    "            pool3 = avg_pool(conv3_3, kernel_size = 8, stride = 1, padding = 'VALID')\n",
    "            print('nin3 layer: ' + str(pool3.get_shape()))\n",
    "        \n",
    "        flat = tf.reshape(pool3, [-1, 10])\n",
    "        # Return the last layer\n",
    "        return flat\n",
    "    def _loss(self, labels, logits):\n",
    "        self.wd_loss = tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "        self.ce_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits = logits))\n",
    "        self.loss_op = self.ce_loss + self.wd_loss\n",
    "        \n",
    "        \n",
    "    def _build_optimizer(self):\n",
    "        #Set start learning rate as 5e-4 and apply exponential decay every 500 steps with a base of 0.97\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            learning_rate =  tf.train.exponential_decay(1e-3, global_step, 500, 0.97, staircase=True)\n",
    "            self.train_op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss_op) \n",
    "\n",
    "    def train(self, sess, X_train, Y_train, X_val, Y_val):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        step = 0\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        val_accs = []\n",
    "        max_val_acc = 0.0\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            seq = range(num_training)\n",
    "            np.random.shuffle(seq)\n",
    "            X_train = X_train[seq]\n",
    "            Y_train = Y_train[seq]\n",
    "            epoch_loss = 0.0\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\n",
    "                feed_dict = {self.X: X_, self.Y: Y_, self.is_train: 1}                \n",
    "                fetches = [self.train_op, self.loss_op, self.ce_loss, self.wd_loss, self.accuracy_op]\n",
    "\n",
    "                _, loss, ce_loss, wd_loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "                epoch_loss += loss\n",
    "                if step % self.log_step == 0:\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f, ce = %.3f, wd = %.3f' %\n",
    "                        (step, loss, accuracy, ce_loss, wd_loss))\n",
    "                step += 1\n",
    "            # Print validation results\n",
    "            print('total loss for epoch %d: %.3f' % (epoch, epoch_loss))\n",
    "            print('validation for epoch %d' % epoch)\n",
    "            val_accuracy = self.evaluate(sess, X_val, Y_val)\n",
    "            val_accs.append(val_accuracy)\n",
    "            print('-  epoch %d: validation accuracy = %.3f' % (epoch, val_accuracy))\n",
    "            if val_accuracy > max_val_acc and val_accuracy > 0.8:\n",
    "                print \"meet better model, save model...\"\n",
    "                max_val_acc = val_accuracy\n",
    "                saver.save(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")\n",
    "        \n",
    "        print('recover the best model with expected validation accuracy: %.3f' % max_val_acc)\n",
    "        saver.restore(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")\n",
    "        \n",
    "        # Graph 1. X: epoch, Y: training loss\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.title('Training loss')\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Iteration')\n",
    "        # Graph 2. X: epoch, Y: training accuracy\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.title('Training Accuracy')\n",
    "        plt.plot(accuracies)\n",
    "        plt.xlabel('Iteration')\n",
    "        # Graph 2. X: epoch, Y: training accuracy\n",
    "        plt.subplot(3, 1, 3)\n",
    "        plt.title('Validation Accuracy')\n",
    "        plt.plot(val_accs)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.tight_layout()\n",
    "        plt.gcf().set_size_inches(15, 12)\n",
    "        plt.show()\n",
    "    #############################################################################\n",
    "    # TODO: You can redefine BaseModel's methods                                #\n",
    "    #############################################################################\n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Preprocessing                                                       #\n",
    "#############################################################################\n",
    "X_train_ = X_train \n",
    "X_val_ =  X_val \n",
    "X_test_ =  X_test \n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Your model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "nin1 layer: (?, 16, 16, 96)\n",
      "nin2 layer: (?, 8, 8, 192)\n",
      "nin3 layer: (?, 1, 1, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.0299383700682&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_2&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;Placeholder_1&quot;\\n  input: &quot;one_hot/depth&quot;\\n  input: &quot;one_hot/on_value&quot;\\n  input: &quot;one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;map/Shape&quot;\\n  input: &quot;map/strided_slice/stack&quot;\\n  input: &quot;map/strided_slice/stack_1&quot;\\n  input: &quot;map/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;map/strided_slice&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;map/TensorArrayUnstack/Shape&quot;\\n  input: &quot;map/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;map/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;map/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;map/TensorArrayUnstack/range/start&quot;\\n  input: &quot;map/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;map/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;map/TensorArray&quot;\\n  input: &quot;map/TensorArrayUnstack/range&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;map/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Placeholder&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;map/strided_slice&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;map/while/Enter&quot;\\n  input: &quot;map/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;map/while/Enter_1&quot;\\n  input: &quot;map/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map/strided_slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;map/while/Merge&quot;\\n  input: &quot;map/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;map/while/Less&quot;\\n}\\nnode {\\n  name: &quot;map/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;map/while/Merge&quot;\\n  input: &quot;map/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;map/while/Merge_1&quot;\\n  input: &quot;map/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;map/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;map/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;map/while/TensorArrayReadV3/Enter&quot;\\n  input: &quot;map/while/Identity&quot;\\n  input: &quot;map/while/TensorArrayReadV3/Enter_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;map/while/TensorArrayReadV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;map/while/Shape&quot;\\n  input: &quot;map/while/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;map/while/control_dependency&quot;\\n  input: &quot;map/while/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;map/while/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Const_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;map/while/Square&quot;\\n  input: &quot;map/while/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Square_1&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;map/while/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;map/while/Mean_1&quot;\\n  input: &quot;map/while/Square_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;map/while/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;map/while/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;map/while/Prod&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Rsqrt&quot;\\n  op: &quot;Rsqrt&quot;\\n  input: &quot;map/while/Cast_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;map/while/Sqrt&quot;\\n  input: &quot;map/while/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;map/while/control_dependency&quot;\\n  input: &quot;map/while/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;map/while/Sub&quot;\\n  input: &quot;map/while/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/while/div&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;map/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;map/while/Identity&quot;\\n  input: &quot;map/while/div&quot;\\n  input: &quot;map/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/while/div&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;map/while/Identity&quot;\\n  input: &quot;map/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;map/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;map/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;map/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;map/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;map/TensorArray_1&quot;\\n  input: &quot;map/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;map/TensorArrayStack/range/start&quot;\\n  input: &quot;map/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;map/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;map/TensorArray_1&quot;\\n  input: &quot;map/TensorArrayStack/range&quot;\\n  input: &quot;map/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;map/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;map_1/Shape&quot;\\n  input: &quot;map_1/strided_slice/stack&quot;\\n  input: &quot;map_1/strided_slice/stack_1&quot;\\n  input: &quot;map_1/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;map_1/strided_slice&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;map/TensorArrayStack/TensorArrayGatherV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;map_1/TensorArrayUnstack/Shape&quot;\\n  input: &quot;map_1/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;map_1/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;map_1/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;map_1/TensorArrayUnstack/range/start&quot;\\n  input: &quot;map_1/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;map_1/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;map_1/TensorArray&quot;\\n  input: &quot;map_1/TensorArrayUnstack/range&quot;\\n  input: &quot;map/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;map_1/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;map_1/strided_slice&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map_1/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map_1/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map_1/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;map_1/while/Enter&quot;\\n  input: &quot;map_1/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;map_1/while/Enter_1&quot;\\n  input: &quot;map_1/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map_1/strided_slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map_1/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;map_1/while/Merge&quot;\\n  input: &quot;map_1/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;map_1/while/Less&quot;\\n}\\nnode {\\n  name: &quot;map_1/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;map_1/while/Merge&quot;\\n  input: &quot;map_1/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;map_1/while/Merge_1&quot;\\n  input: &quot;map_1/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;map_1/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;map_1/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map_1/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map_1/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map_1/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map_1/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;map_1/while/TensorArrayReadV3/Enter&quot;\\n  input: &quot;map_1/while/Identity&quot;\\n  input: &quot;map_1/while/TensorArrayReadV3/Enter_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;map_1/while/TensorArrayReadV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map_1/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map_1/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map_1/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;map_1/while/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;map_1/while/random_uniform/max&quot;\\n  input: &quot;map_1/while/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;map_1/while/random_uniform/RandomUniform&quot;\\n  input: &quot;map_1/while/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;map_1/while/random_uniform/mul&quot;\\n  input: &quot;map_1/while/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Less_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map_1/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Less_1&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;map_1/while/random_uniform&quot;\\n  input: &quot;map_1/while/Less_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;map_1/while/Less_1&quot;\\n  input: &quot;map_1/while/Less_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;map_1/while/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;map_1/while/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;map_1/while/Less_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/cond/ReverseV2/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map_1/while/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/cond/ReverseV2/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;map_1/while/control_dependency&quot;\\n  input: &quot;map_1/while/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/cond/ReverseV2&quot;\\n  op: &quot;ReverseV2&quot;\\n  input: &quot;map_1/while/cond/ReverseV2/Switch:1&quot;\\n  input: &quot;map_1/while/cond/ReverseV2/axis&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/cond/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;map_1/while/control_dependency&quot;\\n  input: &quot;map_1/while/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/while/TensorArrayReadV3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;map_1/while/cond/Switch_1&quot;\\n  input: &quot;map_1/while/cond/ReverseV2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;map_1/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/while/cond/Merge&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;map_1/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;map_1/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;map_1/while/Identity&quot;\\n  input: &quot;map_1/while/cond/Merge&quot;\\n  input: &quot;map_1/while/Identity_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/while/cond/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^map_1/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;map_1/while/Identity&quot;\\n  input: &quot;map_1/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;map_1/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;map_1/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;map_1/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;map_1/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;map_1/TensorArray_1&quot;\\n  input: &quot;map_1/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;map_1/TensorArrayStack/range/start&quot;\\n  input: &quot;map_1/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;map_1/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;map_1/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;map_1/TensorArray_1&quot;\\n  input: &quot;map_1/TensorArrayStack/range&quot;\\n  input: &quot;map_1/while/Exit_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;map_1/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map_1/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;map/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@map/TensorArray_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;cond/Switch_2&quot;\\n  input: &quot;cond/Switch_1:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.163299322128\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;nin_1/l1_conv1/W/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv1/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;nin_1/l1_conv1/W/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_1/l1_conv1/W/Initializer/random_normal/mul&quot;\\n  input: &quot;nin_1/l1_conv1/W/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/W&quot;\\n  input: &quot;nin_1/l1_conv1/W/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/b&quot;\\n  input: &quot;nin_1/l1_conv1/b/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;nin_1/l1_conv1/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/weight_loss/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999974738e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/weight_loss&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv1/L2Loss&quot;\\n  input: &quot;nin_1/l1_conv1/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;cond/Merge&quot;\\n  input: &quot;nin_1/l1_conv1/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_1/l1_conv1/Conv2D&quot;\\n  input: &quot;nin_1/l1_conv1/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/add&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2:1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/Const&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/add&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_mean/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_variance/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/cond/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims/input&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims_1/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims_1/input&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/Reshape&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/ExpandDims_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/Merge_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg/Sub&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/Merge_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000\\\\240\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10206207633\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;nin_1/l1_conv2/W/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv2/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;nin_1/l1_conv2/W/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_1/l1_conv2/W/Initializer/random_normal/mul&quot;\\n  input: &quot;nin_1/l1_conv2/W/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/W&quot;\\n  input: &quot;nin_1/l1_conv2/W/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/b&quot;\\n  input: &quot;nin_1/l1_conv2/b/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;nin_1/l1_conv2/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/weight_loss/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999974738e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/weight_loss&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv2/L2Loss&quot;\\n  input: &quot;nin_1/l1_conv2/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;nin_1/l1_conv1/Relu&quot;\\n  input: &quot;nin_1/l1_conv2/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_1/l1_conv2/Conv2D&quot;\\n  input: &quot;nin_1/l1_conv2/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/add&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2:1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/Const&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/add&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_mean/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_variance/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/cond/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims/input&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims_1/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims_1/input&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/Reshape&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/ExpandDims_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/Merge_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg/Sub&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/Merge_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\240\\\\000\\\\000\\\\000`\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.111803397536\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;nin_1/l1_conv3/W/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv3/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;nin_1/l1_conv3/W/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_1/l1_conv3/W/Initializer/random_normal/mul&quot;\\n  input: &quot;nin_1/l1_conv3/W/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 160\\n        }\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/W&quot;\\n  input: &quot;nin_1/l1_conv3/W/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/b&quot;\\n  input: &quot;nin_1/l1_conv3/b/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;nin_1/l1_conv3/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/weight_loss/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999974738e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/weight_loss&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv3/L2Loss&quot;\\n  input: &quot;nin_1/l1_conv3/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;nin_1/l1_conv2/Relu&quot;\\n  input: &quot;nin_1/l1_conv3/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_1/l1_conv3/Conv2D&quot;\\n  input: &quot;nin_1/l1_conv3/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/add&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2:1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/Const&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/add&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_mean/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_variance/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/cond/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims/input&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims_1/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims_1/input&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/Reshape&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/ExpandDims_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/Merge_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg/Sub&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/Merge_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/MaxPool&quot;\\n  op: &quot;MaxPool&quot;\\n  input: &quot;nin_1/l1_conv3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 3\\n        i: 3\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/dropout/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/dropout/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/keep_prob&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/dropout/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/Shape/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/MaxPool&quot;\\n  input: &quot;nin_1/dropout/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/MaxPool&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/Shape/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/dropout/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/dropout/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/random_uniform/max&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/random_uniform/RandomUniform&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/random_uniform/mul&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/keep_prob&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/Floor&quot;\\n  op: &quot;Floor&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/Shape/Switch:1&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/dropout/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/div&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/Identity/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/MaxPool&quot;\\n  input: &quot;nin_1/dropout/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/MaxPool&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/dropout/cond/Identity/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/dropout/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_1/dropout/cond/Identity&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/mul&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000`\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0288675129414\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;nin_2/l2_conv1/W/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv1/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;nin_2/l2_conv1/W/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_2/l2_conv1/W/Initializer/random_normal/mul&quot;\\n  input: &quot;nin_2/l2_conv1/W/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 96\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/W&quot;\\n  input: &quot;nin_2/l2_conv1/W/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/b&quot;\\n  input: &quot;nin_2/l2_conv1/b/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;nin_2/l2_conv1/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/weight_loss/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999974738e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/weight_loss&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv1/L2Loss&quot;\\n  input: &quot;nin_2/l2_conv1/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;nin_1/dropout/cond/Merge&quot;\\n  input: &quot;nin_2/l2_conv1/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_2/l2_conv1/Conv2D&quot;\\n  input: &quot;nin_2/l2_conv1/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/add&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2:1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/Const&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/add&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_mean/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_variance/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/cond/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims/input&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims_1/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims_1/input&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/Reshape&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/ExpandDims_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/Merge_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg/Sub&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/Merge_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10206207633\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;nin_2/l2_conv2/W/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv2/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;nin_2/l2_conv2/W/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_2/l2_conv2/W/Initializer/random_normal/mul&quot;\\n  input: &quot;nin_2/l2_conv2/W/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/W&quot;\\n  input: &quot;nin_2/l2_conv2/W/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/b&quot;\\n  input: &quot;nin_2/l2_conv2/b/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;nin_2/l2_conv2/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/weight_loss/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999974738e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/weight_loss&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv2/L2Loss&quot;\\n  input: &quot;nin_2/l2_conv2/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;nin_2/l2_conv1/Relu&quot;\\n  input: &quot;nin_2/l2_conv2/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_2/l2_conv2/Conv2D&quot;\\n  input: &quot;nin_2/l2_conv2/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/add&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2:1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/Const&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/add&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_mean/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_variance/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/cond/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims/input&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims_1/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims_1/input&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/Reshape&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/ExpandDims_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/Merge_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg/Sub&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/Merge_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10206207633\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;nin_2/l2_conv3/W/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv3/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;nin_2/l2_conv3/W/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_2/l2_conv3/W/Initializer/random_normal/mul&quot;\\n  input: &quot;nin_2/l2_conv3/W/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/W&quot;\\n  input: &quot;nin_2/l2_conv3/W/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/b&quot;\\n  input: &quot;nin_2/l2_conv3/b/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;nin_2/l2_conv3/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/weight_loss/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999974738e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/weight_loss&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv3/L2Loss&quot;\\n  input: &quot;nin_2/l2_conv3/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;nin_2/l2_conv2/Relu&quot;\\n  input: &quot;nin_2/l2_conv3/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_2/l2_conv3/Conv2D&quot;\\n  input: &quot;nin_2/l2_conv3/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/add&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2:1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/Const&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/add&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_mean/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_variance/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/cond/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims/input&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims_1/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims_1/input&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/Reshape&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/ExpandDims_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/Merge_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg/Sub&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/Merge_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/AvgPool&quot;\\n  op: &quot;AvgPool&quot;\\n  input: &quot;nin_2/l2_conv3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 3\\n        i: 3\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/dropout/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/dropout/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/keep_prob&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_2/dropout/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/Shape/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/AvgPool&quot;\\n  input: &quot;nin_2/dropout/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/AvgPool&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/Shape/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_2/dropout/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_2/dropout/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/random_uniform/max&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/random_uniform/RandomUniform&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/random_uniform/mul&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/keep_prob&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/Floor&quot;\\n  op: &quot;Floor&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/Shape/Switch:1&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/dropout/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/div&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/Identity/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/AvgPool&quot;\\n  input: &quot;nin_2/dropout/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/AvgPool&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/dropout/cond/Identity/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/dropout/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_2/dropout/cond/Identity&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/mul&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\003\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0340206921101\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;nin_3/l3_conv1/W/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv1/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;nin_3/l3_conv1/W/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_3/l3_conv1/W/Initializer/random_normal/mul&quot;\\n  input: &quot;nin_3/l3_conv1/W/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/W&quot;\\n  input: &quot;nin_3/l3_conv1/W/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/b&quot;\\n  input: &quot;nin_3/l3_conv1/b/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;nin_3/l3_conv1/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/weight_loss/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999974738e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/weight_loss&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv1/L2Loss&quot;\\n  input: &quot;nin_3/l3_conv1/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;nin_2/dropout/cond/Merge&quot;\\n  input: &quot;nin_3/l3_conv1/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_3/l3_conv1/Conv2D&quot;\\n  input: &quot;nin_3/l3_conv1/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/add&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2:1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/Const&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/add&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_mean/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_variance/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/cond/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims/input&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims_1/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims_1/input&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/Reshape&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/ExpandDims_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/Merge_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg/Sub&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/Merge_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10206207633\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;nin_3/l3_conv2/W/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv2/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;nin_3/l3_conv2/W/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_3/l3_conv2/W/Initializer/random_normal/mul&quot;\\n  input: &quot;nin_3/l3_conv2/W/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/W&quot;\\n  input: &quot;nin_3/l3_conv2/W/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/b&quot;\\n  input: &quot;nin_3/l3_conv2/b/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;nin_3/l3_conv2/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/weight_loss/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999974738e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/weight_loss&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv2/L2Loss&quot;\\n  input: &quot;nin_3/l3_conv2/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;nin_3/l3_conv1/Relu&quot;\\n  input: &quot;nin_3/l3_conv2/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_3/l3_conv2/Conv2D&quot;\\n  input: &quot;nin_3/l3_conv2/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/add&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2:1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/Const&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/add&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_mean/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_variance/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/cond/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims/input&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims_1/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims_1/input&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/Reshape&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/ExpandDims_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/Merge_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg/Sub&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/Merge_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10206207633\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;nin_3/l3_conv3/W/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv3/W/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;nin_3/l3_conv3/W/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_3/l3_conv3/W/Initializer/random_normal/mul&quot;\\n  input: &quot;nin_3/l3_conv3/W/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/W&quot;\\n  input: &quot;nin_3/l3_conv3/W/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/b&quot;\\n  input: &quot;nin_3/l3_conv3/b/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;nin_3/l3_conv3/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/weight_loss/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999974738e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/weight_loss&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv3/L2Loss&quot;\\n  input: &quot;nin_3/l3_conv3/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;nin_3/l3_conv2/Relu&quot;\\n  input: &quot;nin_3/l3_conv3/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nin_3/l3_conv3/Conv2D&quot;\\n  input: &quot;nin_3/l3_conv3/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/cond/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/add&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2:1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/Const&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/add&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_mean/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_variance/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  op: &quot;FusedBatchNorm&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/cond/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims/input&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims_1/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims_1/input&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_2&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/Reshape&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/ExpandDims_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/Merge_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg/Sub&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/Merge_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1/Sub&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/Squeeze&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/AvgPool&quot;\\n  op: &quot;AvgPool&quot;\\n  input: &quot;nin_3/l3_conv3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 8\\n        i: 8\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;nin_3/AvgPool&quot;\\n  input: &quot;Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;nin_1/l1_conv1/weight_loss&quot;\\n  input: &quot;nin_1/l1_conv2/weight_loss&quot;\\n  input: &quot;nin_1/l1_conv3/weight_loss&quot;\\n  input: &quot;nin_2/l2_conv1/weight_loss&quot;\\n  input: &quot;nin_2/l2_conv2/weight_loss&quot;\\n  input: &quot;nin_2/l2_conv3/weight_loss&quot;\\n  input: &quot;nin_3/l3_conv1/weight_loss&quot;\\n  input: &quot;nin_3/l3_conv2/weight_loss&quot;\\n  input: &quot;nin_3/l3_conv3/weight_loss&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 9\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank_1&quot;\\n  input: &quot;Sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_1&quot;\\n  input: &quot;Slice/begin&quot;\\n  input: &quot;Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;concat/values_0&quot;\\n  input: &quot;Slice&quot;\\n  input: &quot;concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank_2&quot;\\n  input: &quot;Sub_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape_2&quot;\\n  input: &quot;Slice_1/begin&quot;\\n  input: &quot;Slice_1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;concat_1/values_0&quot;\\n  input: &quot;Slice_1&quot;\\n  input: &quot;concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;one_hot&quot;\\n  input: &quot;concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Reshape_1&quot;\\n  input: &quot;Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Rank&quot;\\n  input: &quot;Sub_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2/size&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Sub_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Slice_2&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Shape&quot;\\n  input: &quot;Slice_2/begin&quot;\\n  input: &quot;Slice_2/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape_3&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Slice_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Reshape_3&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Mean&quot;\\n  input: &quot;AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;Variable/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000475\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Variable/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Cast_1/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 500\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;ExponentialDecay/Cast_1/x&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Cast_2/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.97000002861\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;ExponentialDecay/Cast&quot;\\n  input: &quot;ExponentialDecay/Cast_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Floor&quot;\\n  op: &quot;Floor&quot;\\n  input: &quot;ExponentialDecay/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;ExponentialDecay/Cast_2/x&quot;\\n  input: &quot;ExponentialDecay/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;ExponentialDecay/learning_rate&quot;\\n  input: &quot;ExponentialDecay/Pow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum_1&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape_3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape_3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_2&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/control_dependency_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/control_dependency_5&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/control_dependency_6&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/control_dependency_7&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_grad/tuple/control_dependency_8&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradients/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_3_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_3_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/Reshape_3_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Shape&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_1/l1_conv1/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/mul&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv1/L2Loss&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/mul_1&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/weight_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/weight_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/weight_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Shape&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_1/l1_conv2/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/mul&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv2/L2Loss&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/mul_1&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/weight_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/weight_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/weight_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Shape&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_2&quot;\\n  input: &quot;nin_1/l1_conv3/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/mul&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv3/L2Loss&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/mul_1&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/weight_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/weight_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/weight_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Shape&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_3&quot;\\n  input: &quot;nin_2/l2_conv1/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/mul&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv1/L2Loss&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/mul_1&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/weight_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/weight_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/weight_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Shape&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_4&quot;\\n  input: &quot;nin_2/l2_conv2/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/mul&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv2/L2Loss&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/mul_1&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/weight_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/weight_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/weight_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Shape&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_5&quot;\\n  input: &quot;nin_2/l2_conv3/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/mul&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv3/L2Loss&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/mul_1&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/weight_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/weight_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/weight_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Shape&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_6&quot;\\n  input: &quot;nin_3/l3_conv1/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/mul&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv1/L2Loss&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/mul_1&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/weight_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/weight_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/weight_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Shape&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_7&quot;\\n  input: &quot;nin_3/l3_conv2/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/mul&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv2/L2Loss&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/mul_1&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/weight_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/weight_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/weight_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Shape&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_8&quot;\\n  input: &quot;nin_3/l3_conv3/weight_loss/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/mul&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv3/L2Loss&quot;\\n  input: &quot;gradients/AddN_grad/tuple/control_dependency_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/mul_1&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/weight_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/weight_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/weight_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/weight_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/Reshape_3_grad/Reshape&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv1/W/read&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/weight_loss_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv2/W/read&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/weight_loss_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/l1_conv3/W/read&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/weight_loss_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv1/W/read&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/weight_loss_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv2/W/read&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/weight_loss_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/l2_conv3/W/read&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/weight_loss_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv1/W/read&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/weight_loss_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv2/W/read&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/weight_loss_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_3/l3_conv3/W/read&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/weight_loss_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;gradients/Reshape_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_3/AvgPool&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Reshape_1_grad/Reshape&quot;\\n  input: &quot;gradients/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/AvgPool_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_3/l3_conv3/Relu&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/AvgPool_grad/AvgPoolGrad&quot;\\n  op: &quot;AvgPoolGrad&quot;\\n  input: &quot;gradients/nin_3/AvgPool_grad/Shape&quot;\\n  input: &quot;gradients/Reshape_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 8\\n        i: 8\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/nin_3/AvgPool_grad/AvgPoolGrad&quot;\\n  input: &quot;nin_3/l3_conv3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/Relu_grad/ReluGrad&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_1&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_2&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_3&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_4&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_5&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_6&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_7&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_8&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:3&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:4&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/add&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_1&quot;\\n  input: &quot;gradients/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_1/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_2&quot;\\n  input: &quot;gradients/zeros_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_2/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_2&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_3&quot;\\n  input: &quot;gradients/zeros_2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/add&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_4&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_3/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_3&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_4&quot;\\n  input: &quot;gradients/zeros_3/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_5&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_4/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_4&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_5&quot;\\n  input: &quot;gradients/zeros_4/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_4&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_5&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_6&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_5/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_5&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_6&quot;\\n  input: &quot;gradients/zeros_5/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_3/l3_conv3/Conv2D&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/Shape&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;nin_3/l3_conv2/Relu&quot;\\n  input: &quot;nin_3/l3_conv3/W/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/ShapeN&quot;\\n  input: &quot;nin_3/l3_conv3/W/read&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;nin_3/l3_conv2/Relu&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/nin_3/l3_conv3/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_3/l3_conv2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_3&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv3/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/Relu_grad/ReluGrad&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_9&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_10&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_11&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_12&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_13&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_14&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_15&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_16&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:3&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:4&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_6&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/add&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_7&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_6:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_6/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_6&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_7&quot;\\n  input: &quot;gradients/zeros_6/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_6&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_7&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_8&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_7:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_7/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_7&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_8&quot;\\n  input: &quot;gradients/zeros_7/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_7&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_8&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_9&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_8:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_8/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_8&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_9&quot;\\n  input: &quot;gradients/zeros_8/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_8&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_9&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/add&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_10&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_9/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_9&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_10&quot;\\n  input: &quot;gradients/zeros_9/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_9&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_10&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_11&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_10/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_10&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_11&quot;\\n  input: &quot;gradients/zeros_10/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_10&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_11&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_12&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_11/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_11&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_12&quot;\\n  input: &quot;gradients/zeros_11/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_11&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_4&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_3/l3_conv2/Conv2D&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/Shape&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_4&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_4&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_5&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_6&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;nin_3/l3_conv1/Relu&quot;\\n  input: &quot;nin_3/l3_conv2/W/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/ShapeN&quot;\\n  input: &quot;nin_3/l3_conv2/W/read&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;nin_3/l3_conv1/Relu&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/nin_3/l3_conv2/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_3/l3_conv1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_7&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv2/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/Relu_grad/ReluGrad&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_17&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_18&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_19&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_20&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_21&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_22&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_23&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_24&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:3&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:4&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_12&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/add&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_13&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_12:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_12/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_12&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_13&quot;\\n  input: &quot;gradients/zeros_12/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_12&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_13&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_14&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_13:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_13/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_13&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_14&quot;\\n  input: &quot;gradients/zeros_13/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_13&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_14&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_15&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_14:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_14/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_14&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_15&quot;\\n  input: &quot;gradients/zeros_14/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_14&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_15&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/add&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_16&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_15/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_15&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_16&quot;\\n  input: &quot;gradients/zeros_15/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_15&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_16&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_17&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_16/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_16&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_17&quot;\\n  input: &quot;gradients/zeros_16/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_16&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_17&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_18&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_17&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_17/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_17&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_18&quot;\\n  input: &quot;gradients/zeros_17/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_17&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_8&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_3/l3_conv1/Conv2D&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/Shape&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_8&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/Sum&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_8&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_9&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_10&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;nin_2/dropout/cond/Merge&quot;\\n  input: &quot;nin_3/l3_conv1/W/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/ShapeN&quot;\\n  input: &quot;nin_3/l3_conv1/W/read&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;nin_2/dropout/cond/Merge&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/nin_3/l3_conv1/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_2/dropout/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_11&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_3/l3_conv1/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/div&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/Floor&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Shape&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/mul&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Sum&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/div&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/mul_1&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/dropout/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/dropout/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/dropout/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/dropout/cond/dropout/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/dropout/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/dropout/cond/dropout/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_18&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/AvgPool&quot;\\n  input: &quot;nin_2/dropout/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_19&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_18:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_18/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_18&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_19&quot;\\n  input: &quot;gradients/zeros_18/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/Identity/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_18&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/Shape/Switch:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Shape&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/RealDiv&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Sum&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/Shape/Switch:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Neg&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/RealDiv_1&quot;\\n  input: &quot;nin_2/dropout/cond/dropout/keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/mul&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/dropout/div_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/dropout/div_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/dropout/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/dropout/cond/dropout/div_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_2/dropout/cond/dropout/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/dropout/cond/dropout/div_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_19&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/AvgPool&quot;\\n  input: &quot;nin_2/dropout/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_20&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_19&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_19/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_19&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_20&quot;\\n  input: &quot;gradients/zeros_19/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/dropout/cond/dropout/Shape/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/div_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_19&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_12&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/Identity/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/dropout/cond/dropout/Shape/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/dropout/cond/Identity/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/AvgPool_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_2/l2_conv3/Relu&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/AvgPool_grad/AvgPoolGrad&quot;\\n  op: &quot;AvgPoolGrad&quot;\\n  input: &quot;gradients/nin_2/AvgPool_grad/Shape&quot;\\n  input: &quot;gradients/AddN_12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 3\\n        i: 3\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/nin_2/AvgPool_grad/AvgPoolGrad&quot;\\n  input: &quot;nin_2/l2_conv3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/Relu_grad/ReluGrad&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_25&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_26&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_27&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_28&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_29&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_30&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_31&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_32&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:3&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:4&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_20&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/add&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_21&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_20:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_20/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_20&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_21&quot;\\n  input: &quot;gradients/zeros_20/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_20&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_21&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_22&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_21:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_21/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_21&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_22&quot;\\n  input: &quot;gradients/zeros_21/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_21&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_22&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_23&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_22:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_22/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_22&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_23&quot;\\n  input: &quot;gradients/zeros_22/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_22&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_23&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/add&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_24&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_23&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_23/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_23&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_24&quot;\\n  input: &quot;gradients/zeros_23/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_23&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_24&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_25&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_24&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_24/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_24&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_25&quot;\\n  input: &quot;gradients/zeros_24/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_24&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_25&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_26&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_25&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_25/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_25&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_26&quot;\\n  input: &quot;gradients/zeros_25/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_25&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_13&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_2/l2_conv3/Conv2D&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/Shape&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_13&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_13&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_14&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_15&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;nin_2/l2_conv2/Relu&quot;\\n  input: &quot;nin_2/l2_conv3/W/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/ShapeN&quot;\\n  input: &quot;nin_2/l2_conv3/W/read&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;nin_2/l2_conv2/Relu&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/nin_2/l2_conv3/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_2/l2_conv2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_16&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv3/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/Relu_grad/ReluGrad&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_33&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_34&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_35&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_36&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_37&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_38&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_39&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_40&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:3&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:4&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_26&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/add&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_27&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_26:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_26/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_26&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_27&quot;\\n  input: &quot;gradients/zeros_26/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_26&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_27&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_28&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_27:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_27/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_27&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_28&quot;\\n  input: &quot;gradients/zeros_27/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_27&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_28&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_29&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_28:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_28/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_28&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_29&quot;\\n  input: &quot;gradients/zeros_28/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_28&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_29&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/add&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_30&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_29&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_29/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_29&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_30&quot;\\n  input: &quot;gradients/zeros_29/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_29&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_30&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_31&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_30&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_30/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_30&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_31&quot;\\n  input: &quot;gradients/zeros_30/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_30&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_31&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_32&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_31&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_31/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_31&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_32&quot;\\n  input: &quot;gradients/zeros_31/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_31&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_17&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_2/l2_conv2/Conv2D&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/Shape&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_17&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_17&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_18&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_19&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;nin_2/l2_conv1/Relu&quot;\\n  input: &quot;nin_2/l2_conv2/W/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/ShapeN&quot;\\n  input: &quot;nin_2/l2_conv2/W/read&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;nin_2/l2_conv1/Relu&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/nin_2/l2_conv2/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_2/l2_conv1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_20&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv2/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/Relu_grad/ReluGrad&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_41&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_42&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_43&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_44&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_45&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_46&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_47&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_48&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:3&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:4&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_32&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/add&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_33&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_32:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_32/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_32&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_33&quot;\\n  input: &quot;gradients/zeros_32/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_32&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_33&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_34&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_33:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_33/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_33&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_34&quot;\\n  input: &quot;gradients/zeros_33/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_33&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_34&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_35&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_34:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_34/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_34&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_35&quot;\\n  input: &quot;gradients/zeros_34/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_34&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_35&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/add&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_36&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_35&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_35/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_35&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_36&quot;\\n  input: &quot;gradients/zeros_35/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_35&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_36&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_37&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_36&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_36/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_36&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_37&quot;\\n  input: &quot;gradients/zeros_36/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_36&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_37&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_38&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_37&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_37/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_37&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_38&quot;\\n  input: &quot;gradients/zeros_37/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_37&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_21&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_2/l2_conv1/Conv2D&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/Shape&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_21&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/Sum&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_21&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_22&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_23&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;nin_1/dropout/cond/Merge&quot;\\n  input: &quot;nin_2/l2_conv1/W/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/ShapeN&quot;\\n  input: &quot;nin_2/l2_conv1/W/read&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;nin_1/dropout/cond/Merge&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/nin_2/l2_conv1/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_1/dropout/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_24&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_2/l2_conv1/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/div&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/Floor&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Shape&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/mul&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Sum&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/div&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/mul_1&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/dropout/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/dropout/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/dropout/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/dropout/cond/dropout/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/dropout/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/dropout/cond/dropout/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_38&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/MaxPool&quot;\\n  input: &quot;nin_1/dropout/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_39&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_38:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_38/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_38&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_39&quot;\\n  input: &quot;gradients/zeros_38/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/Identity/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_38&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/Shape/Switch:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Shape&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/RealDiv&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Sum&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/Shape/Switch:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Neg&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/RealDiv_1&quot;\\n  input: &quot;nin_1/dropout/cond/dropout/keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/mul&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/dropout/div_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/dropout/div_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/dropout/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/dropout/cond/dropout/div_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_1/dropout/cond/dropout/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/dropout/cond/dropout/div_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_39&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/MaxPool&quot;\\n  input: &quot;nin_1/dropout/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_40&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_39&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_39/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_39&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_40&quot;\\n  input: &quot;gradients/zeros_39/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/dropout/cond/dropout/Shape/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/div_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_39&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_25&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/Identity/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/dropout/cond/dropout/Shape/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/dropout/cond/Identity/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/MaxPool_grad/MaxPoolGrad&quot;\\n  op: &quot;MaxPoolGrad&quot;\\n  input: &quot;nin_1/l1_conv3/Relu&quot;\\n  input: &quot;nin_1/MaxPool&quot;\\n  input: &quot;gradients/AddN_25&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 3\\n        i: 3\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/nin_1/MaxPool_grad/MaxPoolGrad&quot;\\n  input: &quot;nin_1/l1_conv3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/Relu_grad/ReluGrad&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_49&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_50&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_51&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_52&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_53&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_54&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_55&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_56&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:3&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:4&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_40&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/add&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_41&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_40:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_40/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_40&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_41&quot;\\n  input: &quot;gradients/zeros_40/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_40&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_41&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_42&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_41:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_41/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_41&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_42&quot;\\n  input: &quot;gradients/zeros_41/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_41&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_42&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_43&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_42:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_42/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_42&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_43&quot;\\n  input: &quot;gradients/zeros_42/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_42&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_43&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/add&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_44&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_43&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_43/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_43&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_44&quot;\\n  input: &quot;gradients/zeros_43/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_43&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_44&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_45&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_44&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_44/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_44&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_45&quot;\\n  input: &quot;gradients/zeros_44/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_44&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_45&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_46&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_45&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_45/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_45&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_46&quot;\\n  input: &quot;gradients/zeros_45/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_45&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_26&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_1/l1_conv3/Conv2D&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000`\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/Shape&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_26&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_26&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_27&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_28&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;nin_1/l1_conv2/Relu&quot;\\n  input: &quot;nin_1/l1_conv3/W/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/ShapeN&quot;\\n  input: &quot;nin_1/l1_conv3/W/read&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;nin_1/l1_conv2/Relu&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/nin_1/l1_conv3/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_1/l1_conv2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_29&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv3/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/Relu_grad/ReluGrad&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_57&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_58&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_59&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_60&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_61&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_62&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_63&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_64&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:3&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:4&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_46&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/add&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_47&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_46:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_46/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_46&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_47&quot;\\n  input: &quot;gradients/zeros_46/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_46&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_47&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_48&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_47:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_47/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_47&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_48&quot;\\n  input: &quot;gradients/zeros_47/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_47&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_48&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_49&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_48:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_48/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_48&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_49&quot;\\n  input: &quot;gradients/zeros_48/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_48&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_49&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/add&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_50&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_49&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_49/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_49&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_50&quot;\\n  input: &quot;gradients/zeros_49/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_49&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_50&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_51&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_50&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_50/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_50&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_51&quot;\\n  input: &quot;gradients/zeros_50/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_50&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_51&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_52&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_51&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_51/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_51&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_52&quot;\\n  input: &quot;gradients/zeros_51/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_51&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_30&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_1/l1_conv2/Conv2D&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\240\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/Shape&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_30&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_30&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_31&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_32&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;nin_1/l1_conv1/Relu&quot;\\n  input: &quot;nin_1/l1_conv2/W/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/ShapeN&quot;\\n  input: &quot;nin_1/l1_conv2/W/read&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;nin_1/l1_conv1/Relu&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/nin_1/l1_conv2/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_1/l1_conv1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_33&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv2/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/Relu_grad/ReluGrad&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/cond_grad&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/cond_grad:1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_65&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_66&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_67&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_68&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_69&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm:1&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_70&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm:2&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_71&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like_72&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  op: &quot;FusedBatchNormGrad&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/Merge_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch:1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1:1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm:3&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;epsilon&quot;\\n    value {\\n      f: 0.0010000000475\\n    }\\n  }\\n  attr {\\n    key: &quot;is_training&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:2&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:3&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad:4&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/FusedBatchNormGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_52&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/add&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_53&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_52:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_52/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_52&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_53&quot;\\n  input: &quot;gradients/zeros_52/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_52&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_53&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_54&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_53:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_53/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_53&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_54&quot;\\n  input: &quot;gradients/zeros_53/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_53&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_54&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_55&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_54:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_54/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_54&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_55&quot;\\n  input: &quot;gradients/zeros_54/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_54&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_55&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/add&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_56&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_55&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_55/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_55&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_56&quot;\\n  input: &quot;gradients/zeros_55/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/zeros_55&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_56&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_57&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_56&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_56/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_56&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_57&quot;\\n  input: &quot;gradients/zeros_56/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/zeros_56&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Switch_57&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/read&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/cond/pred_id&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape_58&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Switch_57&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_57/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_57&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape_58&quot;\\n  input: &quot;gradients/zeros_57/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_grad/tuple/control_dependency_2&quot;\\n  input: &quot;gradients/zeros_57&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_34&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nin_1/l1_conv1/Conv2D&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\300\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/Shape&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_34&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/Sum&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN_34&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/Sum_1&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_35&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_1_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_36&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm/Switch_2_grad/cond_grad&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2_grad/cond_grad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;cond/Merge&quot;\\n  input: &quot;nin_1/l1_conv1/W/read&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/ShapeN&quot;\\n  input: &quot;nin_1/l1_conv1/W/read&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;cond/Merge&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/nin_1/l1_conv1/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_37&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/nin_1/l1_conv1/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.899999976158\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta1_power&quot;\\n  input: &quot;beta1_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta1_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;beta1_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.999000012875\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta2_power&quot;\\n  input: &quot;beta2_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta2_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;beta2_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/W/Adam&quot;\\n  input: &quot;nin_1/l1_conv1/W/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/W/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/W/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv1/W/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/W/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/W/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/b/Adam&quot;\\n  input: &quot;nin_1/l1_conv1/b/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/b/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/b/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv1/b/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/b/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/b/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/W/Adam&quot;\\n  input: &quot;nin_1/l1_conv2/W/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/W/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/W/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv2/W/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/W/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/W/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/b/Adam&quot;\\n  input: &quot;nin_1/l1_conv2/b/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/b/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/b/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv2/b/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/b/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/b/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 160\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 160\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 160\\n          }\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 160\\n        }\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/W/Adam&quot;\\n  input: &quot;nin_1/l1_conv3/W/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/W/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 160\\n          }\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 160\\n        }\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/W/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv3/W/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/W/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/W/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/b/Adam&quot;\\n  input: &quot;nin_1/l1_conv3/b/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/b/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/b/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv3/b/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/b/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/b/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 96\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 96\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 96\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 96\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/W/Adam&quot;\\n  input: &quot;nin_2/l2_conv1/W/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/W/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 96\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 96\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/W/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv1/W/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/W/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/W/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/b/Adam&quot;\\n  input: &quot;nin_2/l2_conv1/b/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/b/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/b/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv1/b/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/b/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/b/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/W/Adam&quot;\\n  input: &quot;nin_2/l2_conv2/W/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/W/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/W/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv2/W/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/W/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/W/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/b/Adam&quot;\\n  input: &quot;nin_2/l2_conv2/b/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/b/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/b/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv2/b/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/b/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/b/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/W/Adam&quot;\\n  input: &quot;nin_2/l2_conv3/W/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/W/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/W/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv3/W/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/W/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/W/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/b/Adam&quot;\\n  input: &quot;nin_2/l2_conv3/b/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/b/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/b/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv3/b/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/b/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/b/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/W/Adam&quot;\\n  input: &quot;nin_3/l3_conv1/W/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/W/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/W/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv1/W/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/W/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/W/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/b/Adam&quot;\\n  input: &quot;nin_3/l3_conv1/b/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/b/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/b/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv1/b/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/b/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/b/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/W/Adam&quot;\\n  input: &quot;nin_3/l3_conv2/W/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/W/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/W/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv2/W/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/W/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/W/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/b/Adam&quot;\\n  input: &quot;nin_3/l3_conv2/b/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/b/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/b/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv2/b/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/b/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/b/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 192\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 192\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/W/Adam&quot;\\n  input: &quot;nin_3/l3_conv3/W/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/W/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 192\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 192\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/W/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv3/W/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/W/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/W/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/b/Adam&quot;\\n  input: &quot;nin_3/l3_conv3/b/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/b/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/b/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv3/b/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/b/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/b/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/beta1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.899999976158\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/beta2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.999000012875\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/epsilon&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993923e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv1/W/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv1/W&quot;\\n  input: &quot;nin_1/l1_conv1/W/Adam&quot;\\n  input: &quot;nin_1/l1_conv1/W/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_37&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv1/b/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv1/b&quot;\\n  input: &quot;nin_1/l1_conv1/b/Adam&quot;\\n  input: &quot;nin_1/l1_conv1/b/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/nin_1/l1_conv1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_35&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_1/l1_conv1/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_36&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv2/W/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv2/W&quot;\\n  input: &quot;nin_1/l1_conv2/W/Adam&quot;\\n  input: &quot;nin_1/l1_conv2/W/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_33&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv2/b/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv2/b&quot;\\n  input: &quot;nin_1/l1_conv2/b/Adam&quot;\\n  input: &quot;nin_1/l1_conv2/b/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/nin_1/l1_conv2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_31&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_1/l1_conv2/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_32&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv3/W/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv3/W&quot;\\n  input: &quot;nin_1/l1_conv3/W/Adam&quot;\\n  input: &quot;nin_1/l1_conv3/W/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_29&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv3/b/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv3/b&quot;\\n  input: &quot;nin_1/l1_conv3/b/Adam&quot;\\n  input: &quot;nin_1/l1_conv3/b/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/nin_1/l1_conv3/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_27&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_1/l1_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_1/l1_conv3/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_28&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv1/W/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv1/W&quot;\\n  input: &quot;nin_2/l2_conv1/W/Adam&quot;\\n  input: &quot;nin_2/l2_conv1/W/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_24&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv1/b/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv1/b&quot;\\n  input: &quot;nin_2/l2_conv1/b/Adam&quot;\\n  input: &quot;nin_2/l2_conv1/b/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/nin_2/l2_conv1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_22&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_2/l2_conv1/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_23&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv2/W/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv2/W&quot;\\n  input: &quot;nin_2/l2_conv2/W/Adam&quot;\\n  input: &quot;nin_2/l2_conv2/W/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_20&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv2/b/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv2/b&quot;\\n  input: &quot;nin_2/l2_conv2/b/Adam&quot;\\n  input: &quot;nin_2/l2_conv2/b/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/nin_2/l2_conv2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_18&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_2/l2_conv2/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_19&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv3/W/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv3/W&quot;\\n  input: &quot;nin_2/l2_conv3/W/Adam&quot;\\n  input: &quot;nin_2/l2_conv3/W/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv3/b/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv3/b&quot;\\n  input: &quot;nin_2/l2_conv3/b/Adam&quot;\\n  input: &quot;nin_2/l2_conv3/b/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/nin_2/l2_conv3/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_2/l2_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_2/l2_conv3/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_2/l2_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv1/W/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv1/W&quot;\\n  input: &quot;nin_3/l3_conv1/W/Adam&quot;\\n  input: &quot;nin_3/l3_conv1/W/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv1/b/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv1/b&quot;\\n  input: &quot;nin_3/l3_conv1/b/Adam&quot;\\n  input: &quot;nin_3/l3_conv1/b/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/nin_3/l3_conv1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_3/l3_conv1/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv2/W/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv2/W&quot;\\n  input: &quot;nin_3/l3_conv2/W/Adam&quot;\\n  input: &quot;nin_3/l3_conv2/W/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv2/b/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv2/b&quot;\\n  input: &quot;nin_3/l3_conv2/b/Adam&quot;\\n  input: &quot;nin_3/l3_conv2/b/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/nin_3/l3_conv2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_3/l3_conv2/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv2/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv3/W/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv3/W&quot;\\n  input: &quot;nin_3/l3_conv3/W/Adam&quot;\\n  input: &quot;nin_3/l3_conv3/W/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv3/b/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv3/b&quot;\\n  input: &quot;nin_3/l3_conv3/b/Adam&quot;\\n  input: &quot;nin_3/l3_conv3/b/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/nin_3/l3_conv3/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/gamma/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/update_nin_3/l3_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam&quot;\\n  input: &quot;nin_3/l3_conv3/BatchNorm/beta/Adam_1&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;Adam/epsilon&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_3/l3_conv3/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;beta1_power/read&quot;\\n  input: &quot;Adam/beta1&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta1_power&quot;\\n  input: &quot;Adam/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;beta2_power/read&quot;\\n  input: &quot;Adam/beta2&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta2_power&quot;\\n  input: &quot;Adam/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@nin_1/l1_conv1/BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Adam&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_1/l1_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_2/l2_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv1/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv2/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg&quot;\\n  input: &quot;^nin_3/l3_conv3/BatchNorm/AssignMovingAvg_1&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_1/l1_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_2/l2_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv1/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv2/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/W/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/b/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/BatchNorm/gamma/ApplyAdam&quot;\\n  input: &quot;^Adam/update_nin_3/l3_conv3/BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^Adam/Assign&quot;\\n  input: &quot;^Adam/Assign_1&quot;\\n}\\nnode {\\n  name: &quot;ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;ArgMax&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Cast_1&quot;\\n  input: &quot;Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.0299383700682&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "model = YourModel()\n",
    "\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Start training  -----\n",
      "train for epoch 0\n",
      "iteration (0): loss = 2.456, accuracy = 0.109, ce = 2.314, wd = 0.142\n",
      "iteration (50): loss = 1.837, accuracy = 0.484, ce = 1.695, wd = 0.142\n",
      "iteration (100): loss = 1.754, accuracy = 0.477, ce = 1.613, wd = 0.141\n",
      "iteration (150): loss = 1.578, accuracy = 0.586, ce = 1.437, wd = 0.140\n",
      "iteration (200): loss = 1.565, accuracy = 0.555, ce = 1.426, wd = 0.139\n",
      "iteration (250): loss = 1.526, accuracy = 0.586, ce = 1.387, wd = 0.139\n",
      "iteration (300): loss = 1.433, accuracy = 0.625, ce = 1.294, wd = 0.138\n",
      "iteration (350): loss = 1.436, accuracy = 0.602, ce = 1.299, wd = 0.137\n",
      "total loss for epoch 0: 626.808\n",
      "validation for epoch 0\n",
      "-  epoch 0: validation accuracy = 0.129\n",
      "train for epoch 1\n",
      "iteration (400): loss = 1.389, accuracy = 0.633, ce = 1.252, wd = 0.137\n",
      "iteration (450): loss = 1.212, accuracy = 0.719, ce = 1.075, wd = 0.137\n",
      "iteration (500): loss = 1.312, accuracy = 0.688, ce = 1.176, wd = 0.137\n",
      "iteration (550): loss = 1.292, accuracy = 0.703, ce = 1.155, wd = 0.136\n",
      "iteration (600): loss = 1.205, accuracy = 0.656, ce = 1.069, wd = 0.136\n",
      "iteration (650): loss = 1.180, accuracy = 0.688, ce = 1.043, wd = 0.136\n",
      "iteration (700): loss = 1.225, accuracy = 0.680, ce = 1.089, wd = 0.136\n",
      "iteration (750): loss = 1.178, accuracy = 0.688, ce = 1.042, wd = 0.136\n",
      "total loss for epoch 1: 480.496\n",
      "validation for epoch 1\n",
      "-  epoch 1: validation accuracy = 0.482\n",
      "train for epoch 2\n",
      "iteration (800): loss = 1.090, accuracy = 0.711, ce = 0.954, wd = 0.136\n",
      "iteration (850): loss = 1.181, accuracy = 0.672, ce = 1.045, wd = 0.136\n",
      "iteration (900): loss = 1.063, accuracy = 0.742, ce = 0.926, wd = 0.136\n",
      "iteration (950): loss = 1.048, accuracy = 0.703, ce = 0.912, wd = 0.136\n",
      "iteration (1000): loss = 0.928, accuracy = 0.781, ce = 0.791, wd = 0.136\n",
      "iteration (1050): loss = 0.931, accuracy = 0.781, ce = 0.795, wd = 0.137\n",
      "iteration (1100): loss = 0.968, accuracy = 0.734, ce = 0.831, wd = 0.137\n",
      "total loss for epoch 2: 407.790\n",
      "validation for epoch 2\n",
      "-  epoch 2: validation accuracy = 0.533\n",
      "train for epoch 3\n",
      "iteration (1150): loss = 1.050, accuracy = 0.695, ce = 0.913, wd = 0.137\n",
      "iteration (1200): loss = 0.997, accuracy = 0.727, ce = 0.860, wd = 0.137\n",
      "iteration (1250): loss = 0.946, accuracy = 0.711, ce = 0.808, wd = 0.137\n",
      "iteration (1300): loss = 0.901, accuracy = 0.805, ce = 0.764, wd = 0.137\n",
      "iteration (1350): loss = 0.804, accuracy = 0.789, ce = 0.667, wd = 0.137\n",
      "iteration (1400): loss = 0.943, accuracy = 0.766, ce = 0.806, wd = 0.138\n",
      "iteration (1450): loss = 0.869, accuracy = 0.781, ce = 0.731, wd = 0.138\n",
      "iteration (1500): loss = 0.866, accuracy = 0.797, ce = 0.728, wd = 0.138\n",
      "total loss for epoch 3: 361.215\n",
      "validation for epoch 3\n",
      "-  epoch 3: validation accuracy = 0.694\n",
      "train for epoch 4\n",
      "iteration (1550): loss = 0.916, accuracy = 0.750, ce = 0.778, wd = 0.138\n",
      "iteration (1600): loss = 0.749, accuracy = 0.812, ce = 0.611, wd = 0.138\n",
      "iteration (1650): loss = 0.880, accuracy = 0.773, ce = 0.742, wd = 0.139\n",
      "iteration (1700): loss = 0.829, accuracy = 0.773, ce = 0.690, wd = 0.139\n",
      "iteration (1750): loss = 0.846, accuracy = 0.781, ce = 0.706, wd = 0.139\n",
      "iteration (1800): loss = 0.956, accuracy = 0.727, ce = 0.816, wd = 0.140\n",
      "iteration (1850): loss = 0.861, accuracy = 0.773, ce = 0.721, wd = 0.140\n",
      "iteration (1900): loss = 0.839, accuracy = 0.734, ce = 0.699, wd = 0.140\n",
      "total loss for epoch 4: 331.713\n",
      "validation for epoch 4\n",
      "-  epoch 4: validation accuracy = 0.732\n",
      "train for epoch 5\n",
      "iteration (1950): loss = 0.789, accuracy = 0.797, ce = 0.649, wd = 0.140\n",
      "iteration (2000): loss = 0.994, accuracy = 0.727, ce = 0.853, wd = 0.141\n",
      "iteration (2050): loss = 0.974, accuracy = 0.734, ce = 0.833, wd = 0.141\n",
      "iteration (2100): loss = 0.765, accuracy = 0.797, ce = 0.623, wd = 0.141\n",
      "iteration (2150): loss = 0.802, accuracy = 0.773, ce = 0.661, wd = 0.141\n",
      "iteration (2200): loss = 0.767, accuracy = 0.805, ce = 0.625, wd = 0.141\n",
      "iteration (2250): loss = 0.758, accuracy = 0.812, ce = 0.616, wd = 0.142\n",
      "total loss for epoch 5: 308.029\n",
      "validation for epoch 5\n",
      "-  epoch 5: validation accuracy = 0.739\n",
      "train for epoch 6\n",
      "iteration (2300): loss = 0.742, accuracy = 0.820, ce = 0.600, wd = 0.142\n",
      "iteration (2350): loss = 0.842, accuracy = 0.773, ce = 0.700, wd = 0.142\n",
      "iteration (2400): loss = 0.798, accuracy = 0.789, ce = 0.656, wd = 0.142\n",
      "iteration (2450): loss = 0.838, accuracy = 0.773, ce = 0.696, wd = 0.143\n",
      "iteration (2500): loss = 0.764, accuracy = 0.828, ce = 0.621, wd = 0.143\n",
      "iteration (2550): loss = 0.800, accuracy = 0.781, ce = 0.657, wd = 0.143\n",
      "iteration (2600): loss = 0.611, accuracy = 0.844, ce = 0.468, wd = 0.143\n",
      "iteration (2650): loss = 0.733, accuracy = 0.805, ce = 0.590, wd = 0.144\n",
      "total loss for epoch 6: 291.498\n",
      "validation for epoch 6\n",
      "-  epoch 6: validation accuracy = 0.647\n",
      "train for epoch 7\n",
      "iteration (2700): loss = 0.757, accuracy = 0.812, ce = 0.613, wd = 0.144\n",
      "iteration (2750): loss = 0.680, accuracy = 0.836, ce = 0.536, wd = 0.144\n",
      "iteration (2800): loss = 0.775, accuracy = 0.789, ce = 0.630, wd = 0.144\n",
      "iteration (2850): loss = 0.634, accuracy = 0.867, ce = 0.490, wd = 0.145\n",
      "iteration (2900): loss = 0.794, accuracy = 0.797, ce = 0.649, wd = 0.145\n",
      "iteration (2950): loss = 0.599, accuracy = 0.883, ce = 0.454, wd = 0.145\n",
      "iteration (3000): loss = 0.719, accuracy = 0.773, ce = 0.573, wd = 0.145\n",
      "iteration (3050): loss = 0.802, accuracy = 0.758, ce = 0.657, wd = 0.146\n",
      "total loss for epoch 7: 274.349\n",
      "validation for epoch 7\n",
      "-  epoch 7: validation accuracy = 0.761\n",
      "train for epoch 8\n",
      "iteration (3100): loss = 0.878, accuracy = 0.758, ce = 0.732, wd = 0.146\n",
      "iteration (3150): loss = 0.737, accuracy = 0.828, ce = 0.590, wd = 0.146\n",
      "iteration (3200): loss = 0.627, accuracy = 0.859, ce = 0.481, wd = 0.146\n",
      "iteration (3250): loss = 0.520, accuracy = 0.891, ce = 0.373, wd = 0.147\n",
      "iteration (3300): loss = 0.693, accuracy = 0.859, ce = 0.546, wd = 0.147\n",
      "iteration (3350): loss = 0.855, accuracy = 0.727, ce = 0.708, wd = 0.147\n",
      "iteration (3400): loss = 0.542, accuracy = 0.898, ce = 0.394, wd = 0.147\n",
      "total loss for epoch 8: 264.509\n",
      "validation for epoch 8\n",
      "-  epoch 8: validation accuracy = 0.799\n",
      "train for epoch 9\n",
      "iteration (3450): loss = 0.568, accuracy = 0.883, ce = 0.420, wd = 0.148\n",
      "iteration (3500): loss = 0.745, accuracy = 0.797, ce = 0.597, wd = 0.148\n",
      "iteration (3550): loss = 0.692, accuracy = 0.828, ce = 0.543, wd = 0.148\n",
      "iteration (3600): loss = 0.678, accuracy = 0.805, ce = 0.529, wd = 0.148\n",
      "iteration (3650): loss = 0.645, accuracy = 0.875, ce = 0.496, wd = 0.149\n",
      "iteration (3700): loss = 0.776, accuracy = 0.750, ce = 0.627, wd = 0.149\n",
      "iteration (3750): loss = 0.762, accuracy = 0.805, ce = 0.613, wd = 0.149\n",
      "iteration (3800): loss = 0.790, accuracy = 0.828, ce = 0.641, wd = 0.150\n",
      "total loss for epoch 9: 257.384\n",
      "validation for epoch 9\n",
      "-  epoch 9: validation accuracy = 0.730\n",
      "train for epoch 10\n",
      "iteration (3850): loss = 0.633, accuracy = 0.859, ce = 0.483, wd = 0.150\n",
      "iteration (3900): loss = 0.653, accuracy = 0.859, ce = 0.503, wd = 0.150\n",
      "iteration (3950): loss = 0.592, accuracy = 0.891, ce = 0.442, wd = 0.150\n",
      "iteration (4000): loss = 0.694, accuracy = 0.828, ce = 0.544, wd = 0.150\n",
      "iteration (4050): loss = 0.627, accuracy = 0.836, ce = 0.477, wd = 0.151\n",
      "iteration (4100): loss = 0.695, accuracy = 0.820, ce = 0.544, wd = 0.151\n",
      "iteration (4150): loss = 0.503, accuracy = 0.898, ce = 0.352, wd = 0.151\n",
      "iteration (4200): loss = 0.752, accuracy = 0.773, ce = 0.601, wd = 0.152\n",
      "total loss for epoch 10: 246.897\n",
      "validation for epoch 10\n",
      "-  epoch 10: validation accuracy = 0.712\n",
      "train for epoch 11\n",
      "iteration (4250): loss = 0.608, accuracy = 0.828, ce = 0.456, wd = 0.152\n",
      "iteration (4300): loss = 0.500, accuracy = 0.898, ce = 0.348, wd = 0.152\n",
      "iteration (4350): loss = 0.660, accuracy = 0.805, ce = 0.508, wd = 0.152\n",
      "iteration (4400): loss = 0.669, accuracy = 0.836, ce = 0.517, wd = 0.152\n",
      "iteration (4450): loss = 0.572, accuracy = 0.852, ce = 0.419, wd = 0.152\n",
      "iteration (4500): loss = 0.602, accuracy = 0.844, ce = 0.449, wd = 0.153\n",
      "iteration (4550): loss = 0.744, accuracy = 0.820, ce = 0.592, wd = 0.153\n",
      "total loss for epoch 11: 239.968\n",
      "validation for epoch 11\n",
      "-  epoch 11: validation accuracy = 0.744\n",
      "train for epoch 12\n",
      "iteration (4600): loss = 0.732, accuracy = 0.805, ce = 0.579, wd = 0.153\n",
      "iteration (4650): loss = 0.590, accuracy = 0.875, ce = 0.437, wd = 0.153\n",
      "iteration (4700): loss = 0.467, accuracy = 0.922, ce = 0.314, wd = 0.154\n",
      "iteration (4750): loss = 0.597, accuracy = 0.844, ce = 0.443, wd = 0.154\n",
      "iteration (4800): loss = 0.656, accuracy = 0.820, ce = 0.502, wd = 0.154\n",
      "iteration (4850): loss = 0.572, accuracy = 0.867, ce = 0.418, wd = 0.154\n",
      "iteration (4900): loss = 0.720, accuracy = 0.836, ce = 0.566, wd = 0.154\n",
      "iteration (4950): loss = 0.750, accuracy = 0.773, ce = 0.596, wd = 0.155\n",
      "total loss for epoch 12: 233.552\n",
      "validation for epoch 12\n",
      "-  epoch 12: validation accuracy = 0.754\n",
      "train for epoch 13\n",
      "iteration (5000): loss = 0.506, accuracy = 0.891, ce = 0.351, wd = 0.155\n",
      "iteration (5050): loss = 0.534, accuracy = 0.898, ce = 0.379, wd = 0.155\n",
      "iteration (5100): loss = 0.505, accuracy = 0.883, ce = 0.350, wd = 0.155\n",
      "iteration (5150): loss = 0.574, accuracy = 0.875, ce = 0.419, wd = 0.155\n",
      "iteration (5200): loss = 0.584, accuracy = 0.867, ce = 0.429, wd = 0.155\n",
      "iteration (5250): loss = 0.525, accuracy = 0.883, ce = 0.369, wd = 0.156\n",
      "iteration (5300): loss = 0.688, accuracy = 0.844, ce = 0.532, wd = 0.156\n",
      "total loss for epoch 13: 226.138\n",
      "validation for epoch 13\n",
      "-  epoch 13: validation accuracy = 0.705\n",
      "train for epoch 14\n",
      "iteration (5350): loss = 0.595, accuracy = 0.883, ce = 0.439, wd = 0.156\n",
      "iteration (5400): loss = 0.550, accuracy = 0.867, ce = 0.394, wd = 0.156\n",
      "iteration (5450): loss = 0.480, accuracy = 0.898, ce = 0.324, wd = 0.156\n",
      "iteration (5500): loss = 0.460, accuracy = 0.906, ce = 0.303, wd = 0.157\n",
      "iteration (5550): loss = 0.622, accuracy = 0.836, ce = 0.465, wd = 0.157\n",
      "iteration (5600): loss = 0.600, accuracy = 0.875, ce = 0.443, wd = 0.157\n",
      "iteration (5650): loss = 0.552, accuracy = 0.875, ce = 0.394, wd = 0.157\n",
      "iteration (5700): loss = 0.497, accuracy = 0.891, ce = 0.340, wd = 0.158\n",
      "total loss for epoch 14: 220.651\n",
      "validation for epoch 14\n",
      "-  epoch 14: validation accuracy = 0.840\n",
      "meet better model, save model...\n",
      "train for epoch 15\n",
      "iteration (5750): loss = 0.595, accuracy = 0.875, ce = 0.437, wd = 0.158\n",
      "iteration (5800): loss = 0.530, accuracy = 0.852, ce = 0.373, wd = 0.158\n",
      "iteration (5850): loss = 0.614, accuracy = 0.844, ce = 0.456, wd = 0.158\n",
      "iteration (5900): loss = 0.606, accuracy = 0.859, ce = 0.448, wd = 0.158\n",
      "iteration (5950): loss = 0.597, accuracy = 0.844, ce = 0.439, wd = 0.158\n",
      "iteration (6000): loss = 0.533, accuracy = 0.883, ce = 0.374, wd = 0.159\n",
      "iteration (6050): loss = 0.531, accuracy = 0.859, ce = 0.372, wd = 0.159\n",
      "iteration (6100): loss = 0.499, accuracy = 0.883, ce = 0.340, wd = 0.159\n",
      "total loss for epoch 15: 214.412\n",
      "validation for epoch 15\n",
      "-  epoch 15: validation accuracy = 0.833\n",
      "train for epoch 16\n",
      "iteration (6150): loss = 0.553, accuracy = 0.906, ce = 0.394, wd = 0.159\n",
      "iteration (6200): loss = 0.523, accuracy = 0.867, ce = 0.363, wd = 0.159\n",
      "iteration (6250): loss = 0.468, accuracy = 0.930, ce = 0.309, wd = 0.160\n",
      "iteration (6300): loss = 0.552, accuracy = 0.891, ce = 0.392, wd = 0.160\n",
      "iteration (6350): loss = 0.512, accuracy = 0.891, ce = 0.352, wd = 0.160\n",
      "iteration (6400): loss = 0.647, accuracy = 0.844, ce = 0.487, wd = 0.160\n",
      "iteration (6450): loss = 0.531, accuracy = 0.906, ce = 0.370, wd = 0.161\n",
      "total loss for epoch 16: 212.119\n",
      "validation for epoch 16\n",
      "-  epoch 16: validation accuracy = 0.819\n",
      "train for epoch 17\n",
      "iteration (6500): loss = 0.515, accuracy = 0.875, ce = 0.354, wd = 0.161\n",
      "iteration (6550): loss = 0.574, accuracy = 0.867, ce = 0.413, wd = 0.161\n",
      "iteration (6600): loss = 0.544, accuracy = 0.852, ce = 0.382, wd = 0.161\n",
      "iteration (6650): loss = 0.507, accuracy = 0.906, ce = 0.346, wd = 0.161\n",
      "iteration (6700): loss = 0.541, accuracy = 0.859, ce = 0.379, wd = 0.161\n",
      "iteration (6750): loss = 0.530, accuracy = 0.906, ce = 0.369, wd = 0.162\n",
      "iteration (6800): loss = 0.562, accuracy = 0.883, ce = 0.400, wd = 0.162\n",
      "iteration (6850): loss = 0.575, accuracy = 0.898, ce = 0.413, wd = 0.162\n",
      "total loss for epoch 17: 207.960\n",
      "validation for epoch 17\n",
      "-  epoch 17: validation accuracy = 0.837\n",
      "train for epoch 18\n",
      "iteration (6900): loss = 0.611, accuracy = 0.867, ce = 0.448, wd = 0.162\n",
      "iteration (6950): loss = 0.561, accuracy = 0.891, ce = 0.398, wd = 0.162\n",
      "iteration (7000): loss = 0.511, accuracy = 0.891, ce = 0.348, wd = 0.163\n",
      "iteration (7050): loss = 0.546, accuracy = 0.898, ce = 0.383, wd = 0.163\n",
      "iteration (7100): loss = 0.477, accuracy = 0.891, ce = 0.314, wd = 0.163\n",
      "iteration (7150): loss = 0.551, accuracy = 0.859, ce = 0.388, wd = 0.163\n",
      "iteration (7200): loss = 0.510, accuracy = 0.891, ce = 0.346, wd = 0.163\n",
      "iteration (7250): loss = 0.430, accuracy = 0.914, ce = 0.266, wd = 0.164\n",
      "total loss for epoch 18: 205.609\n",
      "validation for epoch 18\n",
      "-  epoch 18: validation accuracy = 0.805\n",
      "train for epoch 19\n",
      "iteration (7300): loss = 0.548, accuracy = 0.891, ce = 0.384, wd = 0.164\n",
      "iteration (7350): loss = 0.499, accuracy = 0.898, ce = 0.336, wd = 0.164\n",
      "iteration (7400): loss = 0.456, accuracy = 0.930, ce = 0.292, wd = 0.164\n",
      "iteration (7450): loss = 0.505, accuracy = 0.898, ce = 0.341, wd = 0.164\n",
      "iteration (7500): loss = 0.446, accuracy = 0.914, ce = 0.281, wd = 0.164\n",
      "iteration (7550): loss = 0.574, accuracy = 0.859, ce = 0.410, wd = 0.164\n",
      "iteration (7600): loss = 0.525, accuracy = 0.844, ce = 0.360, wd = 0.165\n",
      "total loss for epoch 19: 201.752\n",
      "validation for epoch 19\n",
      "-  epoch 19: validation accuracy = 0.846\n",
      "meet better model, save model...\n",
      "train for epoch 20\n",
      "iteration (7650): loss = 0.506, accuracy = 0.883, ce = 0.341, wd = 0.165\n",
      "iteration (7700): loss = 0.524, accuracy = 0.883, ce = 0.359, wd = 0.165\n",
      "iteration (7750): loss = 0.506, accuracy = 0.898, ce = 0.341, wd = 0.165\n",
      "iteration (7800): loss = 0.510, accuracy = 0.875, ce = 0.345, wd = 0.165\n",
      "iteration (7850): loss = 0.408, accuracy = 0.930, ce = 0.243, wd = 0.165\n",
      "iteration (7900): loss = 0.606, accuracy = 0.844, ce = 0.441, wd = 0.166\n",
      "iteration (7950): loss = 0.422, accuracy = 0.906, ce = 0.256, wd = 0.166\n",
      "iteration (8000): loss = 0.556, accuracy = 0.875, ce = 0.390, wd = 0.166\n",
      "total loss for epoch 20: 199.237\n",
      "validation for epoch 20\n",
      "-  epoch 20: validation accuracy = 0.827\n",
      "train for epoch 21\n",
      "iteration (8050): loss = 0.526, accuracy = 0.891, ce = 0.360, wd = 0.166\n",
      "iteration (8100): loss = 0.336, accuracy = 0.961, ce = 0.170, wd = 0.166\n",
      "iteration (8150): loss = 0.501, accuracy = 0.883, ce = 0.335, wd = 0.166\n",
      "iteration (8200): loss = 0.549, accuracy = 0.852, ce = 0.382, wd = 0.167\n",
      "iteration (8250): loss = 0.457, accuracy = 0.906, ce = 0.290, wd = 0.167\n",
      "iteration (8300): loss = 0.538, accuracy = 0.844, ce = 0.371, wd = 0.167\n",
      "iteration (8350): loss = 0.493, accuracy = 0.914, ce = 0.326, wd = 0.167\n",
      "iteration (8400): loss = 0.553, accuracy = 0.883, ce = 0.385, wd = 0.167\n",
      "total loss for epoch 21: 196.458\n",
      "validation for epoch 21\n",
      "-  epoch 21: validation accuracy = 0.798\n",
      "train for epoch 22\n",
      "iteration (8450): loss = 0.496, accuracy = 0.883, ce = 0.329, wd = 0.167\n",
      "iteration (8500): loss = 0.537, accuracy = 0.875, ce = 0.369, wd = 0.167\n",
      "iteration (8550): loss = 0.498, accuracy = 0.898, ce = 0.330, wd = 0.168\n",
      "iteration (8600): loss = 0.487, accuracy = 0.906, ce = 0.319, wd = 0.168\n",
      "iteration (8650): loss = 0.459, accuracy = 0.914, ce = 0.291, wd = 0.168\n",
      "iteration (8700): loss = 0.526, accuracy = 0.875, ce = 0.357, wd = 0.168\n",
      "iteration (8750): loss = 0.636, accuracy = 0.836, ce = 0.468, wd = 0.169\n",
      "total loss for epoch 22: 195.136\n",
      "validation for epoch 22\n",
      "-  epoch 22: validation accuracy = 0.850\n",
      "meet better model, save model...\n",
      "train for epoch 23\n",
      "iteration (8800): loss = 0.692, accuracy = 0.789, ce = 0.523, wd = 0.169\n",
      "iteration (8850): loss = 0.508, accuracy = 0.906, ce = 0.339, wd = 0.169\n",
      "iteration (8900): loss = 0.474, accuracy = 0.883, ce = 0.305, wd = 0.169\n",
      "iteration (8950): loss = 0.428, accuracy = 0.930, ce = 0.259, wd = 0.169\n",
      "iteration (9000): loss = 0.660, accuracy = 0.844, ce = 0.490, wd = 0.169\n",
      "iteration (9050): loss = 0.479, accuracy = 0.891, ce = 0.309, wd = 0.170\n",
      "iteration (9100): loss = 0.528, accuracy = 0.898, ce = 0.358, wd = 0.170\n",
      "iteration (9150): loss = 0.522, accuracy = 0.891, ce = 0.352, wd = 0.170\n",
      "total loss for epoch 23: 191.108\n",
      "validation for epoch 23\n",
      "-  epoch 23: validation accuracy = 0.863\n",
      "meet better model, save model...\n",
      "train for epoch 24\n",
      "iteration (9200): loss = 0.461, accuracy = 0.867, ce = 0.291, wd = 0.170\n",
      "iteration (9250): loss = 0.493, accuracy = 0.883, ce = 0.322, wd = 0.170\n",
      "iteration (9300): loss = 0.437, accuracy = 0.922, ce = 0.267, wd = 0.170\n",
      "iteration (9350): loss = 0.519, accuracy = 0.914, ce = 0.349, wd = 0.170\n",
      "iteration (9400): loss = 0.506, accuracy = 0.867, ce = 0.335, wd = 0.171\n",
      "iteration (9450): loss = 0.594, accuracy = 0.875, ce = 0.423, wd = 0.171\n",
      "iteration (9500): loss = 0.635, accuracy = 0.836, ce = 0.464, wd = 0.171\n",
      "total loss for epoch 24: 188.652\n",
      "validation for epoch 24\n",
      "-  epoch 24: validation accuracy = 0.815\n",
      "train for epoch 25\n",
      "iteration (9550): loss = 0.479, accuracy = 0.891, ce = 0.308, wd = 0.171\n",
      "iteration (9600): loss = 0.481, accuracy = 0.891, ce = 0.309, wd = 0.171\n",
      "iteration (9650): loss = 0.479, accuracy = 0.906, ce = 0.308, wd = 0.171\n",
      "iteration (9700): loss = 0.416, accuracy = 0.930, ce = 0.244, wd = 0.172\n",
      "iteration (9750): loss = 0.480, accuracy = 0.930, ce = 0.308, wd = 0.172\n",
      "iteration (9800): loss = 0.454, accuracy = 0.891, ce = 0.282, wd = 0.172\n",
      "iteration (9850): loss = 0.424, accuracy = 0.891, ce = 0.252, wd = 0.172\n",
      "iteration (9900): loss = 0.465, accuracy = 0.906, ce = 0.293, wd = 0.172\n",
      "total loss for epoch 25: 187.865\n",
      "validation for epoch 25\n",
      "-  epoch 25: validation accuracy = 0.853\n",
      "train for epoch 26\n",
      "iteration (9950): loss = 0.538, accuracy = 0.875, ce = 0.366, wd = 0.172\n",
      "iteration (10000): loss = 0.405, accuracy = 0.938, ce = 0.233, wd = 0.172\n",
      "iteration (10050): loss = 0.377, accuracy = 0.938, ce = 0.204, wd = 0.172\n",
      "iteration (10100): loss = 0.531, accuracy = 0.875, ce = 0.358, wd = 0.173\n",
      "iteration (10150): loss = 0.464, accuracy = 0.914, ce = 0.291, wd = 0.173\n",
      "iteration (10200): loss = 0.451, accuracy = 0.891, ce = 0.278, wd = 0.173\n",
      "iteration (10250): loss = 0.531, accuracy = 0.891, ce = 0.358, wd = 0.173\n",
      "iteration (10300): loss = 0.531, accuracy = 0.875, ce = 0.358, wd = 0.173\n",
      "total loss for epoch 26: 184.395\n",
      "validation for epoch 26\n",
      "-  epoch 26: validation accuracy = 0.838\n",
      "train for epoch 27\n",
      "iteration (10350): loss = 0.447, accuracy = 0.922, ce = 0.274, wd = 0.173\n",
      "iteration (10400): loss = 0.445, accuracy = 0.914, ce = 0.271, wd = 0.173\n",
      "iteration (10450): loss = 0.438, accuracy = 0.906, ce = 0.265, wd = 0.174\n",
      "iteration (10500): loss = 0.600, accuracy = 0.844, ce = 0.426, wd = 0.174\n",
      "iteration (10550): loss = 0.552, accuracy = 0.875, ce = 0.378, wd = 0.174\n",
      "iteration (10600): loss = 0.554, accuracy = 0.875, ce = 0.380, wd = 0.174\n",
      "iteration (10650): loss = 0.520, accuracy = 0.891, ce = 0.345, wd = 0.174\n",
      "total loss for epoch 27: 184.649\n",
      "validation for epoch 27\n",
      "-  epoch 27: validation accuracy = 0.840\n",
      "train for epoch 28\n",
      "iteration (10700): loss = 0.635, accuracy = 0.852, ce = 0.460, wd = 0.175\n",
      "iteration (10750): loss = 0.518, accuracy = 0.898, ce = 0.343, wd = 0.175\n",
      "iteration (10800): loss = 0.401, accuracy = 0.922, ce = 0.226, wd = 0.175\n",
      "iteration (10850): loss = 0.495, accuracy = 0.914, ce = 0.320, wd = 0.175\n",
      "iteration (10900): loss = 0.438, accuracy = 0.906, ce = 0.262, wd = 0.175\n",
      "iteration (10950): loss = 0.506, accuracy = 0.883, ce = 0.331, wd = 0.175\n",
      "iteration (11000): loss = 0.486, accuracy = 0.906, ce = 0.311, wd = 0.176\n",
      "iteration (11050): loss = 0.440, accuracy = 0.914, ce = 0.264, wd = 0.176\n",
      "total loss for epoch 28: 180.750\n",
      "validation for epoch 28\n",
      "-  epoch 28: validation accuracy = 0.834\n",
      "train for epoch 29\n",
      "iteration (11100): loss = 0.497, accuracy = 0.898, ce = 0.321, wd = 0.176\n",
      "iteration (11150): loss = 0.433, accuracy = 0.891, ce = 0.257, wd = 0.176\n",
      "iteration (11200): loss = 0.441, accuracy = 0.898, ce = 0.265, wd = 0.176\n",
      "iteration (11250): loss = 0.426, accuracy = 0.906, ce = 0.251, wd = 0.176\n",
      "iteration (11300): loss = 0.577, accuracy = 0.867, ce = 0.401, wd = 0.176\n",
      "iteration (11350): loss = 0.480, accuracy = 0.922, ce = 0.303, wd = 0.176\n",
      "iteration (11400): loss = 0.556, accuracy = 0.859, ce = 0.380, wd = 0.177\n",
      "iteration (11450): loss = 0.520, accuracy = 0.883, ce = 0.343, wd = 0.177\n",
      "total loss for epoch 29: 179.659\n",
      "validation for epoch 29\n",
      "-  epoch 29: validation accuracy = 0.844\n",
      "train for epoch 30\n",
      "iteration (11500): loss = 0.448, accuracy = 0.906, ce = 0.271, wd = 0.177\n",
      "iteration (11550): loss = 0.568, accuracy = 0.883, ce = 0.391, wd = 0.177\n",
      "iteration (11600): loss = 0.391, accuracy = 0.938, ce = 0.214, wd = 0.177\n",
      "iteration (11650): loss = 0.476, accuracy = 0.914, ce = 0.299, wd = 0.177\n",
      "iteration (11700): loss = 0.519, accuracy = 0.898, ce = 0.341, wd = 0.177\n",
      "iteration (11750): loss = 0.547, accuracy = 0.844, ce = 0.369, wd = 0.178\n",
      "iteration (11800): loss = 0.432, accuracy = 0.938, ce = 0.254, wd = 0.178\n",
      "total loss for epoch 30: 177.976\n",
      "validation for epoch 30\n",
      "-  epoch 30: validation accuracy = 0.836\n",
      "train for epoch 31\n",
      "iteration (11850): loss = 0.446, accuracy = 0.930, ce = 0.268, wd = 0.178\n",
      "iteration (11900): loss = 0.426, accuracy = 0.922, ce = 0.248, wd = 0.178\n",
      "iteration (11950): loss = 0.431, accuracy = 0.906, ce = 0.253, wd = 0.178\n",
      "iteration (12000): loss = 0.360, accuracy = 0.945, ce = 0.182, wd = 0.178\n",
      "iteration (12050): loss = 0.438, accuracy = 0.930, ce = 0.260, wd = 0.178\n",
      "iteration (12100): loss = 0.462, accuracy = 0.906, ce = 0.284, wd = 0.178\n",
      "iteration (12150): loss = 0.427, accuracy = 0.898, ce = 0.249, wd = 0.179\n",
      "iteration (12200): loss = 0.584, accuracy = 0.875, ce = 0.405, wd = 0.179\n",
      "total loss for epoch 31: 178.277\n",
      "validation for epoch 31\n",
      "-  epoch 31: validation accuracy = 0.837\n",
      "train for epoch 32\n",
      "iteration (12250): loss = 0.415, accuracy = 0.922, ce = 0.236, wd = 0.179\n",
      "iteration (12300): loss = 0.455, accuracy = 0.930, ce = 0.276, wd = 0.179\n",
      "iteration (12350): loss = 0.468, accuracy = 0.906, ce = 0.289, wd = 0.179\n",
      "iteration (12400): loss = 0.414, accuracy = 0.898, ce = 0.235, wd = 0.179\n",
      "iteration (12450): loss = 0.438, accuracy = 0.898, ce = 0.259, wd = 0.179\n",
      "iteration (12500): loss = 0.462, accuracy = 0.898, ce = 0.282, wd = 0.179\n",
      "iteration (12550): loss = 0.378, accuracy = 0.930, ce = 0.199, wd = 0.180\n",
      "iteration (12600): loss = 0.449, accuracy = 0.922, ce = 0.270, wd = 0.179\n",
      "total loss for epoch 32: 175.116\n",
      "validation for epoch 32\n",
      "-  epoch 32: validation accuracy = 0.874\n",
      "meet better model, save model...\n",
      "train for epoch 33\n",
      "iteration (12650): loss = 0.510, accuracy = 0.891, ce = 0.331, wd = 0.180\n",
      "iteration (12700): loss = 0.468, accuracy = 0.914, ce = 0.288, wd = 0.179\n",
      "iteration (12750): loss = 0.519, accuracy = 0.883, ce = 0.340, wd = 0.180\n",
      "iteration (12800): loss = 0.452, accuracy = 0.891, ce = 0.272, wd = 0.180\n",
      "iteration (12850): loss = 0.590, accuracy = 0.852, ce = 0.410, wd = 0.180\n",
      "iteration (12900): loss = 0.429, accuracy = 0.914, ce = 0.249, wd = 0.180\n",
      "iteration (12950): loss = 0.449, accuracy = 0.914, ce = 0.268, wd = 0.181\n",
      "total loss for epoch 33: 174.966\n",
      "validation for epoch 33\n",
      "-  epoch 33: validation accuracy = 0.843\n",
      "train for epoch 34\n",
      "iteration (13000): loss = 0.363, accuracy = 0.938, ce = 0.182, wd = 0.181\n",
      "iteration (13050): loss = 0.369, accuracy = 0.906, ce = 0.188, wd = 0.180\n",
      "iteration (13100): loss = 0.516, accuracy = 0.867, ce = 0.335, wd = 0.180\n",
      "iteration (13150): loss = 0.411, accuracy = 0.930, ce = 0.230, wd = 0.181\n",
      "iteration (13200): loss = 0.489, accuracy = 0.914, ce = 0.309, wd = 0.181\n",
      "iteration (13250): loss = 0.498, accuracy = 0.914, ce = 0.317, wd = 0.181\n",
      "iteration (13300): loss = 0.428, accuracy = 0.914, ce = 0.247, wd = 0.181\n",
      "iteration (13350): loss = 0.469, accuracy = 0.914, ce = 0.287, wd = 0.181\n",
      "total loss for epoch 34: 174.230\n",
      "validation for epoch 34\n",
      "-  epoch 34: validation accuracy = 0.835\n",
      "train for epoch 35\n",
      "iteration (13400): loss = 0.482, accuracy = 0.914, ce = 0.301, wd = 0.181\n",
      "iteration (13450): loss = 0.454, accuracy = 0.891, ce = 0.273, wd = 0.181\n",
      "iteration (13500): loss = 0.520, accuracy = 0.883, ce = 0.339, wd = 0.181\n",
      "iteration (13550): loss = 0.540, accuracy = 0.891, ce = 0.358, wd = 0.182\n",
      "iteration (13600): loss = 0.378, accuracy = 0.938, ce = 0.197, wd = 0.182\n",
      "iteration (13650): loss = 0.445, accuracy = 0.883, ce = 0.263, wd = 0.182\n",
      "iteration (13700): loss = 0.480, accuracy = 0.898, ce = 0.298, wd = 0.182\n",
      "iteration (13750): loss = 0.380, accuracy = 0.938, ce = 0.197, wd = 0.182\n",
      "total loss for epoch 35: 172.234\n",
      "validation for epoch 35\n",
      "-  epoch 35: validation accuracy = 0.831\n",
      "train for epoch 36\n",
      "iteration (13800): loss = 0.520, accuracy = 0.867, ce = 0.338, wd = 0.182\n",
      "iteration (13850): loss = 0.315, accuracy = 0.961, ce = 0.133, wd = 0.182\n",
      "iteration (13900): loss = 0.431, accuracy = 0.922, ce = 0.249, wd = 0.182\n",
      "iteration (13950): loss = 0.436, accuracy = 0.945, ce = 0.254, wd = 0.182\n",
      "iteration (14000): loss = 0.510, accuracy = 0.883, ce = 0.327, wd = 0.183\n",
      "iteration (14050): loss = 0.430, accuracy = 0.906, ce = 0.247, wd = 0.183\n",
      "iteration (14100): loss = 0.492, accuracy = 0.914, ce = 0.309, wd = 0.183\n",
      "total loss for epoch 36: 169.863\n",
      "validation for epoch 36\n",
      "-  epoch 36: validation accuracy = 0.847\n",
      "train for epoch 37\n",
      "iteration (14150): loss = 0.395, accuracy = 0.930, ce = 0.212, wd = 0.183\n",
      "iteration (14200): loss = 0.396, accuracy = 0.930, ce = 0.213, wd = 0.183\n",
      "iteration (14250): loss = 0.492, accuracy = 0.883, ce = 0.309, wd = 0.183\n",
      "iteration (14300): loss = 0.431, accuracy = 0.906, ce = 0.248, wd = 0.183\n",
      "iteration (14350): loss = 0.380, accuracy = 0.922, ce = 0.197, wd = 0.183\n",
      "iteration (14400): loss = 0.462, accuracy = 0.859, ce = 0.279, wd = 0.183\n",
      "iteration (14450): loss = 0.421, accuracy = 0.906, ce = 0.237, wd = 0.184\n",
      "iteration (14500): loss = 0.522, accuracy = 0.906, ce = 0.338, wd = 0.184\n",
      "total loss for epoch 37: 169.977\n",
      "validation for epoch 37\n",
      "-  epoch 37: validation accuracy = 0.795\n",
      "train for epoch 38\n",
      "iteration (14550): loss = 0.492, accuracy = 0.906, ce = 0.308, wd = 0.184\n",
      "iteration (14600): loss = 0.376, accuracy = 0.945, ce = 0.192, wd = 0.184\n",
      "iteration (14650): loss = 0.538, accuracy = 0.852, ce = 0.354, wd = 0.184\n",
      "iteration (14700): loss = 0.544, accuracy = 0.875, ce = 0.360, wd = 0.184\n",
      "iteration (14750): loss = 0.479, accuracy = 0.914, ce = 0.294, wd = 0.184\n",
      "iteration (14800): loss = 0.433, accuracy = 0.922, ce = 0.249, wd = 0.184\n",
      "iteration (14850): loss = 0.492, accuracy = 0.914, ce = 0.307, wd = 0.185\n",
      "total loss for epoch 38: 170.360\n",
      "validation for epoch 38\n",
      "-  epoch 38: validation accuracy = 0.867\n",
      "train for epoch 39\n",
      "iteration (14900): loss = 0.332, accuracy = 0.961, ce = 0.147, wd = 0.185\n",
      "iteration (14950): loss = 0.465, accuracy = 0.906, ce = 0.281, wd = 0.185\n",
      "iteration (15000): loss = 0.502, accuracy = 0.891, ce = 0.317, wd = 0.185\n",
      "iteration (15050): loss = 0.420, accuracy = 0.906, ce = 0.236, wd = 0.185\n",
      "iteration (15100): loss = 0.396, accuracy = 0.930, ce = 0.211, wd = 0.185\n",
      "iteration (15150): loss = 0.464, accuracy = 0.898, ce = 0.279, wd = 0.185\n",
      "iteration (15200): loss = 0.425, accuracy = 0.906, ce = 0.240, wd = 0.185\n",
      "iteration (15250): loss = 0.415, accuracy = 0.930, ce = 0.229, wd = 0.185\n",
      "total loss for epoch 39: 168.700\n",
      "validation for epoch 39\n",
      "-  epoch 39: validation accuracy = 0.855\n",
      "train for epoch 40\n",
      "iteration (15300): loss = 0.527, accuracy = 0.875, ce = 0.341, wd = 0.186\n",
      "iteration (15350): loss = 0.440, accuracy = 0.930, ce = 0.255, wd = 0.185\n",
      "iteration (15400): loss = 0.371, accuracy = 0.938, ce = 0.185, wd = 0.185\n",
      "iteration (15450): loss = 0.569, accuracy = 0.844, ce = 0.383, wd = 0.186\n",
      "iteration (15500): loss = 0.379, accuracy = 0.914, ce = 0.193, wd = 0.186\n",
      "iteration (15550): loss = 0.436, accuracy = 0.906, ce = 0.250, wd = 0.186\n",
      "iteration (15600): loss = 0.468, accuracy = 0.914, ce = 0.282, wd = 0.186\n",
      "iteration (15650): loss = 0.378, accuracy = 0.930, ce = 0.192, wd = 0.186\n",
      "total loss for epoch 40: 168.001\n",
      "validation for epoch 40\n",
      "-  epoch 40: validation accuracy = 0.859\n",
      "train for epoch 41\n",
      "iteration (15700): loss = 0.353, accuracy = 0.961, ce = 0.166, wd = 0.186\n",
      "iteration (15750): loss = 0.405, accuracy = 0.922, ce = 0.219, wd = 0.186\n",
      "iteration (15800): loss = 0.428, accuracy = 0.930, ce = 0.242, wd = 0.186\n",
      "iteration (15850): loss = 0.411, accuracy = 0.930, ce = 0.225, wd = 0.186\n",
      "iteration (15900): loss = 0.413, accuracy = 0.930, ce = 0.227, wd = 0.186\n",
      "iteration (15950): loss = 0.463, accuracy = 0.906, ce = 0.277, wd = 0.186\n",
      "iteration (16000): loss = 0.395, accuracy = 0.922, ce = 0.208, wd = 0.187\n",
      "total loss for epoch 41: 166.485\n",
      "validation for epoch 41\n",
      "-  epoch 41: validation accuracy = 0.849\n",
      "train for epoch 42\n",
      "iteration (16050): loss = 0.361, accuracy = 0.945, ce = 0.175, wd = 0.187\n",
      "iteration (16100): loss = 0.515, accuracy = 0.891, ce = 0.329, wd = 0.187\n",
      "iteration (16150): loss = 0.472, accuracy = 0.891, ce = 0.286, wd = 0.187\n",
      "iteration (16200): loss = 0.399, accuracy = 0.914, ce = 0.212, wd = 0.187\n",
      "iteration (16250): loss = 0.478, accuracy = 0.875, ce = 0.291, wd = 0.187\n",
      "iteration (16300): loss = 0.414, accuracy = 0.945, ce = 0.227, wd = 0.187\n",
      "iteration (16350): loss = 0.475, accuracy = 0.922, ce = 0.288, wd = 0.187\n",
      "iteration (16400): loss = 0.495, accuracy = 0.922, ce = 0.308, wd = 0.187\n",
      "total loss for epoch 42: 164.135\n",
      "validation for epoch 42\n",
      "-  epoch 42: validation accuracy = 0.855\n",
      "train for epoch 43\n",
      "iteration (16450): loss = 0.316, accuracy = 0.977, ce = 0.129, wd = 0.187\n",
      "iteration (16500): loss = 0.438, accuracy = 0.938, ce = 0.251, wd = 0.187\n",
      "iteration (16550): loss = 0.429, accuracy = 0.938, ce = 0.242, wd = 0.187\n",
      "iteration (16600): loss = 0.456, accuracy = 0.938, ce = 0.269, wd = 0.187\n",
      "iteration (16650): loss = 0.460, accuracy = 0.930, ce = 0.273, wd = 0.187\n",
      "iteration (16700): loss = 0.367, accuracy = 0.945, ce = 0.179, wd = 0.188\n",
      "iteration (16750): loss = 0.421, accuracy = 0.922, ce = 0.233, wd = 0.188\n",
      "iteration (16800): loss = 0.433, accuracy = 0.898, ce = 0.245, wd = 0.188\n",
      "total loss for epoch 43: 164.430\n",
      "validation for epoch 43\n",
      "-  epoch 43: validation accuracy = 0.828\n",
      "train for epoch 44\n",
      "iteration (16850): loss = 0.380, accuracy = 0.938, ce = 0.192, wd = 0.188\n",
      "iteration (16900): loss = 0.391, accuracy = 0.938, ce = 0.204, wd = 0.188\n",
      "iteration (16950): loss = 0.391, accuracy = 0.938, ce = 0.203, wd = 0.188\n",
      "iteration (17000): loss = 0.439, accuracy = 0.922, ce = 0.252, wd = 0.188\n",
      "iteration (17050): loss = 0.520, accuracy = 0.891, ce = 0.332, wd = 0.188\n",
      "iteration (17100): loss = 0.475, accuracy = 0.914, ce = 0.287, wd = 0.188\n",
      "iteration (17150): loss = 0.447, accuracy = 0.922, ce = 0.259, wd = 0.188\n",
      "total loss for epoch 44: 163.674\n",
      "validation for epoch 44\n",
      "-  epoch 44: validation accuracy = 0.858\n",
      "train for epoch 45\n",
      "iteration (17200): loss = 0.379, accuracy = 0.945, ce = 0.191, wd = 0.188\n",
      "iteration (17250): loss = 0.393, accuracy = 0.922, ce = 0.205, wd = 0.188\n",
      "iteration (17300): loss = 0.471, accuracy = 0.891, ce = 0.283, wd = 0.188\n",
      "iteration (17350): loss = 0.397, accuracy = 0.930, ce = 0.209, wd = 0.188\n",
      "iteration (17400): loss = 0.394, accuracy = 0.922, ce = 0.205, wd = 0.188\n",
      "iteration (17450): loss = 0.426, accuracy = 0.922, ce = 0.238, wd = 0.188\n",
      "iteration (17500): loss = 0.360, accuracy = 0.945, ce = 0.172, wd = 0.188\n",
      "iteration (17550): loss = 0.393, accuracy = 0.930, ce = 0.204, wd = 0.189\n",
      "total loss for epoch 45: 161.154\n",
      "validation for epoch 45\n",
      "-  epoch 45: validation accuracy = 0.871\n",
      "train for epoch 46\n",
      "iteration (17600): loss = 0.341, accuracy = 0.953, ce = 0.152, wd = 0.189\n",
      "iteration (17650): loss = 0.431, accuracy = 0.922, ce = 0.242, wd = 0.189\n",
      "iteration (17700): loss = 0.369, accuracy = 0.945, ce = 0.180, wd = 0.189\n",
      "iteration (17750): loss = 0.439, accuracy = 0.891, ce = 0.250, wd = 0.189\n",
      "iteration (17800): loss = 0.447, accuracy = 0.922, ce = 0.258, wd = 0.189\n",
      "iteration (17850): loss = 0.340, accuracy = 0.945, ce = 0.151, wd = 0.189\n",
      "iteration (17900): loss = 0.453, accuracy = 0.898, ce = 0.263, wd = 0.189\n",
      "iteration (17950): loss = 0.407, accuracy = 0.914, ce = 0.217, wd = 0.189\n",
      "total loss for epoch 46: 163.202\n",
      "validation for epoch 46\n",
      "-  epoch 46: validation accuracy = 0.875\n",
      "meet better model, save model...\n",
      "train for epoch 47\n",
      "iteration (18000): loss = 0.388, accuracy = 0.922, ce = 0.199, wd = 0.189\n",
      "iteration (18050): loss = 0.403, accuracy = 0.930, ce = 0.214, wd = 0.189\n",
      "iteration (18100): loss = 0.410, accuracy = 0.922, ce = 0.221, wd = 0.189\n",
      "iteration (18150): loss = 0.432, accuracy = 0.914, ce = 0.242, wd = 0.189\n",
      "iteration (18200): loss = 0.412, accuracy = 0.906, ce = 0.222, wd = 0.190\n",
      "iteration (18250): loss = 0.436, accuracy = 0.898, ce = 0.246, wd = 0.190\n",
      "iteration (18300): loss = 0.350, accuracy = 0.930, ce = 0.160, wd = 0.190\n",
      "total loss for epoch 47: 162.133\n",
      "validation for epoch 47\n",
      "-  epoch 47: validation accuracy = 0.873\n",
      "train for epoch 48\n",
      "iteration (18350): loss = 0.372, accuracy = 0.930, ce = 0.182, wd = 0.190\n",
      "iteration (18400): loss = 0.373, accuracy = 0.938, ce = 0.183, wd = 0.190\n",
      "iteration (18450): loss = 0.399, accuracy = 0.938, ce = 0.209, wd = 0.190\n",
      "iteration (18500): loss = 0.372, accuracy = 0.945, ce = 0.182, wd = 0.190\n",
      "iteration (18550): loss = 0.466, accuracy = 0.922, ce = 0.276, wd = 0.190\n",
      "iteration (18600): loss = 0.475, accuracy = 0.859, ce = 0.285, wd = 0.190\n",
      "iteration (18650): loss = 0.443, accuracy = 0.914, ce = 0.253, wd = 0.190\n",
      "iteration (18700): loss = 0.523, accuracy = 0.906, ce = 0.332, wd = 0.191\n",
      "total loss for epoch 48: 160.506\n",
      "validation for epoch 48\n",
      "-  epoch 48: validation accuracy = 0.854\n",
      "train for epoch 49\n",
      "iteration (18750): loss = 0.381, accuracy = 0.945, ce = 0.191, wd = 0.191\n",
      "iteration (18800): loss = 0.365, accuracy = 0.938, ce = 0.174, wd = 0.191\n",
      "iteration (18850): loss = 0.428, accuracy = 0.898, ce = 0.237, wd = 0.191\n",
      "iteration (18900): loss = 0.366, accuracy = 0.969, ce = 0.175, wd = 0.191\n",
      "iteration (18950): loss = 0.367, accuracy = 0.945, ce = 0.176, wd = 0.191\n",
      "iteration (19000): loss = 0.414, accuracy = 0.945, ce = 0.223, wd = 0.191\n",
      "iteration (19050): loss = 0.426, accuracy = 0.922, ce = 0.235, wd = 0.191\n",
      "total loss for epoch 49: 159.397\n",
      "validation for epoch 49\n",
      "-  epoch 49: validation accuracy = 0.864\n",
      "train for epoch 50\n",
      "iteration (19100): loss = 0.506, accuracy = 0.891, ce = 0.315, wd = 0.191\n",
      "iteration (19150): loss = 0.407, accuracy = 0.914, ce = 0.216, wd = 0.191\n",
      "iteration (19200): loss = 0.439, accuracy = 0.891, ce = 0.248, wd = 0.191\n",
      "iteration (19250): loss = 0.396, accuracy = 0.914, ce = 0.205, wd = 0.191\n",
      "iteration (19300): loss = 0.333, accuracy = 0.945, ce = 0.142, wd = 0.191\n",
      "iteration (19350): loss = 0.429, accuracy = 0.930, ce = 0.238, wd = 0.191\n",
      "iteration (19400): loss = 0.454, accuracy = 0.867, ce = 0.263, wd = 0.191\n",
      "iteration (19450): loss = 0.444, accuracy = 0.922, ce = 0.252, wd = 0.191\n",
      "total loss for epoch 50: 158.579\n",
      "validation for epoch 50\n",
      "-  epoch 50: validation accuracy = 0.859\n",
      "train for epoch 51\n",
      "iteration (19500): loss = 0.415, accuracy = 0.930, ce = 0.224, wd = 0.191\n",
      "iteration (19550): loss = 0.436, accuracy = 0.922, ce = 0.244, wd = 0.191\n",
      "iteration (19600): loss = 0.377, accuracy = 0.930, ce = 0.185, wd = 0.191\n",
      "iteration (19650): loss = 0.501, accuracy = 0.859, ce = 0.310, wd = 0.192\n",
      "iteration (19700): loss = 0.477, accuracy = 0.898, ce = 0.285, wd = 0.192\n",
      "iteration (19750): loss = 0.418, accuracy = 0.922, ce = 0.226, wd = 0.192\n",
      "iteration (19800): loss = 0.412, accuracy = 0.914, ce = 0.220, wd = 0.192\n",
      "iteration (19850): loss = 0.309, accuracy = 0.984, ce = 0.117, wd = 0.192\n",
      "total loss for epoch 51: 159.977\n",
      "validation for epoch 51\n",
      "-  epoch 51: validation accuracy = 0.855\n",
      "train for epoch 52\n",
      "iteration (19900): loss = 0.468, accuracy = 0.906, ce = 0.275, wd = 0.192\n",
      "iteration (19950): loss = 0.385, accuracy = 0.930, ce = 0.193, wd = 0.192\n",
      "iteration (20000): loss = 0.420, accuracy = 0.914, ce = 0.228, wd = 0.192\n",
      "iteration (20050): loss = 0.366, accuracy = 0.953, ce = 0.174, wd = 0.192\n",
      "iteration (20100): loss = 0.460, accuracy = 0.906, ce = 0.267, wd = 0.192\n",
      "iteration (20150): loss = 0.435, accuracy = 0.930, ce = 0.243, wd = 0.192\n",
      "iteration (20200): loss = 0.397, accuracy = 0.938, ce = 0.204, wd = 0.193\n",
      "total loss for epoch 52: 158.648\n",
      "validation for epoch 52\n",
      "-  epoch 52: validation accuracy = 0.864\n",
      "train for epoch 53\n",
      "iteration (20250): loss = 0.554, accuracy = 0.891, ce = 0.361, wd = 0.193\n",
      "iteration (20300): loss = 0.479, accuracy = 0.883, ce = 0.286, wd = 0.193\n",
      "iteration (20350): loss = 0.359, accuracy = 0.945, ce = 0.167, wd = 0.193\n",
      "iteration (20400): loss = 0.505, accuracy = 0.875, ce = 0.312, wd = 0.193\n",
      "iteration (20450): loss = 0.428, accuracy = 0.930, ce = 0.235, wd = 0.193\n",
      "iteration (20500): loss = 0.387, accuracy = 0.953, ce = 0.195, wd = 0.193\n",
      "iteration (20550): loss = 0.324, accuracy = 0.961, ce = 0.131, wd = 0.193\n",
      "iteration (20600): loss = 0.444, accuracy = 0.898, ce = 0.251, wd = 0.193\n",
      "total loss for epoch 53: 158.692\n",
      "validation for epoch 53\n",
      "-  epoch 53: validation accuracy = 0.859\n",
      "train for epoch 54\n",
      "iteration (20650): loss = 0.441, accuracy = 0.898, ce = 0.248, wd = 0.193\n",
      "iteration (20700): loss = 0.366, accuracy = 0.938, ce = 0.173, wd = 0.193\n",
      "iteration (20750): loss = 0.414, accuracy = 0.922, ce = 0.221, wd = 0.193\n",
      "iteration (20800): loss = 0.434, accuracy = 0.906, ce = 0.241, wd = 0.193\n",
      "iteration (20850): loss = 0.309, accuracy = 0.969, ce = 0.115, wd = 0.193\n",
      "iteration (20900): loss = 0.381, accuracy = 0.930, ce = 0.187, wd = 0.193\n",
      "iteration (20950): loss = 0.440, accuracy = 0.930, ce = 0.246, wd = 0.194\n",
      "iteration (21000): loss = 0.482, accuracy = 0.906, ce = 0.289, wd = 0.194\n",
      "total loss for epoch 54: 158.114\n",
      "validation for epoch 54\n",
      "-  epoch 54: validation accuracy = 0.842\n",
      "train for epoch 55\n",
      "iteration (21050): loss = 0.319, accuracy = 0.969, ce = 0.126, wd = 0.194\n",
      "iteration (21100): loss = 0.373, accuracy = 0.945, ce = 0.180, wd = 0.193\n",
      "iteration (21150): loss = 0.413, accuracy = 0.938, ce = 0.219, wd = 0.193\n",
      "iteration (21200): loss = 0.385, accuracy = 0.930, ce = 0.191, wd = 0.194\n",
      "iteration (21250): loss = 0.400, accuracy = 0.945, ce = 0.206, wd = 0.194\n",
      "iteration (21300): loss = 0.473, accuracy = 0.906, ce = 0.279, wd = 0.194\n",
      "iteration (21350): loss = 0.394, accuracy = 0.953, ce = 0.201, wd = 0.194\n",
      "total loss for epoch 55: 157.217\n",
      "validation for epoch 55\n",
      "-  epoch 55: validation accuracy = 0.855\n",
      "train for epoch 56\n",
      "iteration (21400): loss = 0.410, accuracy = 0.938, ce = 0.216, wd = 0.194\n",
      "iteration (21450): loss = 0.410, accuracy = 0.914, ce = 0.216, wd = 0.194\n",
      "iteration (21500): loss = 0.341, accuracy = 0.945, ce = 0.147, wd = 0.194\n",
      "iteration (21550): loss = 0.425, accuracy = 0.914, ce = 0.231, wd = 0.194\n",
      "iteration (21600): loss = 0.413, accuracy = 0.930, ce = 0.219, wd = 0.194\n",
      "iteration (21650): loss = 0.373, accuracy = 0.930, ce = 0.179, wd = 0.194\n",
      "iteration (21700): loss = 0.420, accuracy = 0.930, ce = 0.226, wd = 0.194\n",
      "iteration (21750): loss = 0.351, accuracy = 0.945, ce = 0.156, wd = 0.195\n",
      "total loss for epoch 56: 157.117\n",
      "validation for epoch 56\n",
      "-  epoch 56: validation accuracy = 0.850\n",
      "train for epoch 57\n",
      "iteration (21800): loss = 0.424, accuracy = 0.922, ce = 0.230, wd = 0.195\n",
      "iteration (21850): loss = 0.297, accuracy = 0.961, ce = 0.102, wd = 0.194\n",
      "iteration (21900): loss = 0.349, accuracy = 0.961, ce = 0.155, wd = 0.194\n",
      "iteration (21950): loss = 0.393, accuracy = 0.953, ce = 0.199, wd = 0.194\n",
      "iteration (22000): loss = 0.395, accuracy = 0.945, ce = 0.201, wd = 0.195\n",
      "iteration (22050): loss = 0.445, accuracy = 0.898, ce = 0.250, wd = 0.195\n",
      "iteration (22100): loss = 0.399, accuracy = 0.953, ce = 0.204, wd = 0.195\n",
      "iteration (22150): loss = 0.387, accuracy = 0.953, ce = 0.192, wd = 0.195\n",
      "total loss for epoch 57: 156.353\n",
      "validation for epoch 57\n",
      "-  epoch 57: validation accuracy = 0.859\n",
      "train for epoch 58\n",
      "iteration (22200): loss = 0.430, accuracy = 0.938, ce = 0.236, wd = 0.195\n",
      "iteration (22250): loss = 0.349, accuracy = 0.938, ce = 0.155, wd = 0.195\n",
      "iteration (22300): loss = 0.452, accuracy = 0.922, ce = 0.258, wd = 0.195\n",
      "iteration (22350): loss = 0.400, accuracy = 0.922, ce = 0.205, wd = 0.195\n",
      "iteration (22400): loss = 0.423, accuracy = 0.914, ce = 0.228, wd = 0.195\n",
      "iteration (22450): loss = 0.293, accuracy = 0.984, ce = 0.098, wd = 0.195\n",
      "iteration (22500): loss = 0.405, accuracy = 0.922, ce = 0.210, wd = 0.195\n",
      "total loss for epoch 58: 155.103\n",
      "validation for epoch 58\n",
      "-  epoch 58: validation accuracy = 0.855\n",
      "train for epoch 59\n",
      "iteration (22550): loss = 0.423, accuracy = 0.930, ce = 0.227, wd = 0.195\n",
      "iteration (22600): loss = 0.365, accuracy = 0.945, ce = 0.169, wd = 0.195\n",
      "iteration (22650): loss = 0.392, accuracy = 0.922, ce = 0.197, wd = 0.195\n",
      "iteration (22700): loss = 0.422, accuracy = 0.906, ce = 0.227, wd = 0.195\n",
      "iteration (22750): loss = 0.397, accuracy = 0.953, ce = 0.202, wd = 0.195\n",
      "iteration (22800): loss = 0.415, accuracy = 0.930, ce = 0.220, wd = 0.195\n",
      "iteration (22850): loss = 0.461, accuracy = 0.906, ce = 0.265, wd = 0.195\n",
      "iteration (22900): loss = 0.428, accuracy = 0.914, ce = 0.232, wd = 0.195\n",
      "total loss for epoch 59: 155.910\n",
      "validation for epoch 59\n",
      "-  epoch 59: validation accuracy = 0.873\n",
      "train for epoch 60\n",
      "iteration (22950): loss = 0.340, accuracy = 0.953, ce = 0.145, wd = 0.195\n",
      "iteration (23000): loss = 0.344, accuracy = 0.945, ce = 0.148, wd = 0.195\n",
      "iteration (23050): loss = 0.393, accuracy = 0.945, ce = 0.197, wd = 0.195\n",
      "iteration (23100): loss = 0.376, accuracy = 0.938, ce = 0.181, wd = 0.195\n",
      "iteration (23150): loss = 0.446, accuracy = 0.922, ce = 0.251, wd = 0.196\n",
      "iteration (23200): loss = 0.481, accuracy = 0.906, ce = 0.285, wd = 0.196\n",
      "iteration (23250): loss = 0.369, accuracy = 0.938, ce = 0.173, wd = 0.196\n",
      "iteration (23300): loss = 0.444, accuracy = 0.922, ce = 0.248, wd = 0.196\n",
      "total loss for epoch 60: 155.632\n",
      "validation for epoch 60\n",
      "-  epoch 60: validation accuracy = 0.844\n",
      "train for epoch 61\n",
      "iteration (23350): loss = 0.383, accuracy = 0.938, ce = 0.187, wd = 0.196\n",
      "iteration (23400): loss = 0.411, accuracy = 0.938, ce = 0.216, wd = 0.196\n",
      "iteration (23450): loss = 0.462, accuracy = 0.922, ce = 0.267, wd = 0.195\n",
      "iteration (23500): loss = 0.372, accuracy = 0.945, ce = 0.177, wd = 0.196\n",
      "iteration (23550): loss = 0.407, accuracy = 0.922, ce = 0.212, wd = 0.196\n",
      "iteration (23600): loss = 0.446, accuracy = 0.914, ce = 0.251, wd = 0.196\n",
      "iteration (23650): loss = 0.383, accuracy = 0.930, ce = 0.187, wd = 0.196\n",
      "total loss for epoch 61: 153.514\n",
      "validation for epoch 61\n",
      "-  epoch 61: validation accuracy = 0.864\n",
      "train for epoch 62\n",
      "iteration (23700): loss = 0.397, accuracy = 0.922, ce = 0.201, wd = 0.196\n",
      "iteration (23750): loss = 0.426, accuracy = 0.930, ce = 0.230, wd = 0.196\n",
      "iteration (23800): loss = 0.313, accuracy = 0.961, ce = 0.117, wd = 0.196\n",
      "iteration (23850): loss = 0.408, accuracy = 0.906, ce = 0.213, wd = 0.196\n",
      "iteration (23900): loss = 0.343, accuracy = 0.922, ce = 0.147, wd = 0.196\n",
      "iteration (23950): loss = 0.392, accuracy = 0.922, ce = 0.196, wd = 0.196\n",
      "iteration (24000): loss = 0.394, accuracy = 0.930, ce = 0.198, wd = 0.196\n",
      "iteration (24050): loss = 0.405, accuracy = 0.961, ce = 0.209, wd = 0.196\n",
      "total loss for epoch 62: 152.869\n",
      "validation for epoch 62\n",
      "-  epoch 62: validation accuracy = 0.873\n",
      "train for epoch 63\n",
      "iteration (24100): loss = 0.406, accuracy = 0.938, ce = 0.210, wd = 0.196\n",
      "iteration (24150): loss = 0.332, accuracy = 0.969, ce = 0.136, wd = 0.196\n",
      "iteration (24200): loss = 0.296, accuracy = 0.984, ce = 0.100, wd = 0.196\n",
      "iteration (24250): loss = 0.479, accuracy = 0.898, ce = 0.283, wd = 0.196\n",
      "iteration (24300): loss = 0.475, accuracy = 0.898, ce = 0.278, wd = 0.196\n",
      "iteration (24350): loss = 0.348, accuracy = 0.953, ce = 0.151, wd = 0.196\n",
      "iteration (24400): loss = 0.455, accuracy = 0.914, ce = 0.258, wd = 0.196\n",
      "total loss for epoch 63: 152.835\n",
      "validation for epoch 63\n",
      "-  epoch 63: validation accuracy = 0.874\n",
      "train for epoch 64\n",
      "iteration (24450): loss = 0.374, accuracy = 0.945, ce = 0.178, wd = 0.197\n",
      "iteration (24500): loss = 0.333, accuracy = 0.977, ce = 0.136, wd = 0.197\n",
      "iteration (24550): loss = 0.443, accuracy = 0.914, ce = 0.246, wd = 0.196\n",
      "iteration (24600): loss = 0.431, accuracy = 0.922, ce = 0.234, wd = 0.196\n",
      "iteration (24650): loss = 0.438, accuracy = 0.930, ce = 0.241, wd = 0.197\n",
      "iteration (24700): loss = 0.480, accuracy = 0.875, ce = 0.284, wd = 0.197\n",
      "iteration (24750): loss = 0.357, accuracy = 0.953, ce = 0.160, wd = 0.197\n",
      "iteration (24800): loss = 0.435, accuracy = 0.914, ce = 0.238, wd = 0.197\n",
      "total loss for epoch 64: 153.686\n",
      "validation for epoch 64\n",
      "-  epoch 64: validation accuracy = 0.852\n",
      "train for epoch 65\n",
      "iteration (24850): loss = 0.364, accuracy = 0.953, ce = 0.167, wd = 0.197\n",
      "iteration (24900): loss = 0.428, accuracy = 0.922, ce = 0.231, wd = 0.197\n",
      "iteration (24950): loss = 0.392, accuracy = 0.930, ce = 0.195, wd = 0.197\n",
      "iteration (25000): loss = 0.356, accuracy = 0.953, ce = 0.159, wd = 0.197\n",
      "iteration (25050): loss = 0.426, accuracy = 0.914, ce = 0.229, wd = 0.197\n",
      "iteration (25100): loss = 0.344, accuracy = 0.969, ce = 0.147, wd = 0.197\n",
      "iteration (25150): loss = 0.421, accuracy = 0.922, ce = 0.224, wd = 0.197\n",
      "iteration (25200): loss = 0.504, accuracy = 0.883, ce = 0.306, wd = 0.197\n",
      "total loss for epoch 65: 152.457\n",
      "validation for epoch 65\n",
      "-  epoch 65: validation accuracy = 0.836\n",
      "train for epoch 66\n",
      "iteration (25250): loss = 0.404, accuracy = 0.906, ce = 0.206, wd = 0.197\n",
      "iteration (25300): loss = 0.424, accuracy = 0.914, ce = 0.227, wd = 0.197\n",
      "iteration (25350): loss = 0.396, accuracy = 0.938, ce = 0.199, wd = 0.197\n",
      "iteration (25400): loss = 0.359, accuracy = 0.938, ce = 0.161, wd = 0.197\n",
      "iteration (25450): loss = 0.455, accuracy = 0.914, ce = 0.258, wd = 0.197\n",
      "iteration (25500): loss = 0.371, accuracy = 0.953, ce = 0.174, wd = 0.197\n",
      "iteration (25550): loss = 0.452, accuracy = 0.883, ce = 0.255, wd = 0.197\n",
      "total loss for epoch 66: 152.663\n",
      "validation for epoch 66\n",
      "-  epoch 66: validation accuracy = 0.871\n",
      "train for epoch 67\n",
      "iteration (25600): loss = 0.330, accuracy = 0.945, ce = 0.132, wd = 0.198\n",
      "iteration (25650): loss = 0.355, accuracy = 0.961, ce = 0.158, wd = 0.197\n",
      "iteration (25700): loss = 0.448, accuracy = 0.898, ce = 0.251, wd = 0.197\n",
      "iteration (25750): loss = 0.426, accuracy = 0.938, ce = 0.228, wd = 0.197\n",
      "iteration (25800): loss = 0.349, accuracy = 0.961, ce = 0.151, wd = 0.197\n",
      "iteration (25850): loss = 0.347, accuracy = 0.945, ce = 0.150, wd = 0.197\n",
      "iteration (25900): loss = 0.464, accuracy = 0.914, ce = 0.266, wd = 0.197\n",
      "iteration (25950): loss = 0.438, accuracy = 0.930, ce = 0.240, wd = 0.198\n",
      "total loss for epoch 67: 151.610\n",
      "validation for epoch 67\n",
      "-  epoch 67: validation accuracy = 0.879\n",
      "meet better model, save model...\n",
      "train for epoch 68\n",
      "iteration (26000): loss = 0.386, accuracy = 0.945, ce = 0.188, wd = 0.198\n",
      "iteration (26050): loss = 0.402, accuracy = 0.930, ce = 0.205, wd = 0.197\n",
      "iteration (26100): loss = 0.339, accuracy = 0.945, ce = 0.142, wd = 0.197\n",
      "iteration (26150): loss = 0.449, accuracy = 0.914, ce = 0.251, wd = 0.198\n",
      "iteration (26200): loss = 0.345, accuracy = 0.961, ce = 0.147, wd = 0.198\n",
      "iteration (26250): loss = 0.316, accuracy = 0.977, ce = 0.118, wd = 0.198\n",
      "iteration (26300): loss = 0.529, accuracy = 0.914, ce = 0.331, wd = 0.198\n",
      "iteration (26350): loss = 0.357, accuracy = 0.945, ce = 0.159, wd = 0.198\n",
      "total loss for epoch 68: 151.156\n",
      "validation for epoch 68\n",
      "-  epoch 68: validation accuracy = 0.877\n",
      "train for epoch 69\n",
      "iteration (26400): loss = 0.369, accuracy = 0.953, ce = 0.171, wd = 0.198\n",
      "iteration (26450): loss = 0.500, accuracy = 0.883, ce = 0.302, wd = 0.198\n",
      "iteration (26500): loss = 0.420, accuracy = 0.922, ce = 0.223, wd = 0.198\n",
      "iteration (26550): loss = 0.454, accuracy = 0.922, ce = 0.257, wd = 0.198\n",
      "iteration (26600): loss = 0.420, accuracy = 0.930, ce = 0.222, wd = 0.198\n",
      "iteration (26650): loss = 0.404, accuracy = 0.938, ce = 0.206, wd = 0.198\n",
      "iteration (26700): loss = 0.389, accuracy = 0.945, ce = 0.191, wd = 0.198\n",
      "total loss for epoch 69: 150.368\n",
      "validation for epoch 69\n",
      "-  epoch 69: validation accuracy = 0.892\n",
      "meet better model, save model...\n",
      "train for epoch 70\n",
      "iteration (26750): loss = 0.412, accuracy = 0.945, ce = 0.214, wd = 0.198\n",
      "iteration (26800): loss = 0.366, accuracy = 0.945, ce = 0.168, wd = 0.198\n",
      "iteration (26850): loss = 0.325, accuracy = 0.945, ce = 0.128, wd = 0.198\n",
      "iteration (26900): loss = 0.364, accuracy = 0.945, ce = 0.166, wd = 0.198\n",
      "iteration (26950): loss = 0.345, accuracy = 0.953, ce = 0.147, wd = 0.198\n",
      "iteration (27000): loss = 0.417, accuracy = 0.938, ce = 0.219, wd = 0.198\n",
      "iteration (27050): loss = 0.435, accuracy = 0.922, ce = 0.236, wd = 0.198\n",
      "iteration (27100): loss = 0.416, accuracy = 0.922, ce = 0.217, wd = 0.198\n",
      "total loss for epoch 70: 151.535\n",
      "validation for epoch 70\n",
      "-  epoch 70: validation accuracy = 0.872\n",
      "train for epoch 71\n",
      "iteration (27150): loss = 0.431, accuracy = 0.922, ce = 0.232, wd = 0.199\n",
      "iteration (27200): loss = 0.340, accuracy = 0.945, ce = 0.141, wd = 0.199\n",
      "iteration (27250): loss = 0.304, accuracy = 0.961, ce = 0.106, wd = 0.198\n",
      "iteration (27300): loss = 0.358, accuracy = 0.945, ce = 0.160, wd = 0.199\n",
      "iteration (27350): loss = 0.395, accuracy = 0.922, ce = 0.197, wd = 0.199\n",
      "iteration (27400): loss = 0.461, accuracy = 0.914, ce = 0.262, wd = 0.199\n",
      "iteration (27450): loss = 0.512, accuracy = 0.891, ce = 0.313, wd = 0.199\n",
      "iteration (27500): loss = 0.400, accuracy = 0.930, ce = 0.201, wd = 0.199\n",
      "total loss for epoch 71: 150.514\n",
      "validation for epoch 71\n",
      "-  epoch 71: validation accuracy = 0.888\n",
      "train for epoch 72\n",
      "iteration (27550): loss = 0.479, accuracy = 0.891, ce = 0.280, wd = 0.199\n",
      "iteration (27600): loss = 0.331, accuracy = 0.953, ce = 0.132, wd = 0.199\n",
      "iteration (27650): loss = 0.370, accuracy = 0.945, ce = 0.171, wd = 0.199\n",
      "iteration (27700): loss = 0.356, accuracy = 0.938, ce = 0.157, wd = 0.199\n",
      "iteration (27750): loss = 0.389, accuracy = 0.930, ce = 0.190, wd = 0.199\n",
      "iteration (27800): loss = 0.396, accuracy = 0.914, ce = 0.197, wd = 0.199\n",
      "iteration (27850): loss = 0.323, accuracy = 0.961, ce = 0.124, wd = 0.199\n",
      "total loss for epoch 72: 150.743\n",
      "validation for epoch 72\n",
      "-  epoch 72: validation accuracy = 0.873\n",
      "train for epoch 73\n",
      "iteration (27900): loss = 0.405, accuracy = 0.938, ce = 0.206, wd = 0.199\n",
      "iteration (27950): loss = 0.384, accuracy = 0.938, ce = 0.185, wd = 0.199\n",
      "iteration (28000): loss = 0.399, accuracy = 0.922, ce = 0.200, wd = 0.199\n",
      "iteration (28050): loss = 0.420, accuracy = 0.914, ce = 0.221, wd = 0.199\n",
      "iteration (28100): loss = 0.287, accuracy = 0.969, ce = 0.088, wd = 0.199\n",
      "iteration (28150): loss = 0.386, accuracy = 0.930, ce = 0.186, wd = 0.199\n",
      "iteration (28200): loss = 0.390, accuracy = 0.922, ce = 0.190, wd = 0.199\n",
      "iteration (28250): loss = 0.515, accuracy = 0.898, ce = 0.316, wd = 0.199\n",
      "total loss for epoch 73: 148.907\n",
      "validation for epoch 73\n",
      "-  epoch 73: validation accuracy = 0.834\n",
      "train for epoch 74\n",
      "iteration (28300): loss = 0.421, accuracy = 0.922, ce = 0.222, wd = 0.199\n",
      "iteration (28350): loss = 0.360, accuracy = 0.938, ce = 0.161, wd = 0.199\n",
      "iteration (28400): loss = 0.480, accuracy = 0.906, ce = 0.281, wd = 0.199\n",
      "iteration (28450): loss = 0.429, accuracy = 0.914, ce = 0.230, wd = 0.199\n",
      "iteration (28500): loss = 0.378, accuracy = 0.938, ce = 0.179, wd = 0.199\n",
      "iteration (28550): loss = 0.398, accuracy = 0.898, ce = 0.199, wd = 0.199\n",
      "iteration (28600): loss = 0.431, accuracy = 0.891, ce = 0.232, wd = 0.199\n",
      "total loss for epoch 74: 149.827\n",
      "validation for epoch 74\n",
      "-  epoch 74: validation accuracy = 0.868\n",
      "train for epoch 75\n",
      "iteration (28650): loss = 0.451, accuracy = 0.922, ce = 0.252, wd = 0.200\n",
      "iteration (28700): loss = 0.352, accuracy = 0.961, ce = 0.152, wd = 0.200\n",
      "iteration (28750): loss = 0.343, accuracy = 0.961, ce = 0.144, wd = 0.199\n",
      "iteration (28800): loss = 0.385, accuracy = 0.938, ce = 0.186, wd = 0.199\n",
      "iteration (28850): loss = 0.336, accuracy = 0.961, ce = 0.137, wd = 0.199\n",
      "iteration (28900): loss = 0.329, accuracy = 0.953, ce = 0.129, wd = 0.199\n",
      "iteration (28950): loss = 0.367, accuracy = 0.969, ce = 0.168, wd = 0.199\n",
      "iteration (29000): loss = 0.498, accuracy = 0.906, ce = 0.299, wd = 0.199\n",
      "total loss for epoch 75: 149.069\n",
      "validation for epoch 75\n",
      "-  epoch 75: validation accuracy = 0.844\n",
      "train for epoch 76\n",
      "iteration (29050): loss = 0.429, accuracy = 0.938, ce = 0.229, wd = 0.200\n",
      "iteration (29100): loss = 0.372, accuracy = 0.953, ce = 0.172, wd = 0.199\n",
      "iteration (29150): loss = 0.365, accuracy = 0.945, ce = 0.166, wd = 0.199\n",
      "iteration (29200): loss = 0.404, accuracy = 0.922, ce = 0.205, wd = 0.199\n",
      "iteration (29250): loss = 0.303, accuracy = 0.961, ce = 0.104, wd = 0.199\n",
      "iteration (29300): loss = 0.447, accuracy = 0.945, ce = 0.247, wd = 0.199\n",
      "iteration (29350): loss = 0.443, accuracy = 0.922, ce = 0.244, wd = 0.200\n",
      "iteration (29400): loss = 0.378, accuracy = 0.922, ce = 0.179, wd = 0.200\n",
      "total loss for epoch 76: 148.556\n",
      "validation for epoch 76\n",
      "-  epoch 76: validation accuracy = 0.879\n",
      "train for epoch 77\n",
      "iteration (29450): loss = 0.344, accuracy = 0.961, ce = 0.145, wd = 0.199\n",
      "iteration (29500): loss = 0.371, accuracy = 0.930, ce = 0.171, wd = 0.199\n",
      "iteration (29550): loss = 0.385, accuracy = 0.930, ce = 0.186, wd = 0.199\n",
      "iteration (29600): loss = 0.473, accuracy = 0.906, ce = 0.273, wd = 0.199\n",
      "iteration (29650): loss = 0.377, accuracy = 0.938, ce = 0.178, wd = 0.199\n",
      "iteration (29700): loss = 0.417, accuracy = 0.922, ce = 0.218, wd = 0.199\n",
      "iteration (29750): loss = 0.441, accuracy = 0.922, ce = 0.242, wd = 0.200\n",
      "total loss for epoch 77: 149.283\n",
      "validation for epoch 77\n",
      "-  epoch 77: validation accuracy = 0.860\n",
      "train for epoch 78\n",
      "iteration (29800): loss = 0.436, accuracy = 0.891, ce = 0.237, wd = 0.200\n",
      "iteration (29850): loss = 0.371, accuracy = 0.945, ce = 0.171, wd = 0.200\n",
      "iteration (29900): loss = 0.313, accuracy = 0.961, ce = 0.113, wd = 0.200\n",
      "iteration (29950): loss = 0.378, accuracy = 0.938, ce = 0.179, wd = 0.200\n",
      "iteration (30000): loss = 0.347, accuracy = 0.953, ce = 0.148, wd = 0.200\n",
      "iteration (30050): loss = 0.355, accuracy = 0.961, ce = 0.155, wd = 0.200\n",
      "iteration (30100): loss = 0.453, accuracy = 0.922, ce = 0.253, wd = 0.200\n",
      "iteration (30150): loss = 0.426, accuracy = 0.914, ce = 0.226, wd = 0.200\n",
      "total loss for epoch 78: 147.544\n",
      "validation for epoch 78\n",
      "-  epoch 78: validation accuracy = 0.892\n",
      "train for epoch 79\n",
      "iteration (30200): loss = 0.360, accuracy = 0.938, ce = 0.160, wd = 0.200\n",
      "iteration (30250): loss = 0.429, accuracy = 0.906, ce = 0.229, wd = 0.200\n",
      "iteration (30300): loss = 0.378, accuracy = 0.953, ce = 0.178, wd = 0.200\n",
      "iteration (30350): loss = 0.417, accuracy = 0.930, ce = 0.217, wd = 0.200\n",
      "iteration (30400): loss = 0.418, accuracy = 0.938, ce = 0.217, wd = 0.200\n",
      "iteration (30450): loss = 0.447, accuracy = 0.906, ce = 0.246, wd = 0.200\n",
      "iteration (30500): loss = 0.509, accuracy = 0.883, ce = 0.308, wd = 0.200\n",
      "iteration (30550): loss = 0.360, accuracy = 0.930, ce = 0.160, wd = 0.200\n",
      "total loss for epoch 79: 148.094\n",
      "validation for epoch 79\n",
      "-  epoch 79: validation accuracy = 0.854\n",
      "train for epoch 80\n",
      "iteration (30600): loss = 0.407, accuracy = 0.945, ce = 0.207, wd = 0.200\n",
      "iteration (30650): loss = 0.313, accuracy = 0.961, ce = 0.113, wd = 0.200\n",
      "iteration (30700): loss = 0.334, accuracy = 0.977, ce = 0.134, wd = 0.200\n",
      "iteration (30750): loss = 0.375, accuracy = 0.945, ce = 0.175, wd = 0.200\n",
      "iteration (30800): loss = 0.352, accuracy = 0.945, ce = 0.152, wd = 0.200\n",
      "iteration (30850): loss = 0.441, accuracy = 0.906, ce = 0.240, wd = 0.200\n",
      "iteration (30900): loss = 0.398, accuracy = 0.922, ce = 0.197, wd = 0.201\n",
      "total loss for epoch 80: 147.717\n",
      "validation for epoch 80\n",
      "-  epoch 80: validation accuracy = 0.892\n",
      "train for epoch 81\n",
      "iteration (30950): loss = 0.368, accuracy = 0.953, ce = 0.168, wd = 0.201\n",
      "iteration (31000): loss = 0.384, accuracy = 0.930, ce = 0.183, wd = 0.200\n",
      "iteration (31050): loss = 0.358, accuracy = 0.945, ce = 0.158, wd = 0.200\n",
      "iteration (31100): loss = 0.383, accuracy = 0.938, ce = 0.183, wd = 0.200\n",
      "iteration (31150): loss = 0.422, accuracy = 0.945, ce = 0.222, wd = 0.200\n",
      "iteration (31200): loss = 0.453, accuracy = 0.930, ce = 0.253, wd = 0.200\n",
      "iteration (31250): loss = 0.330, accuracy = 0.977, ce = 0.131, wd = 0.200\n",
      "iteration (31300): loss = 0.409, accuracy = 0.922, ce = 0.209, wd = 0.200\n",
      "total loss for epoch 81: 146.259\n",
      "validation for epoch 81\n",
      "-  epoch 81: validation accuracy = 0.863\n",
      "train for epoch 82\n",
      "iteration (31350): loss = 0.374, accuracy = 0.953, ce = 0.174, wd = 0.200\n",
      "iteration (31400): loss = 0.458, accuracy = 0.914, ce = 0.258, wd = 0.200\n",
      "iteration (31450): loss = 0.365, accuracy = 0.945, ce = 0.165, wd = 0.200\n",
      "iteration (31500): loss = 0.375, accuracy = 0.938, ce = 0.175, wd = 0.200\n",
      "iteration (31550): loss = 0.389, accuracy = 0.930, ce = 0.188, wd = 0.200\n",
      "iteration (31600): loss = 0.351, accuracy = 0.945, ce = 0.151, wd = 0.200\n",
      "iteration (31650): loss = 0.419, accuracy = 0.930, ce = 0.219, wd = 0.200\n",
      "iteration (31700): loss = 0.347, accuracy = 0.945, ce = 0.146, wd = 0.200\n",
      "total loss for epoch 82: 146.961\n",
      "validation for epoch 82\n",
      "-  epoch 82: validation accuracy = 0.862\n",
      "train for epoch 83\n",
      "iteration (31750): loss = 0.314, accuracy = 0.961, ce = 0.114, wd = 0.200\n",
      "iteration (31800): loss = 0.321, accuracy = 0.969, ce = 0.120, wd = 0.200\n",
      "iteration (31850): loss = 0.436, accuracy = 0.945, ce = 0.236, wd = 0.200\n",
      "iteration (31900): loss = 0.424, accuracy = 0.938, ce = 0.224, wd = 0.200\n",
      "iteration (31950): loss = 0.336, accuracy = 0.969, ce = 0.136, wd = 0.200\n",
      "iteration (32000): loss = 0.367, accuracy = 0.953, ce = 0.167, wd = 0.200\n",
      "iteration (32050): loss = 0.381, accuracy = 0.938, ce = 0.181, wd = 0.200\n",
      "total loss for epoch 83: 145.853\n",
      "validation for epoch 83\n",
      "-  epoch 83: validation accuracy = 0.850\n",
      "train for epoch 84\n",
      "iteration (32100): loss = 0.364, accuracy = 0.938, ce = 0.164, wd = 0.200\n",
      "iteration (32150): loss = 0.342, accuracy = 0.938, ce = 0.142, wd = 0.200\n",
      "iteration (32200): loss = 0.329, accuracy = 0.961, ce = 0.129, wd = 0.200\n",
      "iteration (32250): loss = 0.392, accuracy = 0.930, ce = 0.193, wd = 0.200\n",
      "iteration (32300): loss = 0.389, accuracy = 0.914, ce = 0.189, wd = 0.200\n",
      "iteration (32350): loss = 0.362, accuracy = 0.945, ce = 0.162, wd = 0.200\n",
      "iteration (32400): loss = 0.399, accuracy = 0.922, ce = 0.198, wd = 0.200\n",
      "iteration (32450): loss = 0.435, accuracy = 0.914, ce = 0.235, wd = 0.201\n",
      "total loss for epoch 84: 146.463\n",
      "validation for epoch 84\n",
      "-  epoch 84: validation accuracy = 0.872\n",
      "train for epoch 85\n",
      "iteration (32500): loss = 0.367, accuracy = 0.945, ce = 0.167, wd = 0.200\n",
      "iteration (32550): loss = 0.387, accuracy = 0.930, ce = 0.186, wd = 0.200\n",
      "iteration (32600): loss = 0.352, accuracy = 0.953, ce = 0.151, wd = 0.200\n",
      "iteration (32650): loss = 0.426, accuracy = 0.914, ce = 0.226, wd = 0.200\n",
      "iteration (32700): loss = 0.407, accuracy = 0.938, ce = 0.206, wd = 0.201\n",
      "iteration (32750): loss = 0.343, accuracy = 0.977, ce = 0.142, wd = 0.201\n",
      "iteration (32800): loss = 0.411, accuracy = 0.922, ce = 0.211, wd = 0.201\n",
      "iteration (32850): loss = 0.397, accuracy = 0.922, ce = 0.196, wd = 0.201\n",
      "total loss for epoch 85: 145.853\n",
      "validation for epoch 85\n",
      "-  epoch 85: validation accuracy = 0.863\n",
      "train for epoch 86\n",
      "iteration (32900): loss = 0.379, accuracy = 0.938, ce = 0.178, wd = 0.201\n",
      "iteration (32950): loss = 0.330, accuracy = 0.953, ce = 0.129, wd = 0.201\n",
      "iteration (33000): loss = 0.372, accuracy = 0.922, ce = 0.171, wd = 0.201\n",
      "iteration (33050): loss = 0.399, accuracy = 0.914, ce = 0.198, wd = 0.201\n",
      "iteration (33100): loss = 0.439, accuracy = 0.898, ce = 0.238, wd = 0.201\n",
      "iteration (33150): loss = 0.358, accuracy = 0.938, ce = 0.156, wd = 0.201\n",
      "iteration (33200): loss = 0.364, accuracy = 0.953, ce = 0.162, wd = 0.201\n",
      "total loss for epoch 86: 147.246\n",
      "validation for epoch 86\n",
      "-  epoch 86: validation accuracy = 0.859\n",
      "train for epoch 87\n",
      "iteration (33250): loss = 0.433, accuracy = 0.906, ce = 0.232, wd = 0.201\n",
      "iteration (33300): loss = 0.488, accuracy = 0.891, ce = 0.287, wd = 0.201\n",
      "iteration (33350): loss = 0.355, accuracy = 0.953, ce = 0.154, wd = 0.201\n",
      "iteration (33400): loss = 0.416, accuracy = 0.891, ce = 0.216, wd = 0.201\n",
      "iteration (33450): loss = 0.391, accuracy = 0.938, ce = 0.190, wd = 0.201\n",
      "iteration (33500): loss = 0.396, accuracy = 0.945, ce = 0.195, wd = 0.201\n",
      "iteration (33550): loss = 0.434, accuracy = 0.914, ce = 0.233, wd = 0.201\n",
      "iteration (33600): loss = 0.333, accuracy = 0.969, ce = 0.132, wd = 0.201\n",
      "total loss for epoch 87: 144.441\n",
      "validation for epoch 87\n",
      "-  epoch 87: validation accuracy = 0.863\n",
      "train for epoch 88\n",
      "iteration (33650): loss = 0.356, accuracy = 0.938, ce = 0.156, wd = 0.201\n",
      "iteration (33700): loss = 0.309, accuracy = 0.977, ce = 0.108, wd = 0.201\n",
      "iteration (33750): loss = 0.363, accuracy = 0.930, ce = 0.162, wd = 0.201\n",
      "iteration (33800): loss = 0.395, accuracy = 0.922, ce = 0.194, wd = 0.201\n",
      "iteration (33850): loss = 0.336, accuracy = 0.961, ce = 0.135, wd = 0.201\n",
      "iteration (33900): loss = 0.302, accuracy = 0.961, ce = 0.101, wd = 0.201\n",
      "iteration (33950): loss = 0.371, accuracy = 0.938, ce = 0.170, wd = 0.201\n",
      "total loss for epoch 88: 145.427\n",
      "validation for epoch 88\n",
      "-  epoch 88: validation accuracy = 0.860\n",
      "train for epoch 89\n",
      "iteration (34000): loss = 0.436, accuracy = 0.922, ce = 0.235, wd = 0.201\n",
      "iteration (34050): loss = 0.333, accuracy = 0.977, ce = 0.132, wd = 0.201\n",
      "iteration (34100): loss = 0.353, accuracy = 0.961, ce = 0.152, wd = 0.201\n",
      "iteration (34150): loss = 0.378, accuracy = 0.938, ce = 0.177, wd = 0.200\n",
      "iteration (34200): loss = 0.386, accuracy = 0.938, ce = 0.185, wd = 0.201\n",
      "iteration (34250): loss = 0.344, accuracy = 0.945, ce = 0.143, wd = 0.201\n",
      "iteration (34300): loss = 0.317, accuracy = 0.969, ce = 0.116, wd = 0.201\n",
      "iteration (34350): loss = 0.414, accuracy = 0.938, ce = 0.213, wd = 0.201\n",
      "total loss for epoch 89: 145.434\n",
      "validation for epoch 89\n",
      "-  epoch 89: validation accuracy = 0.852\n",
      "train for epoch 90\n",
      "iteration (34400): loss = 0.329, accuracy = 0.953, ce = 0.127, wd = 0.201\n",
      "iteration (34450): loss = 0.356, accuracy = 0.961, ce = 0.155, wd = 0.201\n",
      "iteration (34500): loss = 0.411, accuracy = 0.945, ce = 0.210, wd = 0.201\n",
      "iteration (34550): loss = 0.363, accuracy = 0.922, ce = 0.162, wd = 0.201\n",
      "iteration (34600): loss = 0.462, accuracy = 0.906, ce = 0.261, wd = 0.201\n",
      "iteration (34650): loss = 0.375, accuracy = 0.961, ce = 0.175, wd = 0.201\n",
      "iteration (34700): loss = 0.476, accuracy = 0.875, ce = 0.275, wd = 0.201\n",
      "iteration (34750): loss = 0.315, accuracy = 0.969, ce = 0.114, wd = 0.201\n",
      "total loss for epoch 90: 145.841\n",
      "validation for epoch 90\n",
      "-  epoch 90: validation accuracy = 0.856\n",
      "train for epoch 91\n",
      "iteration (34800): loss = 0.299, accuracy = 0.977, ce = 0.098, wd = 0.201\n",
      "iteration (34850): loss = 0.382, accuracy = 0.953, ce = 0.181, wd = 0.201\n",
      "iteration (34900): loss = 0.447, accuracy = 0.922, ce = 0.246, wd = 0.201\n",
      "iteration (34950): loss = 0.409, accuracy = 0.930, ce = 0.208, wd = 0.201\n",
      "iteration (35000): loss = 0.414, accuracy = 0.930, ce = 0.214, wd = 0.201\n",
      "iteration (35050): loss = 0.427, accuracy = 0.914, ce = 0.226, wd = 0.201\n",
      "iteration (35100): loss = 0.285, accuracy = 0.969, ce = 0.084, wd = 0.201\n",
      "total loss for epoch 91: 144.847\n",
      "validation for epoch 91\n",
      "-  epoch 91: validation accuracy = 0.873\n",
      "train for epoch 92\n",
      "iteration (35150): loss = 0.408, accuracy = 0.930, ce = 0.207, wd = 0.201\n",
      "iteration (35200): loss = 0.342, accuracy = 0.945, ce = 0.141, wd = 0.201\n",
      "iteration (35250): loss = 0.429, accuracy = 0.914, ce = 0.228, wd = 0.201\n",
      "iteration (35300): loss = 0.336, accuracy = 0.945, ce = 0.135, wd = 0.201\n",
      "iteration (35350): loss = 0.443, accuracy = 0.914, ce = 0.242, wd = 0.201\n",
      "iteration (35400): loss = 0.343, accuracy = 0.945, ce = 0.142, wd = 0.201\n",
      "iteration (35450): loss = 0.385, accuracy = 0.922, ce = 0.184, wd = 0.201\n",
      "iteration (35500): loss = 0.351, accuracy = 0.945, ce = 0.149, wd = 0.201\n",
      "total loss for epoch 92: 145.214\n",
      "validation for epoch 92\n",
      "-  epoch 92: validation accuracy = 0.868\n",
      "train for epoch 93\n",
      "iteration (35550): loss = 0.357, accuracy = 0.930, ce = 0.156, wd = 0.201\n",
      "iteration (35600): loss = 0.406, accuracy = 0.922, ce = 0.204, wd = 0.201\n",
      "iteration (35650): loss = 0.361, accuracy = 0.938, ce = 0.160, wd = 0.201\n",
      "iteration (35700): loss = 0.367, accuracy = 0.938, ce = 0.166, wd = 0.201\n",
      "iteration (35750): loss = 0.467, accuracy = 0.906, ce = 0.266, wd = 0.201\n",
      "iteration (35800): loss = 0.418, accuracy = 0.945, ce = 0.217, wd = 0.201\n",
      "iteration (35850): loss = 0.424, accuracy = 0.914, ce = 0.223, wd = 0.201\n",
      "iteration (35900): loss = 0.345, accuracy = 0.945, ce = 0.143, wd = 0.201\n",
      "total loss for epoch 93: 144.487\n",
      "validation for epoch 93\n",
      "-  epoch 93: validation accuracy = 0.868\n",
      "train for epoch 94\n",
      "iteration (35950): loss = 0.477, accuracy = 0.922, ce = 0.276, wd = 0.201\n",
      "iteration (36000): loss = 0.340, accuracy = 0.953, ce = 0.139, wd = 0.201\n",
      "iteration (36050): loss = 0.368, accuracy = 0.930, ce = 0.167, wd = 0.201\n",
      "iteration (36100): loss = 0.471, accuracy = 0.906, ce = 0.270, wd = 0.201\n",
      "iteration (36150): loss = 0.340, accuracy = 0.953, ce = 0.139, wd = 0.201\n",
      "iteration (36200): loss = 0.464, accuracy = 0.883, ce = 0.262, wd = 0.201\n",
      "iteration (36250): loss = 0.428, accuracy = 0.930, ce = 0.226, wd = 0.201\n",
      "total loss for epoch 94: 143.443\n",
      "validation for epoch 94\n",
      "-  epoch 94: validation accuracy = 0.886\n",
      "train for epoch 95\n",
      "iteration (36300): loss = 0.474, accuracy = 0.906, ce = 0.272, wd = 0.202\n",
      "iteration (36350): loss = 0.408, accuracy = 0.922, ce = 0.207, wd = 0.201\n",
      "iteration (36400): loss = 0.392, accuracy = 0.914, ce = 0.191, wd = 0.201\n",
      "iteration (36450): loss = 0.389, accuracy = 0.922, ce = 0.188, wd = 0.201\n",
      "iteration (36500): loss = 0.366, accuracy = 0.922, ce = 0.165, wd = 0.201\n",
      "iteration (36550): loss = 0.340, accuracy = 0.953, ce = 0.139, wd = 0.201\n",
      "iteration (36600): loss = 0.308, accuracy = 0.977, ce = 0.106, wd = 0.201\n",
      "iteration (36650): loss = 0.388, accuracy = 0.953, ce = 0.187, wd = 0.201\n",
      "total loss for epoch 95: 143.284\n",
      "validation for epoch 95\n",
      "-  epoch 95: validation accuracy = 0.874\n",
      "train for epoch 96\n",
      "iteration (36700): loss = 0.355, accuracy = 0.969, ce = 0.154, wd = 0.201\n",
      "iteration (36750): loss = 0.354, accuracy = 0.938, ce = 0.153, wd = 0.201\n",
      "iteration (36800): loss = 0.382, accuracy = 0.930, ce = 0.181, wd = 0.201\n",
      "iteration (36850): loss = 0.317, accuracy = 0.969, ce = 0.116, wd = 0.201\n",
      "iteration (36900): loss = 0.325, accuracy = 0.961, ce = 0.123, wd = 0.201\n",
      "iteration (36950): loss = 0.340, accuracy = 0.961, ce = 0.139, wd = 0.201\n",
      "iteration (37000): loss = 0.427, accuracy = 0.930, ce = 0.225, wd = 0.201\n",
      "iteration (37050): loss = 0.422, accuracy = 0.938, ce = 0.221, wd = 0.201\n",
      "total loss for epoch 96: 144.872\n",
      "validation for epoch 96\n",
      "-  epoch 96: validation accuracy = 0.879\n",
      "train for epoch 97\n",
      "iteration (37100): loss = 0.303, accuracy = 0.977, ce = 0.101, wd = 0.201\n",
      "iteration (37150): loss = 0.367, accuracy = 0.953, ce = 0.165, wd = 0.201\n",
      "iteration (37200): loss = 0.386, accuracy = 0.922, ce = 0.185, wd = 0.201\n",
      "iteration (37250): loss = 0.341, accuracy = 0.953, ce = 0.140, wd = 0.201\n",
      "iteration (37300): loss = 0.421, accuracy = 0.938, ce = 0.220, wd = 0.201\n",
      "iteration (37350): loss = 0.347, accuracy = 0.938, ce = 0.146, wd = 0.201\n",
      "iteration (37400): loss = 0.372, accuracy = 0.922, ce = 0.171, wd = 0.201\n",
      "total loss for epoch 97: 142.608\n",
      "validation for epoch 97\n",
      "-  epoch 97: validation accuracy = 0.856\n",
      "train for epoch 98\n",
      "iteration (37450): loss = 0.356, accuracy = 0.938, ce = 0.154, wd = 0.201\n",
      "iteration (37500): loss = 0.471, accuracy = 0.914, ce = 0.270, wd = 0.201\n",
      "iteration (37550): loss = 0.434, accuracy = 0.922, ce = 0.232, wd = 0.201\n",
      "iteration (37600): loss = 0.395, accuracy = 0.938, ce = 0.194, wd = 0.201\n",
      "iteration (37650): loss = 0.343, accuracy = 0.953, ce = 0.141, wd = 0.201\n",
      "iteration (37700): loss = 0.305, accuracy = 0.969, ce = 0.104, wd = 0.201\n",
      "iteration (37750): loss = 0.386, accuracy = 0.930, ce = 0.184, wd = 0.201\n",
      "iteration (37800): loss = 0.413, accuracy = 0.914, ce = 0.212, wd = 0.202\n",
      "total loss for epoch 98: 144.197\n",
      "validation for epoch 98\n",
      "-  epoch 98: validation accuracy = 0.866\n",
      "train for epoch 99\n",
      "iteration (37850): loss = 0.300, accuracy = 0.969, ce = 0.098, wd = 0.202\n",
      "iteration (37900): loss = 0.416, accuracy = 0.930, ce = 0.215, wd = 0.202\n",
      "iteration (37950): loss = 0.395, accuracy = 0.914, ce = 0.194, wd = 0.201\n",
      "iteration (38000): loss = 0.535, accuracy = 0.898, ce = 0.333, wd = 0.201\n",
      "iteration (38050): loss = 0.346, accuracy = 0.953, ce = 0.145, wd = 0.201\n",
      "iteration (38100): loss = 0.353, accuracy = 0.953, ce = 0.152, wd = 0.201\n",
      "iteration (38150): loss = 0.343, accuracy = 0.961, ce = 0.142, wd = 0.201\n",
      "total loss for epoch 99: 142.799\n",
      "validation for epoch 99\n",
      "-  epoch 99: validation accuracy = 0.876\n",
      "recover the best model with expected validation accuracy: 0.892\n",
      "INFO:tensorflow:Restoring parameters from lib/tf_models/problem2/csci-599_mine.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from lib/tf_models/problem2/csci-599_mine.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8YAAALOCAYAAABrtQoYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nO3MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f83af4350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test accuracy: 0.874\n",
      "Model saved in lib/tf_models/problem2/csci-599_mine.ckpt\n"
     ]
    }
   ],
   "source": [
    "model.train(sess, X_train_, Y_train, X_val_, Y_val)\n",
    "accuracy = model.evaluate(sess, X_test_, Y_test)\n",
    "print('***** test accuracy: %.3f' % accuracy)\n",
    "\n",
    "# Save your model\n",
    "saver = tf.train.Saver()\n",
    "model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")\n",
    "print(\"Model saved in %s\" % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Load your model\n",
    "model = YourModel()\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(sess, X_test_, Y_test)\n",
    "print('***** test accuracy: %.3f' % accuracy)\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
